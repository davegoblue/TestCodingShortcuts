---
title: "CDC Daily by State"
author: "davegoblue"
date: "4/14/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background
This file is designed to use CDC data to assess coronavirus disease burden by state, including creating and analyzing state-level cluters.

Through March 7, 2021, [The COVID Tracking Project](https://covidtracking.com/) collected and integrated data on tests, cases, hospitalizations, deaths, and the like by state and date.  The latest code for using this data is available in Coronavirus_Statistics_CTP_v004.Rmd.

The COVID Tracking Project suggest that [US federal data sources](https://covidtracking.com/analysis-updates/federal-covid-data-101-how-to-find-data) are now sufficiently robust to be used for analyses that previously relied on COVID Tracking Project.  This code is an attempt to update modules in Coronavirus_Statistics_CTP_v004.Rmd to leverage US federal data.

The code leverages tidyverse and a variable mapping file throughout:  
```{r}

# All functions assume that tidyverse and its components are loaded and available
# Other functions are declared in the sourcing files or use library::function()
library(tidyverse)

# For future use, source key modules from a separate .R file

# Create a variable mapping file - this is not yest updated for federal data
varMapper <- c("cases"="Cases", 
               "newCases"="Increase in cases, most recent 30 days",
               "casesroll7"="Rolling 7-day mean cases", 
               "deaths"="Deaths", 
               "newDeaths"="Increase in deaths, most recent 30 days",
               "deathsroll7"="Rolling 7-day mean deaths", 
               "cpm"="Cases per million",
               "cpm7"="Cases per day (7-day rolling mean) per million", 
               "newcpm"="Increase in cases, most recent 30 days, per million",
               "dpm"="Deaths per million", 
               "dpm7"="Deaths per day (7-day rolling mean) per million", 
               "newdpm"="Increase in deaths, most recent 30 days, per million", 
               "hpm7"="Currently Hospitalized per million (7-day rolling mean)", 
               "tpm"="Tests per million", 
               "tpm7"="Tests per million per day (7-day rolling mean)"
               )

# Helper functions used early in the process
# Function for saving an R object to RDS, including a check for whether the object already exists
saveToRDS <- function(obj, 
                      file=paste0(deparse(substitute(obj)), ".RDS"), 
                      dir="./RInputFiles/Coronavirus/", 
                      ovrWrite=FALSE, 
                      ovrWriteError=TRUE,
                      makeReadOnly=TRUE
                      ) {
    
    # FUNCTION ARGUMENTS:
    # obj: the R object to save
    # file: the file name to save as
    # dir: the directory to save in (file path will be paste0(dir, file))
    # ovrWrite: boolean, should the file be overwritten if it already exists?
    # ovrWriteError: boolean, should an error be thrown if an attempt is made to overwrite the file?
    # makeReadOnly: boolean, should the output file be made read-only?
    
    # Create the file name
    locFile <- paste0(dir, file)
    
    # Check if the file already exists and proceed as per options
    if (file.exists(locFile)) {
        cat("\nFile already exists:", locFile, "\n")
        if (!ovrWrite & ovrWriteError) stop("\nAborting due to ovrWrite=FALSE and ovrWriteError=TRUE")
        if (!ovrWrite) {
            cat("\nNot replacing the existing file since ovrWrite=FALSE\n")
            return(NULL)
        }
    }
    
    # Save the file and update the permissions to read-only (if flag is set)
    saveRDS(obj, file=locFile)
    if (makeReadOnly) Sys.chmod(locFile, mode="0555", use_umask = FALSE)
    
}



# Function for reading an R object from RDS
readFromRDS <- function(file, 
                        dir="./RInputFiles/Coronavirus/", 
                        addSuffix=".RDS", 
                        deparseSub=FALSE
                        ) {
    
    # FUNCTION ARGUMENTS:
    # file: the file name to read in
    # dir: the directory the file is in
    # addSuffix: the suffix that should be added to file (file path will be paste0(dir, file, addSuffix))
    # deparseSub: whether to deparse and substitute file (use it as the text name)
    
    # Convert file if needed
    if (deparseSub) file <- deparse(substitute(file))
    
    # Ensure that file is of type character
    if (!isTRUE(all.equal(class(file), "character"))) {
        stop("\nUnable to read since file is not a character\n")
    }
    
    # Create the file name
    locFile <- paste0(dir, file, addSuffix)
    
    # Read the file (will be the return)
    readRDS(locFile)
    
}


```
  
### Downloading and Integrating US Federal Data  
#### _Cases and Deaths by State-Date_
CDC case and death data by state and date are available for download on the [CDC website](https://data.cdc.gov/api/views/9mfq-cb36/rows.csv?accessType=DOWNLOAD).  The previously written function downloadCOVIDbyState() can be used to acquire the data by updating the API:  
```{r}

# NO CHANGES MADE TO FUNCTION - default API is from COVID Tracking Project
# Function to download data for COVID Tracking Project
downloadCOVIDbyState <- function(fileName, 
                                 api="https://api.covidtracking.com/v1/states/daily.csv", 
                                 ovrWrite=FALSE
                                 ) {
    
    # FUNCTION ARGUMENTS:
    # fileName: the filename that the data will be saved to
    # api: The API link for data downloads
    # ovrWrite: whether to allow overwriting of the existing fileName
    
    # Check whether fileName already exists
    if (file.exists(fileName)) {
        cat("\nFile already exists at:", fileName, "\n")
        if (ovrWrite) cat("Will over-write with current data from", api, "\n")
        else stop("Exiting due to ovrWrite=FALSE and a duplicate fileName\n")
    }
    
    # Download the file 
    download.file(api, destfile=fileName)
    
    # Show statistics on downloaded file
    file.info(fileName)
    
}


```

The data are downloaded and the process cached to avoid repeated hits against the CDC website:  
```{r cache=TRUE}

downloadCOVIDbyState("./RInputFiles/Coronavirus/CDC_dc_downloaded_210414.csv",
                     api="https://data.cdc.gov/api/views/9mfq-cb36/rows.csv?accessType=DOWNLOAD", 
                     ovrWrite=FALSE
                     )

```

Key fields from the documentation include:  
  
* submission_date - date of counts  
* state - state (includes 50 states, DC, NYC, and 8 territories/federations)  
* tot_cases - cumulative number of cases (confirmed and probable)  
* new_case - new cases (confirmed and probable)  
* tot_death - cumulative number of deaths (confirmed and probable)  
* new_death - new deaths (confirmed and probable)  
* consent_cases - boolean tracked as "Agree" (confirmed and probable tracked separately) or "Not Agree" (only total tracked)  
* consent_deaths - boolean tracked as "Agree" or "Not Agree" (same as for consent_cases)  
  
Basic formatting and QC is run on the downloaded data (this can later be converted to functional form):  
```{r}

# Read and glimpse downloaded CDC file
cdcRaw <- readr::read_csv("./RInputFiles/Coronavirus/CDC_dc_downloaded_210414.csv")
glimpse(cdcRaw)

# Check for variables in the consent_ fields
cdcRaw %>% 
    count(consent_cases, consent_deaths)

# Function to convert N/A, Agree, and Not agree to boolean
cdcToBool <- function(x) {
    y <- case_when(is.na(x) ~ "NA", 
                   x=="N/A" ~ "NA", 
                   x=="Agree" ~ "TRUE", 
                   x=="Not agree" ~ "FALSE", 
                   TRUE ~ "Problem"
                   )
    if (sum(y=="Problem") != 0) stop("Problem with the boolean conversion")
    y[y=="NA"] <- NA
    as.logical(y)
}

# Format fields as desired types
cdcProcessed <- cdcRaw %>%
    mutate(date=lubridate::mdy(submission_date), 
           creation_date=lubridate::mdy_hms(created_at), 
           bool_c_cases=cdcToBool(consent_cases), 
           bool_c_deaths=cdcToBool(consent_deaths)
           )
glimpse(cdcProcessed)

# Get control totals by state for numeric fields
cdcControl <- cdcProcessed %>%
    group_by(state) %>%
    summarize_if(is.numeric, .funs=function(x) sum(x, na.rm=TRUE))

# Plot control totals by state for numeric fields
for (keyVar in names(cdcControl)[2:ncol(cdcControl)]) {
    p1 <- cdcControl %>%
        select_at(vars(all_of(c("state", keyVar)))) %>%
        purrr::set_names(c("state", "y")) %>%
        ggplot(aes(x=fct_reorder(state, y), y=y)) + 
        geom_col(fill="lightblue") + 
        geom_text(aes(y=y/2, label=format(y, big.mark=",")), size=3, hjust=0) +
        labs(x="", y="", title=paste0("Control totals by state for ", keyVar)) + 
        coord_flip()
    print(p1)
}

```
  
Not every state reports on every metric.  In particular, some jurisdictions break cases and deaths in to probable and confirmed while others do not.  All states appear to report both total (cumulative) and new case.  Comparisons of these fields are run, since restatements of history can lead to total and cumsum(new) being different:  
```{r}

# Check for alignment of total and sum(new)
cdcMism <- cdcProcessed %>%
    arrange(state, date) %>%
    group_by(state) %>%
    mutate(ck_tot_case=cumsum(ifelse(is.na(new_case), 0, new_case)), 
           ck_tot_death=cumsum(ifelse(is.na(new_death), 0, new_death))
           ) %>%
    select(date, state, tot_cases, ck_tot_case, tot_death, ck_tot_death, everything()) %>%
    mutate(mism_case=tot_cases != ck_tot_case, mism_death=tot_death != ck_tot_death) %>%
    group_by(state) %>%
    summarize(mism_case=sum(mism_case), mism_death=sum(mism_death), .groups="drop") %>%
    filter(mism_death > 0 | mism_case > 0) %>%
    arrange(-mism_case, -mism_death)
cdcMism

```

Many states have data that are aligned throughout.  In some states, there are differences between the total and new fields that should be explored further.  A function is written to assess mismatches in the data:  
```{r}

# Function to report totals and plot trends by state
assessMismatch <- function(keyStates, 
                           keyMetric="cases",
                           df=cdcProcessed
                           ) {
    
    # FUNCTION ARGUMENTS
    # keyStates: states to be explored for differences
    # keyMetric: metric to be explored
    # df: the data frame containing data by state-date
    
    # Create a main database for comparisons
    dfUse <- cdcProcessed %>%
        arrange(state, date) %>%
        group_by(state) %>%
        mutate(ck_tot_case=cumsum(ifelse(is.na(new_case), 0, new_case)), 
               ck_tot_death=cumsum(ifelse(is.na(new_death), 0, new_death)), 
               d_cases=ck_tot_case-tot_cases,
               d_deaths=ck_tot_death-tot_death
               ) %>%
        select(date, 
               state, 
               cases=tot_cases, 
               ck_cases=ck_tot_case, 
               d_cases,
               deaths=tot_death, 
               ck_deaths=ck_tot_death, 
               d_deaths,
               everything()
               )
    
    # Show the discrepancies in the final data for each state
    dfUse %>%
        filter(state %in% all_of(keyStates)) %>%
        group_by(state) %>%
        filter(row_number()==n()) %>% 
        select(date, state, cases, ck_cases, d_cases, deaths, ck_deaths, d_deaths) %>%
        print()
    
    # Create plot of metric evolution
    dfPlot <- dfUse %>%
        filter(state %in% all_of(keyStates)) %>%
        select(date, state, cases, ck_cases, d_cases, deaths, ck_deaths, d_deaths) %>%
        pivot_longer(-c(date, state)) %>%
        filter(str_detect(name, keyMetric)) 
    p1 <- dfPlot %>%
        filter(!str_detect(name, "d_")) %>%
        mutate(useName=ifelse(str_detect(name, "ck_"), "cumsum(new)", "reported total")) %>%
        ggplot(aes(x=date, y=value)) + 
        geom_line(aes(group=useName, color=useName)) +
        labs(x="", 
             y="Cumulative reported", 
             title=paste0("Discrepancies in cumulative total ", keyMetric)
             ) +
        scale_color_discrete("Source") +
        facet_wrap(~state, scales="free_y")
    print(p1)
    p2 <- dfPlot %>%
        filter(str_detect(name, "d_")) %>%
        ggplot(aes(x=date, y=value)) + 
        geom_line(aes(group=state, color=state)) +
        labs(x="", 
             y="Cumulative discrepancy", 
             title=paste0("Discrepancies in cumulative total ", keyMetric)
             ) +
        scale_color_discrete("State")
    print(p2)
    
}

```
  
The function can then be applied to the case and death data with mismatches:  
```{r}

assessMismatch(keyStates=cdcMism %>% filter(mism_case > 0) %>% pull(state), keyMetric="cases")
assessMismatch(keyStates=cdcMism %>% filter(mism_death > 0) %>% pull(state), keyMetric="deaths")

```

The mismathes appear to arise at discrete points in time, likely reflecting a reclassification of many previous cases and deaths.  The total field is always greater than or equal to the sum of the new field.  This sugests using 'new' for shape of the curve and 'total' for overall disease burden.

A function is then written to rename and split columns appropriately:  
```{r}

# Create list of expected variables and renames (NA means keep as-is)
cdcVarNames <- c("date"=NA, 
                 "state"=NA, 
                 "tot_cases"=NA, 
                 "conf_cases"=NA, 
                 "prob_cases"=NA, 
                 "new_case"="new_cases", 
                 "pnew_case"="pnew_cases", 
                 "tot_death"="tot_deaths", 
                 "conf_death"="conf_deaths", 
                 "prob_death"="prob_deaths", 
                 "new_death"="new_deaths", 
                 "pnew_death"="pnew_deaths",
                 "bool_c_cases"="bool_cases", 
                 "bool_c_deaths"="bool_deaths"
                 )

# Function to rename variables, split, and pivot for easier analysis
renamePivotProcessed <- function(df, 
                                 selectRename=cdcVarNames
                                 ) {
    
    # FUNCTION ARGUMENTS
    # df: a processed CDC data file
    # selectRename: a list of variable -> new name (NA means keep as-is) as c('original'='new')
    
    # Check alignment of variables in df and selectRename
    dfNames <- names(df)
    selNames <- names(selectRename)
    
    # Create the vector of renamed variables after selection
    selRenames <- unname(selectRename[selNames])
    selRenames[is.na(selRenames)] <- selNames[is.na(selRenames)]
    
    # Names in one but not the other
    cat("\n*** Variables that will be dropped (not in selectRename vector) include:", 
        setdiff(dfNames, selNames), 
        sep="\n"
        )
    cat("\n\n*** Variables passed in selectRename that are not in the data include:", 
        setdiff(selNames, dfNames), 
        sep="\n"
        )
    
    # Select the key variables and rename
    df <- df %>%
        select_at(vars(all_of(selNames))) %>%
        purrr::set_names(selRenames)

    # Pivot and separate the data, keeping unique by date-state
    # Requires that selectRename have every variable as modifier_type
    df <- df %>%
        pivot_longer(-c(date, state)) %>%
        tidyr::separate(name, into=c("modifier", "metric"), sep="_")

    # Summary NA statistics of the new dataset
    cat("\nSummary statistics for processed and pivoted data\n")
    df %>%
        group_by(modifier, metric) %>%
        summarize(n=n(), nna=sum(is.na(value)), sum=sum(value, na.rm=TRUE), .groups="drop") %>%
        print()
    cat("\n")
    
    # Return the data frane
    df
    
}

```
  
The function is applied to create cdcPivotLong:  
```{r}

cdcPivotLong <- renamePivotProcessed(cdcProcessed)
glimpse(cdcPivotLong)

```

Next steps are to combine the NYS/NYC data as NY and to filter to the states and DC.  A function is written to combine states (will be applied only to NY and NYC for these data):  
```{r}

# Function to combine states
combineStates <- function(df, 
                          mapper=comboStates,
                          sortBy=c("date", "state", "modifier", "metric"),
                          boolMod=c("bool")
                          ) {
    
    # FUNCTION ARGUMENTS:
    # df: a data frame resulting from renamePivotProcessed() that includes date-state-modifier-metric-value
    # mapper: a vector listing the states to be remapped
    # sortBy: order that the resulting file should be sorted (and unique) by
    # boolMod: modifier indicating value is a boolean rather than number (cannot be summed)
    
    # Split the file in to stand-alone and combined
    df <- df %>%
        mutate(combined=state %in% names(mapper))
    dfAlone <- df %>% filter(!combined)
    dfCombo <- df %>% filter(combined)
    
    # Process the combined file to give it the new state name
    # Group by the final sorting variables
    dfCombo <- dfCombo %>%
        mutate(state=unname(comboStates[state])) %>%
        group_by_at(vars(all_of(sortBy))) %>%
        arrange_at(vars(all_of(sortBy)))
    
    # Numeric variables should be summed, with NA+NA=NA and NA+number=number
    specNASum <- function(x) if (any(!is.na(x))) sum(x, na.rm=TRUE) else NA

    # Sum the value field, leave the combined field as-is
    dfCombo <- dfCombo %>%
        summarize(value=specNASum(value), combined=first(combined), .groups="drop")
    
    # Boolean variables should be output as NA since there is no sensible combining based on what it means
    dfCombo <- dfCombo %>%
        mutate(value=ifelse(modifier %in% all_of(boolMod), NA, value))
    
    # Combine the data, sort, check for uniqueness, and return
    dfAll <- bind_rows(dfCombo, dfAlone) %>%
        arrange_at(vars(all_of(sortBy)))
    if (nrow(distinct(dfAll %>% select_at(vars(all_of(sortBy))))) != nrow(dfAll)) stop("\nRow mismatch\n")
    dfAll
    
}

```
  
The function is then applied to the cdcPivotLong data:  
```{r}

# List of states to be changed 
# Also include any state that is mapped to itself with some other state mapping to it
# Format is 'currentState'='combinedState'
comboStates <- c("NYC"="NY", 
                 "NY"="NY"
                 )

# Run function
cdcAnalysis <- combineStates(cdcPivotLong)

# Check for prevalenece of NA by metric-modifier
cdcAnalysis %>%
    group_by(metric, modifier) %>%
    summarize(sumValue=sum(value, na.rm=TRUE), n=n(), nna=sum(is.na(value)), nComb=sum(combined))

```
  
The fields for tot/new by cases/deaths appear appropriate for further usage.  Next steps are to compare the totals to existing data from the CTP (final date 2021-03-07).

The final CTP data are pulled, with cumulative data through 2021-03-07 calculated.  Cumulative data through 2021-03-07 from the CDC file are also extracted:  
```{r}

# Read in existing data from CTP
ctp_hier6_210401 <- readFromRDS("ctp_hier6_210401")

# Totals through 2021-03-07 for CTP (final date of collection)
ctp_cum_210307 <- ctp_hier6_210401$dfFiltered %>%
    group_by(state) %>%
    summarize_if(is.numeric, sum, na.rm=TRUE) %>%
    pivot_longer(-c(state), names_to="metric") %>%
    mutate(modifier="ctp") %>%
    select(state, modifier, metric, value, everything())
ctp_cum_210307

# Totals through 2021-03-07 for CDC (to match CTP data)
# Uses final tot-cases, final tot-deaths, cumsum new-cases, cumsum new-deaths
cdc_cum_210307 <- cdcAnalysis %>%
    filter(date <= as.Date("2021-03-07"), 
           metric %in% c("cases", "deaths"), 
           modifier %in% c("new", "tot"), 
           state %in% c(state.abb, "DC")
           ) %>%
    pivot_wider(c(state, date, metric), names_from="modifier", values_from="value") %>%
    group_by(state, metric) %>%
    summarize(new=sum(new, na.rm=TRUE), tot=last(tot, order_by=date), .groups="drop") %>%
    pivot_longer(-c(state, metric), names_to="modifier") %>%
    select(state, modifier, metric, value, everything())
cdc_cum_210307

```

Next steps are to write a function to pull a specific metric and plot the differences in a 'base' modifier and any other values for modifier.

A function is written to compare data from different sources:  
```{r}

# Function to assess variables new_x, tot_x, and x for percentage differences
checkStateCompare <- function(..., 
                              met="cases", 
                              baseModifier="ctp"
                              ) {
    
    # FUNCTION ARGUMENTS:
    # ...: one or more data frames of the form state-modifier-metric-value
    # met: the metric to be used, "cases" or "deaths"
    # baseModifier: value of the modifier field that signifies the baseline for comparison
    
    # Bind the data frames, and calculate as a percentage of the "base" modifier
    df <- bind_rows(...) %>%
        filter(metric %in% all_of(met)) %>%
        arrange(state, modifier) %>%
        group_by(state) %>%
        mutate(pct_of=value/sum(ifelse(modifier==all_of(baseModifier), value, 0))) %>%
        ungroup()

    # Plot the percentage differences for fields other than reference
    p1 <- df %>%
        filter(modifier != all_of(baseModifier)) %>%
        ggplot(aes(x=fct_reorder(state, pct_of), 
                   y=pct_of, 
                   color=modifier
                   )
               ) + 
        geom_point() + 
        coord_flip() + 
        labs(x="", 
             y=paste0("Reported ", met, " as function of baseline data from ", baseModifier), 
             title=paste0("Comparison to baseline data for ", met)
             ) + 
        scale_color_discrete("Comparison metric") + 
        geom_hline(yintercept=1, lty=2)
    print(p1)
    
    # Return the data frame
    df
    
}

```

The function can then be applied to the cases and deaths data:  
```{r}

# Run comparisons for cases and deaths
caseCompare <- checkStateCompare(ctp_cum_210307, cdc_cum_210307, met="cases")
deathCompare <- checkStateCompare(ctp_cum_210307, cdc_cum_210307, met="deaths")

# Print cases and deaths that are at least 3% different
caseCompare %>%
    filter(abs(1-pct_of) >= 0.03)
deathCompare %>%
    filter(abs(1-pct_of) >= 0.03)

```

Data are well aligned between CTP and CDC as of 2021-03-07.  Primary differences include:  
  
* CDC reports significantly greater cases for Iowa (+20%) and Missouri (+17%)  
* CDC reports modestly lower cases for Massachusetts (-4%) and Hawaii (-6%)  
* CDC reports significantly more deaths for Oklahoma (+46%) and New York (+13% on sum of 'new', +23% on 'tot)  
* CDC reports modestly more deaths for Texas (+5%)  
* CDC reports significantly lower deaths for Indiana (-11% using 'new'), Ohio (-21% using 'new'), and New Jersey (-8% using 'new'), though sums of 'tot' for these states appear well aligned to the CTP data  
  
In general, the CDC 'tot' field appears well aligned to the cumulative totals from CTP, and can likely be used on a go-forward as a measure of cumulative disease impact in each state.

Next steps are to check the curve evolutions, particularly since states with differences in 'new' and 'tot' have large corrections all reported at once.

A function is written to compare the shapes of the curves.  Curve shape will be assessed as the percentage distribution of 'new' cases and deaths by time:  
```{r}

curvePercent <- function(df, 
                         keyMetric, 
                         keyModifiers=c("new", "ctp"), 
                         dateMax=as.Date("2021-03-07")
                         ) {
  
 
    # FUNCTION ARGUMENTS:
    # df: the data frame containing date-state-modifier-metric-value
    
    # Filter for the metric and modifiers of interest and only through dateMax
    df <- df %>%
        filter(metric %in% all_of(keyMetric), 
               modifier %in% all_of(keyModifiers), 
               date <= all_of(dateMax)
               )
    
    # Calculate the cumulative percentage by date
    df <- df %>%
        mutate(value=ifelse(is.na(value), 0, value)) %>%
        arrange(date) %>%
        group_by(state, metric, modifier) %>%
        mutate(pct=cumsum(value)/sum(value)) %>%
        ungroup()
    
    # Pivot for percentages by state-date-metric
    df <- df %>%
        pivot_wider(c(state, date, metric), names_from="modifier", values_from="pct") %>%
        mutate_at(vars(all_of(keyModifiers)), .funs=function(x) ifelse(is.na(x), 0, x))
    
    # Calculate RMSE for each state-metric (assumes only two columns - can expand later)
    stateRMSE <- df %>%
        group_by(state, metric) %>%
        summarize(rmse=sqrt(mean((get(keyModifiers[1])-get(keyModifiers[2]))**2)), .groups="drop")

    # Create plots of RMSE by state
    p1 <- stateRMSE %>%
        ggplot(aes(x=fct_reorder(state, rmse), y=rmse)) + 
        geom_point() +
        geom_text(aes(label=round(rmse, 3), y=rmse+0.00025), hjust=0, size=3) +
        coord_flip() + 
        labs(x="", 
             y="RMSE for cumulative percentage by date", 
             title=paste0("Curve comparison for ", keyMetric)
             )
    print(p1)
    
    # Return the data frame
    df
    
}

```
  
The CTP data are formatted for use with the function, integrated with cdcPivotLong, and assessed:  
```{r}

fullPivotLong <- ctp_hier6_210401$dfFiltered %>%
    pivot_longer(-c(date, state), names_to="metric") %>%
    mutate(modifier="ctp") %>%
    bind_rows(cdcPivotLong) %>%
    filter(state %in% c(state.abb, "DC"))

curveCases <- curvePercent(fullPivotLong, keyMetric="cases")
curveDeath <- curvePercent(fullPivotLong, keyMetric="deaths")

```

Many of the same locales that have differences between the 'new' and 'total' fields in CDC also have differences in curve shape with CTP.  Next steps are to explore some of the larger differences.

A function is written to explore curves for a speciic metric and set of states:  
```{r}

exploreCurve <- function(df, 
                         keyMetric=NULL, 
                         keyStates=NULL
                         ) {
    
    # FUNCTION ARGUMENTS:
    # df: data frame containing state-date-metric-[1 column per metric type]
    # keyMetric: the metric to filter in column 'metric' (NULL means determine from data)
    # keyStates: the list of states to be plotted (NULL means pick the top 9 from data)
    
    # Get keyMetric if it is passed as NULL
    if (is.null(keyMetric)) {
        keyMetric <- df %>% count(metric) %>% arrange(-n) %>% head(1) %>% pull(metric)
        cat("\nKey metric will be: ", keyMetric)
    }
    
    # Get the numerical columns for plotting
    colPlot <- df %>% select_if(is.numeric) %>% names()
    cat("\nColumns to be plotted will be: ", colPlot, "\n")
    
    # Get keyStates if not passed
    if (is.null(keyStates)) {
        keyStates <- df %>%
            filter(metric==all_of(keyMetric)) %>%
            group_by(state) %>%
            summarize(rmse=sqrt(mean((get(colPlot[1])-get(colPlot[2]))**2)), .groups="drop") %>%
            arrange(-rmse) %>%
            head(9) %>%
            pull(state)
        cat("States to be plotted will be: ", keyStates, "\n")
    }
    
    # Create faceted plots for the requested metrics
    dfPlot <- df %>%
        filter(metric==all_of(keyMetric), state %in% all_of(keyStates)) %>%
        select_at(vars(all_of(c("state", "date", colPlot)))) %>%
        mutate(state=factor(state, levels=keyStates)) %>%
        pivot_longer(-c("state", "date")) %>%
        arrange(state, name, date) %>%
        group_by(state, name) %>%
        mutate(delta=ifelse(row_number()==1, value, value-lag(value, 1)))
    p1 <- dfPlot %>%
        ggplot(aes(x=date, y=value)) + 
        geom_line(aes(group=name, color=name)) + 
        facet_wrap(~state) + 
        labs(x="", 
             y="Cumulative percentage of total recorded by date", 
             title=paste0("Curve evolution by percentage for metric: ", keyMetric), 
             subtitle="Cumulative"
             ) + 
        scale_color_discrete("Data source")
    p2 <- dfPlot %>%
        ggplot(aes(x=date, y=delta)) + 
        geom_line(aes(group=name, color=name)) + 
        facet_wrap(~state, scales="free_y") + 
        labs(x="", 
             y="Incremental percentage of total recorded by date", 
             title=paste0("Curve evolution by percentage for metric: ", keyMetric), 
             subtitle="Incremental"
             ) + 
        scale_color_discrete("Data source")
    print(p1)
    print(p2)
    
}

```

The routine is then run for cases and deaths, with a larger plotting area:  
```{r, fig.height=9, fig.width=9}

exploreCurve(curveCases)
exploreCurve(curveDeath)

```

Visually, the shapes of the case curves are nearly overlapping, and segments based using shape will likely be the same whether using CTP or CDC data.  The shapes of the death curves vary meaningfully in NY and modestly in OH, OK, and IN.  While the different curve evolutions are unlikely to drive different segments, it is worth keeping an eye on (particularly for NY).

Next steps are to adapt the CDC data and existing CTP code so they can be used together.

#### _Coding Steps for State Data_
The main function used previously is readRunCOVIDTrackingProject(), which performs multiple tasks:  
  
STEP 1: Extracts a file of population by state (by default uses 2015 population from usmap::statepop)  
STEP 2a^: Downloads the latest data from COVID Tracking Project if requested  
STEP 2b^: Reads in data from a specified local file (may have just been downloaded in step 2a), and checks control total trends against a previous version of the file  
STEP 3^: Processed the loaded data file for keeping proper variables, dropping non-valid states, etc.  
STEP 4^: Adds per-capita metrics for cases, deaths, tests, and hospitalizations  
STEP 5: Adds existing clusters by state if passed as an argument to useClusters=, otherwise creates new segments based on user-defined parameters  
STEP 6^^: Creates assessment plots for the state-level clusters  
STEP 7^^: Creates consolidated plots of cases, hospitalizations, deaths, and tests  
STEP 8^^: Optionally, creates plots of cumulative burden by segments and by state  
STEP 9: Returns a list of key data frames, modeling objects, named cluster vectors, etc.  
  
^ The user can instead specify a previously processed file and skip steps 2a, 2b, 3, and 4.  The previously processed file needs to be formatted and filtered such that it can be used "as is"  
^^ The user can skip the segment-level assessments by setting skipAssessmentPlots=TRUE  
  
The main function and the helper functions were previously updated to allow for using 2021 data.  The main function is copied below and will eventually be adapted for CDC daily data:  
```{r}

# Function to download/load, process, segment, and analyze data for CDC daily
# Needs to be updated
readRunCDCDaily <- function(thruLabel, 
                            downloadTo=NULL, 
                            readFrom=downloadTo, 
                            compareFile=NULL,
                            dateChangePlot=FALSE,
                            dateMetricPrint=TRUE,
                            writeLog=NULL,
                            ovrwriteLog=TRUE,
                            dfPerCapita=NULL,
                            useClusters=NULL,
                            hierarchical=TRUE,
                            returnList=!hierarchical, 
                            kCut=6,
                            reAssignState=vector("list", 0),
                            makeCumulativePlots=TRUE,
                            skipAssessmentPlots=FALSE,
                            ...
                            ) {
    
    # FUNCTION ARGUMENTS:
    # thruLabel: the label for when the data are through (e.g., "Aug 30, 2020")
    # donwloadTo: download the most recent CDC daily data to this location
    #             NULL means do not download any data
    # readFrom: location for reading in the CDC daily data (defaults to donwloadTo)
    # compareFile: name of the file to use for comparisons when reading in raw data (NULL means no comparison)
    # dateChangePlot: boolean, should changes in dates be captured as a plot rather than as a list?
    # dateMetricPrint: boolean, should the changes by date and metric be printed to the main log?
    # writeLog: name of a separate log file for capturing detailed data on changes between files
    #           NULL means no detailed data captured
    # ovrwriteLog: boolean, should the log file be overwritten and started again from scratch?
    # dfPerCapita: file can be passed directly, which bypasses the loading and processing steps
    # useClusters: file containing clusters by state (NULL means make the clusters from the data)
    # hierarchical: boolean, should hierarchical clusters be produced (if FALSE, will be k-means)?
    # returnList: boolean, should a list be returned or just the cluster object?
    #             refers to what is returned by clusterStates(); the main function always returns a list
    # kCut: number of segments when cutting the hierarchical tree
    # reAssignState: mapping file for assigning a state to another state's cluster
    #                format list("stateToChange"="stateClusterToAssign")
    # makeCumulativePlots: whether to make plots of cumulative metrics
    # skipAssessmentPlots: boolean to skip the plots for assessClusters()
    #                      especially useful if just exploring dendrograms or silhouette widths
    # ...: arguments to be passed to clusterStates(), will be used only if useClusters is NULL
    
    
    # STEP 1: Get state data
    stateData <- getStateData()
    
    # Helper function for glimpsing
    glimpseFile <- function(x, txt) {
        cat(txt)
        glimpse(x)
    }
            
    # STEPS 2-4 are run only if dfPerCapita does not exist
    if (is.null(dfPerCapita)) {
        
        # STEP 2a: Download latest CDC daily data (if requested)
        if (!is.null(downloadTo)) {
            downloadCOVIDbyState(fileName=downloadTo, 
                                 api="https://api.covidtracking.com/v1/states/daily.csv"
                                 )
        }
        
        # STEP 2b: Read-in CDC Daily Data
        dfRaw <- readCOViDbyState(readFrom, 
                                  checkFile=compareFile, 
                                  dateChangePlot=dateChangePlot, 
                                  dateMetricPrint=dateMetricPrint, 
                                  writeLog=writeLog, 
                                  ovrwriteLog=ovrwriteLog
                                  )
        if (is.null(writeLog)) glimpseFile(dfRaw, txt="\nRaw data file:\n")
        else capture.output(glimpseFile(dfRaw, txt="\nRaw data file:\n"), file=writeLog, append=TRUE)
        
        # STEP 3: Process the data so that it includes all requested key variables
        varsFilter <- c("date", "state", "positiveIncrease", "deathIncrease", 
                        "hospitalizedCurrently", "totalTestResultsIncrease"
                        )
        dfFiltered <- processCVData(dfRaw, 
                                    varsKeep=varsFilter, 
                                    varsRename=c(positiveIncrease="cases", 
                                                 deathIncrease="deaths", 
                                                 hospitalizedCurrently="hosp", 
                                                 totalTestResultsIncrease="tests"
                                    )
        )
        if (is.null(writeLog)) glimpseFile(dfFiltered, txt="\nFiltered data file:\n")
        else capture.output(glimpseFile(dfFiltered, txt="\nFiltered data file:\n"), file=writeLog, append=TRUE)
        
        # STEP 4: Convert to per capita
        dfPerCapita <- helperMakePerCapita(dfFiltered, 
                                           mapVars=c("cases"="cpm", "deaths"="dpm", 
                                                     "hosp"="hpm", "tests"="tpm"
                                           ), 
                                           popData=stateData
        )
        if (is.null(writeLog)) glimpseFile(dfPerCapita, txt="\nPer capita data file:\n")
        else capture.output(glimpseFile(dfPerCapita, txt="\nPer capita data file:\n"), 
                            file=writeLog, 
                            append=TRUE
                            )
        
    } else {
        dfRaw <- NULL
        dfFiltered <- NULL
    }
    
    
    # STEP 5: Create the clusters (if they have not been passed)
    if (is.null(useClusters)) {
        # Run the clustering process
        clData <- clusterStates(df=dfPerCapita, hierarchical=hierarchical, returnList=returnList, ...)
        # If hierarchical clusters, cut the tree, otherwise use the output object directly
        if (hierarchical) {
            useClusters <- cutree(clData, k=kCut)
        } else {
            useClusters <- clData$objCluster$cluster
        }
        # If requested, manually assign clusters to the cluster for another state
        for (xNum in seq_len(length(reAssignState))) {
            useClusters[names(reAssignState)[xNum]] <- useClusters[reAssignState[[xNum]]]
        }
        
    }
    
    
    # STEP 5a: Stop the process and return what is available if skipAssessmentPlots is TRUE
    if (skipAssessmentPlots) {
        return(list(stateData=stateData, 
                    dfRaw=dfRaw, 
                    dfFiltered=dfFiltered, 
                    dfPerCapita=dfPerCapita, 
                    useClusters=useClusters, 
                    plotData=NULL, 
                    consolidatedPlotData=NULL, 
                    clCum=NULL
                    )
               )
    }
    
    
    # STEP 6: Create the cluster assessments
    plotData <- assessClusters(useClusters, 
                               dfState=stateData, 
                               dfBurden=dfPerCapita,
                               thruLabel=thruLabel,
                               plotsTogether=TRUE
    )
    
    
    # STEP 7: Plot the consolidated metrics
    subT <- "Cases: new cases, Deaths: new deaths, Hosp: total in hospital (not new), Tests: new tests"
    consolidatedPlotData <- plotConsolidatedMetrics(plotData, 
                                                    varMain=c("state", "cluster", "date", "pop",
                                                              "cases", "deaths", "hosp", "tests"
                                                    ), 
                                                    subT=subT, 
                                                    nrowPlot2=2
    )
    
    # STEP 8: Create cumulative metrics if requested
    if (makeCumulativePlots) {
        consPos <- consolidatedPlotData %>%
            ungroup() %>%
            select(state, cluster, date, name, vpm7) %>%
            arrange(state, cluster, date, name) %>%
            pivot_wider(-vpm7, names_from="name", values_from="vpm7") %>%
            mutate(pctpos=cases/tests) %>%
            pivot_longer(-c(state, cluster, date), values_to="vpm7") %>%
            filter(!is.na(vpm7))
        clCum <- makeCumulative(consPos)
        plotCumulativeData(clCum, 
                           keyMetricp2="", 
                           flagsp2="", 
                           makep1=TRUE, 
                           makep2=FALSE
        )
        plotCumulativeData(clCum, 
                           keyMetricp2="deaths", 
                           flagsp2=findFlagStates(clCum, keyMetricVal = "deaths")
        )
        plotCumulativeData(clCum, 
                           keyMetricp2="cases", 
                           flagsp2=findFlagStates(clCum, keyMetricVal = "cases")
        )
        plotCumulativeData(clCum, 
                           keyMetricp2="tests", 
                           flagsp2=findFlagStates(clCum, keyMetricVal = "tests")
        )
    } else {
        clCum <- NULL
    }
    
    
    # STEP 9: Return a list of the key data
    list(stateData=stateData, 
         dfRaw=dfRaw, 
         dfFiltered=dfFiltered, 
         dfPerCapita=dfPerCapita, 
         useClusters=useClusters, 
         plotData=plotData, 
         consolidatedPlotData=consolidatedPlotData, 
         clCum=clCum
    )
    
    
}

```
  
The state data are downloaded and a per capita file created:  
```{r, fig.height=9, fig.width=9}

# Function to extract and format key state data
getStateData <- function(df=readFromRDS("statePop2019"), 
                         renameVars=c("stateAbb"="state", "NAME"="name", "pop_2019"="pop"), 
                         keepVars=c("state", "name", "pop")
                         ) {
    
    # FUNCTION ARGUMENTS:
    # df: the data frame containing state data
    # renameVars: variables to be renamed, using named list with format "originalName"="newName"
    # keepVars: variables to be kept in the final file
    
    # Rename variables where appropriate
    names(df) <- ifelse(is.na(renameVars[names(df)]), names(df), renameVars[names(df)])
    
    # Return file with only key variables kept
    df %>%
        select_at(vars(all_of(keepVars)))
    
}

# Run getStateData() as a stand-alone
stateDataCDC <- getStateData()

# Create an analysis file, pivoted wider, for new and total cases/deaths
cdcFiltered <- cdcAnalysis %>%
    filter(metric %in% c("cases", "deaths"), modifier %in% c("new", "tot")) %>%
    mutate(key=paste(modifier, metric, sep="_")) %>%
    pivot_wider(c("date", "state"), names_from="key", values_from="value")


# Helper function to create per capita metrics
helperPerCapita <- function(df, 
                            origVar, 
                            newName,
                            byVar="state",
                            popVar="pop",
                            popData=stateData,
                            mult=1000000
                            ) {
    
    # FUNCTION ARGUMENTS:
    # df: the data frame currently being processed
    # origVar: the variables to be converted to per capita
    # newName: the new per capita variable name
    # byVar: the variable that will be merged by
    # popVar: the name of the population variable in the popData file
    # popData: the file containing the population data
    # mult: the multiplier, so that the metric is "per mult people"
    
    # Create the per capita variable
    df %>%
        inner_join(select_at(popData, vars(all_of(c(byVar, popVar)))), by=byVar) %>%
        mutate(!!newName:=mult*get(origVar)/get(popVar)) %>%
        select(-all_of(popVar))
    
}


# Helper function to create rolling aggregates
helperRollingAgg <- function(df, 
                             origVar, 
                             newName,
                             func=zoo::rollmean,
                             k=7, 
                             fill=NA, 
                             ...
                             ) {
    
    # FUNCTION ARGUMENTS:
    # df: the data frame containing the data
    # origVar: the original data column name
    # newName: the new variable column name
    # func: the function to be applied (zoo::rollmean will be by far the most common)
    # k: the periodicity (k=7 is rolling weekly data)
    # fill: how to fill leading.trailing data to maintain the same vector lengths
    # ...: any other arguments to be passed to func
    
    # Create the appropriate variable
    df %>%
        mutate(!!newName:=func(get(origVar), k=k, fill=fill, ...))
    
}


# Function to add per capita and rolling to the base data frame
helperMakePerCapita <- function(df, 
                                mapVars=c("cases"="cpm", "deaths"="dpm"),
                                popData=stateData,
                                k=7
                                ) {
    
    # FUNCTION ARGUMENTS:
    # df: the initial data frame for conversion
    # mapVars: named vector of variables to be converted 'original name'='converted name'
    # k: the rolling time period to use
    
    # Create the variables for per capita
    for (origVar in names(mapVars)) {
        df <- df %>% 
            helperPerCapita(origVar=origVar, newName=mapVars[origVar], popData=popData)
    }
    # Arrange the data by date in preparation for rolling aggregations
    df <- df %>% 
        group_by(state) %>% 
        arrange(date)

    # Create the rolling variables
    for (newVar in mapVars) {
        df <- df %>% 
            helperRollingAgg(origVar=newVar, newName=paste0(newVar, k), k=k)
    }
    
    # Return the updated data frame, ungrouped
    df %>%
        ungroup()
    
}

# Convert to per capita
cdcPerCapita <- helperMakePerCapita(cdcFiltered, 
                                    mapVars=c("new_cases"="cpm", "new_deaths"="dpm", 
                                              "tot_cases"="tcpm", "tot_deaths"="tdpm"
                                              ), 
                                    popData=stateDataCDC
                                    )
cdcPerCapita

cdcPerCapita %>%
    select(date, state, contains("7")) %>%
    pivot_longer(-c("date", "state")) %>%
    filter(!is.na(value)) %>%
    bind_rows(mutate(summarize(group_by(., date, name), value=median(value), .groups="drop"), 
                     state="med"
                     )
              ) %>%
    ggplot(aes(x=date, y=value)) + 
    geom_line(data=~filter(., state!="med"), aes(group=state), alpha=0.15) +
    geom_line(data=~filter(., state=="med"), aes(group=state), color="blue", size=1.5) + 
    labs(x="", y="Per million", title="Evolution metrics per capita by state", subtitle="Blue is median") +
    facet_wrap(~name, scales="free_y")

```
  
Per capita data appear broadly as expected.  Next steps are to update the segmentation and clustering algorithms.
