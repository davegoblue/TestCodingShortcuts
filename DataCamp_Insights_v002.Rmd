---
title: "Data Camp Insights"
author: "davegoblue"
date: "February 15, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
## Background and Overview  
DataCamp offer interactive courses related to R Programming.  While some is review, it is helpful to see other perspectives on material.  As well, DataCamp has some interesting materials on packages that I want to learn better (ggplot2, dplyr, ggvis, etc.).  This document summarizes a few key insights from:  
  
* R Programming (Introduction to R, Intermediate R, Writing Functions in R, Object Oriented Programming in R)  
* Importing and Cleaning Data (Cleaning Data in R, Importing Data in to R)  
* Data Manipulation (dplyr, data.table, xts/zoo)  
* Data Visualization (base, ggplot2 parts I/II/III, ggvis, geospatial)  
  
The original DataCamp_Insights_v001 document has been split for this document:  
  
* This DataCamp_Insights_v002 document contains evolving sections on R Programming and Data Manipulation  
* Importing and Cleaning Data components have been moved to DataCamp_ImportClean_v002  
* Visualization components have been moved to DataCamp_Visualization_v002  
  
## R Programming (Introduction to R, Intermediate R, Writing Functions in R, Object Oriented Programming in R)   
###_Introduction, Intermediate_  
There are a few nuggest from within these beginning modules, including:  
  
####_Generic statements_  
* factor(x, ordered=TRUE, levels=c(myLevels)) creates ordinal factors (e.g., a > b > c)  
* subset(a, b) is functionally the same as a[a$b, ] but easier to read  
* & looks at each element while && looks only at the first element (same for | and ||)  
* Inside of a for loop, break kills the loop entirely while next moves back to the top for the next item  
* args(function) shows the arguments (with defaults) for function  
* search() shows the current search path (all auto-load packages and all attached packages)  
* cat("expression") will print the expression or direct it to a file; this is a way to allow \n and \t to take effect in a print statement  
* unique() keeps only the non-duplicated elements of a vector  
* unlist() converts a list back to a vector, somewhat similar to as.vector() on a matrix  
* sort() will sort a vector, but not a data frame  
* rep(a, times=m, each=n) replicates each element of a n times, and then the whole string m times  
* append(x, values, after=length(x)) will insert values in to vector x after point after  
* rev() reverses a vector  
* Inside a grep, "\\1" captures what is inside the ()  
    
####_Apply usages_  
* lapply() operates on a vector/list and always returns a list  
* sapply() is lapply but converted to a vector/array when possible (same as lapply if not possible); if USE.NAMES=FALSE then the vector will be unnamed, though the default is USE.NAMES=TRUE for a named vector  
* vapply(X, FUN, FUN.VALUE, ... , USE.NAMES=TRUE) is safer than sapply in that you specify what type of vector each iteration should produce; e.g., FUN.VALUE=character(1) or FUN.VALUE=numeric(3), with an error if the vector produced by an iteration is not exactly that  
  
####_Dates and times_  
* Sys.Date() grabs the system date as class "Date", with units of days  
* Sys.time() grabs the system time as class "POSIXct", with units of seconds  
* Sys.timezone() shows the system timezone  
* Years are formatted as %Y (4-digit) or %y (2-digit)  
* Months are formatted as %m (2-digit) or %B (full character) or %b (3-character)  
* Days are formatted as %d (2-digit)  
* Weekdays are formatted as %A (full name) or %a (partial name)  
* Times include %H (24-hour hour), %M (minutes), %S (seconds)  
* ?strptime will provide a lot more detail on the formats  
  
Below is some sample code showing examples for the generic statements:  
```{r}
# Factors
xRaw = c("High", "High", "Low", "Low", "Medium", "Very High", "Low")

xFactorNon = factor(xRaw, levels=c("Low", "Medium", "High", "Very High"))
xFactorNon
xFactorNon[xFactorNon == "High"] > xFactorNon[xFactorNon == "Low"][1]

xFactorOrder = factor(xRaw, ordered=TRUE, levels=c("Low", "Medium", "High", "Very High"))
xFactorOrder
xFactorOrder[xFactorOrder == "High"] > xFactorOrder[xFactorOrder == "Low"][1]


# Subsets
data(mtcars)
subset(mtcars, mpg>=25)
identical(subset(mtcars, mpg>=25), mtcars[mtcars$mpg>=25, ])
subset(mtcars, mpg>25, select=c("mpg", "cyl", "disp"))


# & and && (same as | and ||)
compA <- c(2, 3, 4, 1, 2, 3)
compB <- c(1, 2, 3, 4, 5, 6)
(compA > compB) & (compA + compB < 6)
(compA > compB) | (compA + compB < 6)
(compA > compB) && (compA + compB < 6)
(compA > compB) || (compA + compB < 6)


# Loops and cat()
# for (a in b) {
#     do stuff
#     if (exitCond) { break }
#     if (nextCond) { next }
#     do some more stuff
# }
for (myVal in compA*compB) {
    print(paste0("myVal is: ", myVal))
    if ((myVal %% 3) == 0) { cat("Divisible by 3, not happy about that\n\n"); next }
    print("That is not divisible by 3")
    if ((myVal %% 5) == 0) { cat("Exiting due to divisible by 5 but not divisible by 3\n\n"); break }
    cat("Onwards and upwards\n\n")
}


# args() and search()
args(plot.default)
search()


# unique()
compA
unique(compA)


# unlist()
listA <- as.list(compA)
unlist(listA)
identical(compA, unlist(listA))


# sort()
sort(mtcars$mpg)
sort(mtcars$mpg, decreasing=TRUE)

# rep()
rep(1:6, times=2)  # 1:6 followed by 1:6
rep(1:6, each=2)  # 1 1 2 2 3 3 4 4 5 5 6 6
rep(1:6, times=2, each=3)  # 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 repeated twice (each comes first)
rep(1:6, times=6:1)  # 1 1 1 1 1 1 2 2 2 2 2 3 3 3 3 4 4 4 5 5 6


# append()
myWords <- c("The", "cat", "in", "the", "hat")
paste(append(myWords, c("is", "fun", "to", "read")), collapse=" ")
paste(append(myWords, "funny", 4), collapse=" ")

# grep("//1")
sampMsg <- "This is from myname@subdomain.mydomain.com again"
gsub("(^.*\\w*[a-zA-Z0-9]+@)([a-zA-Z0-9]+\\.[a-zA-Z0-9.]+)(.*$)", "\\1", sampMsg)
gsub("(^.*\\w*[a-zA-Z0-9]+@)([a-zA-Z0-9]+\\.[a-zA-Z0-9.]+)(.*$)", "\\2", sampMsg)
gsub("(^.*\\w*[a-zA-Z0-9]+@)([a-zA-Z0-9]+\\.[a-zA-Z0-9.]+)(.*$)", "\\3", sampMsg)

# rev()
compA
rev(compA)

```
  
Below is some sample code showing examples for the apply statements:  
```{r}
# lapply
args(lapply)
lapply(1:5, FUN=sqrt)
lapply(1:5, FUN=function(x, y=2) { c(x=x, y=y, pow=x^y) }, y=3)
lapply(1:5, FUN=function(x, y=2) { if (x <= 3) {c(x=x, y=y, pow=x^y) } else { c(pow=x^y) } }, y=3)

# sapply (defaults to returning a named vector/array if possible; is lapply otherwise)
args(sapply)
args(simplify2array)
sapply(1:5, FUN=sqrt)
sapply(1:5, FUN=function(x, y=2) { c(x=x, y=y, pow=x^y) }, y=3)
sapply(1:5, FUN=function(x, y=2) { if (x <= 3) {c(x=x, y=y, pow=x^y) } else { c(pow=x^y) } }, y=3)

# vapply (tells sapply exactly what should be returned; errors out otherwise)
args(vapply)
vapply(1:5, FUN=sqrt, FUN.VALUE=numeric(1))
vapply(1:5, FUN=function(x, y=2) { c(x=x, y=y, pow=x^y) }, FUN.VALUE=numeric(3), y=3)

```
  
Below is some sample code for handing dates and times in R:  
```{r}
Sys.Date()
Sys.time()
args(strptime)

rightNow <- as.POSIXct(Sys.time())
format(rightNow, "%Y**%M-%d %H hours and %M minutes", usetz=TRUE)

lastChristmasNoon <- as.POSIXct("2015-12-25 12:00:00", format="%Y-%m-%d %X")
rightNow - lastChristmasNoon

nextUMHomeGame <- as.POSIXct("16/SEP/3 12:00:00", format="%y/%b/%d %H:%M:%S", tz="America/Detroit")
nextUMHomeGame - rightNow

# Time zones available in R
OlsonNames()

# From ?strptime (excerpted)
#
# ** General formats **
# %c Date and time. Locale-specific on output, "%a %b %e %H:%M:%S %Y" on input.
# %F Equivalent to %Y-%m-%d (the ISO 8601 date format).
# %T Equivalent to %H:%M:%S.
# %D Date format such as %m/%d/%y: the C99 standard says it should be that exact format
# %x Date. Locale-specific on output, "%y/%m/%d" on input.
# %X Time. Locale-specific on output, "%H:%M:%S" on input.
# 
# ** Key Components **
# %y Year without century (00-99). On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19
# %Y Year with century
# %m Month as decimal number (01-12).
# %b Abbreviated month name in the current locale on this platform.
# %B Full month name in the current locale.
# %d Day of the month as decimal number (01-31).
# %e Day of the month as decimal number (1-31), with a leading space for a single-digit number.
# %a Abbreviated weekday name in the current locale on this platform.
# %A Full weekday name in the current locale.
# %H Hours as decimal number (00-23)
# %I Hours as decimal number (01-12)
# %M Minute as decimal number (00-59).
# %S Second as integer (00-61), allowing for up to two leap-seconds (but POSIX-compliant implementations will ignore leap seconds).
# 
# ** Additional Options **
# %C Century (00-99): the integer part of the year divided by 100.
# 
# %g The last two digits of the week-based year (see %V). (Accepted but ignored on input.)
# %G The week-based year (see %V) as a decimal number. (Accepted but ignored on input.)
# 
# %h Equivalent to %b.
# 
# %j Day of year as decimal number (001-366).
# 
# %n Newline on output, arbitrary whitespace on input.
# 
# %p AM/PM indicator in the locale. Used in conjunction with %I and not with %H. An empty string in some locales (and the behaviour is undefined if used for input in such a locale).  Some platforms accept %P for output, which uses a lower-case version: others will output P.
# 
# %r The 12-hour clock time (using the locale's AM or PM). Only defined in some locales.
# 
# %R Equivalent to %H:%M.
# 
# %t Tab on output, arbitrary whitespace on input.
# 
# %u Weekday as a decimal number (1-7, Monday is 1).
# 
# %U Week of the year as decimal number (00-53) using Sunday as the first day 1 of the week (and typically with the first Sunday of the year as day 1 of week 1). The US convention.
# 
# %V Week of the year as decimal number (01-53) as defined in ISO 8601. If the week (starting on Monday) containing 1 January has four or more days in the new year, then it is considered week 1. Otherwise, it is the last week of the previous year, and the next week is week 1. (Accepted but ignored on input.)
# 
# %w Weekday as decimal number (0-6, Sunday is 0).
# 
# %W Week of the year as decimal number (00-53) using Monday as the first day of week (and typically with the first Monday of the year as day 1 of week 1). The UK convention.
# 
# For input, only years 0:9999 are accepted.
# 
# %z Signed offset in hours and minutes from UTC, so -0800 is 8 hours behind UTC. Values up to +1400 are accepted as from R 3.1.1: previous versions only accepted up to +1200. (Standard only for output.)
# 
# %Z (Output only.) Time zone abbreviation as a character string (empty if not available). This may not be reliable when a time zone has changed abbreviations over the years.

```
  
Additionally, code from several practice examples is added:  
```{r}
set.seed(1608221310)

me <- 89
other_199 <- round(rnorm(199, mean=75.45, sd=11.03), 0)

mean(other_199)
sd(other_199)

desMeans <- c(72.275, 76.24, 74.5, 77.695)
desSD <- c(12.31, 11.22, 12.5, 12.53)

prevData <- c(rnorm(200, mean=72.275, sd=12.31), 
              rnorm(200, mean=76.24, sd=11.22), 
              rnorm(200, mean=74.5, sd=12.5),
              rnorm(200, mean=77.695, sd=12.53) 
              )
previous_4 <- matrix(data=prevData, ncol=4)

curMeans <- apply(previous_4, 2, FUN=mean)
curSD <- apply(previous_4, 2, FUN=sd)

previous_4 <- t(apply(previous_4, 1, FUN=function(x) { desMeans + (desSD / curSD) * (x - curMeans) } ))

apply(round(previous_4, 0), 2, FUN=mean)
apply(round(previous_4, 0), 2, FUN=sd)
previous_4 <- round(previous_4, 0)


# Merge me and other_199: my_class
my_class <- c(me, other_199)

# cbind() my_class and previous_4: last_5
last_5 <- cbind(my_class, previous_4)

# Name last_5 appropriately
nms <- paste0("year_", 1:5)
colnames(last_5) <- nms


# Build histogram of my_class
hist(my_class)

# Generate summary of last_5
summary(last_5)

# Build boxplot of last_5
boxplot(last_5)


# How many grades in your class are higher than 75?
sum(my_class > 75)

# How many students in your class scored strictly higher than you?
sum(my_class > me)

# What's the proportion of grades below or equal to 64 in the last 5 years?
mean(last_5 <= 64)


# Is your grade greater than 87 and smaller than or equal to 89?
me > 87 & me <= 89

# Which grades in your class are below 60 or above 90?
my_class < 60 | my_class > 90

# What's the proportion of grades in your class that is average?
mean(my_class >= 70 & my_class <= 85)


# How many students in the last 5 years had a grade of 80 or 90?
sum(last_5 %in% c(80, 90))

# Define n_smart
n_smart <- sum(my_class >= 80)

# Code the if-else construct
if (n_smart > 50) {
    print("smart class")
} else {
    print("rather average")
}

# Define prop_less
prop_less <- mean(my_class < me)

# Code the control construct
if (prop_less > 0.9) {
    print("you're among the best 10 percent")
} else if (prop_less > 0.8) {
    print("you're among the best 20 percent")
} else {
    print("need more analysis")
}

# Embedded control structure: fix the error
if (mean(my_class) < 75) {
  if (mean(my_class) > me) {
    print("average year, but still smarter than me")
  } else {
    print("average year, but I'm not that bad")
  }
} else {
  if (mean(my_class) > me) {
    print("smart year, even smarter than me")
  } else {
    print("smart year, but I am smarter")
  }
}

# Create top_grades
top_grades <- my_class[my_class >= 85]

# Create worst_grades
worst_grades <- my_class[my_class < 65]

# Write conditional statement
if (length(top_grades) > length(worst_grades)) { print("top grades prevail") }

```
  
  
###_R Programming (Writing Functions in R)_  
Hadley and Charlotte Wickham led a course on writing functions in R.  Broadly, the course includes advice on when/how to use functions, as well as specific advice about commands available through library(purrr).  
  
Key pieces of advice include:  
  
* Write a function once you have cut and paste some code twice or more  
* Solve a simple problem before writing the function  
* A good function is both correct and understandable  
* Abstract away the for loops when possible (focus on data/actions, solve iteration more easily, have more understandable code), for example using purrr::map() or purr::map_<type>() where type can be dbl, chr, lgl, int, forcing a type-certain output  
* Use purrr::safely() and purrr::possibly() for better error handling  
* Use purr::pmap or purr::walk2 to iterate over 2+ arguments  
* Iterate functions for their side effects (printing, plotting, etc.) using purrr::walk()  
* Use stop() and stopifnot() for error catching of function arguments/output formats  
* Avoid type-inconsistent functions (e.g., sapply)  
* Avoid non-standard functions  
* Never rely on global options (e.g., how the user will have set stringsAsFactors)  
  
John Chambers gave a few useful slogans about functions:  
  
* Everything that exists is an object  
* Everything that happens is a function call  
  
Each function has three components:  
  
* formals(x) are in essence the arguments as in args(), but as a list  
* body(x) is the function code  
* environment(x) is where it was defined
  
Only the LAST evaluated expression is returned.  The use of return() is recommended only for early-returns in a special case (for example, when a break() will be called).  
  
Further, functions can be written anonymously on the command line, such as (function (x) {x + 1}) (1:5).  A function should only depend on arguments passed to it, not variables from a parent enviornment.  Every time the function is called, it receives a clean working environment.  Once it finishes, its variables are no longer available unless they were returned (either by default as the last operation, or by way of return()):  
  
```{r}
# Components of a function
args(rnorm)
formals(rnorm)
body(rnorm)
environment(rnorm)


# What is passed back
funDummy <- function(x) {
    if (x <= 2) {
        print("That is too small")
        return(3)  # This ends the function by convention
    }
    ceiling(x)  # This is the defaulted return() value if nothing happened to prevent the code getting here
}

funDummy(1)
funDummy(5)


# Anonymous functions
(function (x) {x + 1}) (1:5)

```
  
The course includes some insightful discussion of vectors.  As it happens, lists and data frames are just special collections of vectors in R.  Each column of a data frame is a vector, while each element of a list is either 1) an embedded data frame (which is eventually a vector by way of columns), 2) an embedded list (which is eventually a vector by way of recursion), or 3) an actual vector.  
  
The atomic vectors are of types logical, integer, character, and double; complex and raw are rarer types that are also available.  Lists are just recursive vectors, which is to say that lists can contain other lists and can be hetergeneous.  To explore vectors, you have:  
  
* typeof() for the type  
* length() for the length  
  
Note that NULL is the absence of a vector and has length 0.  NA is the absence of an element in the vector and has length 1.  All math operations with NA return NA; for example NA == NA will return NA.  
  
There are some good tips on extracting element from a list:  
  
* [] is to extract a sub-list  
* [[]] and $ more common and extract elements while removing an element of hierachy  
* seq_along(mtcars) will return 1:11 since there are 11 elements.  Helfpully, is applied to a frame with no columns, this returns integer(0) which means the for() loop does not crash  
* mtcars[[11]] will return the 11th element (11th column) of mtcars  
* vector("type", "length") will create a n empty vector of the requested type and length  
* range(x, na.rm=FALSE) gives vector c(xmin, xmax) which can be handy for plotting, scaling, and the like  
  
```{r}
# Data types
data(mtcars)
str(mtcars)
typeof(mtcars)  # n.b. that this is technically a "list"
length(mtcars)


# NULL and NA
length(NULL)
typeof(NULL)
length(NA)
typeof(NA)
NULL == NULL
NULL == NA
NA == NA
is.null(NULL)
is.null(NA)
is.na(NULL)
is.na(NA)


# Extraction
mtcars[["mpg"]][1:5]
mtcars[[2]][1:5]
mtcars$hp[1:5]


# Relevant lengths
seq_along(mtcars)
x <- data.frame()
seq_along(x)
length(seq_along(x))

foo <- function(x) { for (eachCol in seq_along(x)) { print(typeof(x[[eachCol]])) }}
foo(mtcars)
foo(x)  # Note that this does nothing!
data(airquality)
str(airquality)
foo(airquality)


# Range command
mpgRange <- range(mtcars$mpg)
mpgRange
mpgScale <- (mtcars$mpg - mpgRange[1]) / (mpgRange[2] - mpgRange[1])
summary(mpgScale)
```
  
The typical arguments in a function use a consistent, simple naming function:  
  
* x, y, z: vectors  
* df: data frame  
* i, j: numeric indices (generally rows and columns)  
* n: length of number of rows  
* p: number of columns  
  
Data arguments should come before detail arguments, and detail arguments should be given reasonable default values.  See for example rnorm(n, mean=0, sd=1).  The number requested (n) must be specified, but defaults are available for the details (mean and standard deviation).  
  
####_Functional Programming and library(purrr)_  
Functions can be passed as arguments to other functions, which is at the core of functional programming.  For example:  
```{r}
do_math <- function(x, fun) { fun(x) }
do_math(1:10, fun=mean)
do_math(1:10, fun=sd)
```
  
The library(purrr) takes advantage of this, and in a type-consistent manner.  There are functions for:  
  
* map() will create a list as the output  
* map_chr() will create a character vector as the output  
* map_dbl() will create a double vector as the output  
* map_int() will create an integer vector as the output  
* map_lgl() will create a logical (boolean) vector as the output  
  
The general arguments are .x (a list or an atomic vector) and .f which can be either a function, an anonymous function (formula with ~), or an extractor .x[[.f]].  For example:  
```{r}
library(purrr)
library(RColorBrewer)  # Need to have in non-cached chunk for later

data(mtcars)

# Create output as a list
map(.x=mtcars, .f=sum)

# Create same output as a double
map_dbl(.x=mtcars, .f=sum)

# Create same output as integer
# map_int(.x=mtcars, .f=sum) . . . this would bomb since it is not actually an integere
map_int(.x=mtcars, .f=function(x) { as.integer(round(sum(x), 0)) } )

# Same thing but using an anonymous function with ~ and .
map_int(.x=mtcars, .f = ~ as.integer(round(sum(.), 0)) )

# Create a boolean vector
map_lgl(.x=mtcars, .f = ~ ifelse(sum(.) > 200, TRUE, FALSE) )

# Create a character vector
map_chr(.x=mtcars, .f = ~ ifelse(sum(.) > 200, "Large", "Not So Large") )

# Use the extractor [pulls the first row]
map_dbl(.x=mtcars, .f=1)

# Example from help file using chaining
mtcars %>%
  split(.$cyl) %>%
  map(~ lm(mpg ~ wt, data = .x)) %>%
  map(summary) %>%
  map_dbl("r.squared")

# Using sapply
sapply(split(mtcars, mtcars$cyl), FUN=function(.x) { summary(lm(mpg ~ wt, data=.x))$r.squared } )

# Use the extractor from a list
cylSplit <- split(mtcars, mtcars$cyl)
map(cylSplit, "mpg")
map(cylSplit, "cyl")
```
  
The purrr library has several additional interesting functions:  
  
* safely() is a wrapper for any functions that traps the errors and returns a relevant list  
* possibly() is similar to safely() with the exception that a default value for error cases is supplied  
* quietly() is a wrapper to suppress verbosity  
* transpose() reverses the order of lists (making the inner-most lists the outer-most lists), which is an easy way to extract either all the answers or all the error cases  
* map2(.x, .y, .f) allows two inputs to be passed to map()  
* pmap(.l, .f) allows passing a named list with as many inputs as needed to function .f  
* invoke_map(.f, .x, ...) lets you iterate over a list of functions .f  
* walk() is like map() but called solely to get function side effects (plot, save, etc.); it also returns the object that is passed to it, which can be convenient for chaining (piping)  
  
Some example code includes:  
```{r}
library(purrr)  # Called again for clarity; all these key functions belong to purrr

# safely(.f, otherwise = NULL, quiet = TRUE)
safe_log10 <- safely(log10)
map(list(0, 1, 10, "a"), .f=safe_log10)

# possibly(.f, otherwise, quiet = TRUE)
poss_log10 <- possibly(log10, otherwise=NaN)
map_dbl(list(0, 1, 10, "a"), .f=poss_log10)

# transpose() - note that this can become masked by data.table::transpose() so be careful
purrr::transpose(map(list(0, 1, 10, "a"), .f=safe_log10))
purrr::transpose(map(list(0, 1, 10, "a"), .f=safe_log10))$result
unlist(purrr::transpose(map(list(0, 1, 10, "a"), .f=safe_log10))$result)
purrr::transpose(map(list(0, 1, 10, "a"), .f=safe_log10))$error
map_lgl(purrr::transpose(map(list(0, 1, 10, "a"), .f=safe_log10))$error, is.null)

# map2(.x, .y, .f)
map2(list(5, 10, 20), list(1, 2, 3), .f=rnorm) # rnorm(5, 1), rnorm(10, 2), and rnorm(20, 3)

# pmap(.l, .f)
pmap(list(n=list(5, 10, 20), mean=list(1, 5, 10), sd=list(0.1, 0.5, 0.1)), rnorm)

# invoke_map(.f, .x, ...)
invoke_map(list(rnorm, runif, rexp), n=5)

# walk() is for the side effects of a function
x <- list(1, "\n\ta\n", 3)
x %>% walk(cat)

# Chaining is available by way of the %>% operator
pretty_titles <- c("N(0, 1)", "Uniform(0, 1)", "Exponential (rate=1)")
set.seed(1607120947)
x <- invoke_map(list(rnorm, runif, rexp), n=5000)
foo <- function(x) { map(x, .f=summary) }
par(mfrow=c(1, 3))
pwalk(list(x=x, main=pretty_titles), .f=hist, xlab="", col="light blue") %>% map(.f=foo)
par(mfrow=c(1, 1))

```
  
####_Writing Robust Functions_  
There are two potentially desirable behaviors with functions:  
  
* Relaxed (default R approach) - make reasonable guesses about what you mean, which is particularly useful for interactive analyses  
* Robust (programming) - strict functions that throw errors rather than guessing in light of uncertainty  
  
As a best practice, R functions that will be used for programming (as opposed to interactive command line work) should be written in a robust manner.  Three standard problems should be avoided/mitigated:  
  
* Type-unstable - may return a vector one time, and a list the next  
* Non-standard evaluation - can use succinct API, but can introduce ambiguity  
* Hidden arguments - dependence on global functions/environments  
  
There are several methods available for throwing errors within an R function:  
  
* stopifnot(expression) will stop and throw an error unless expression is TRUE  
* if (expression) { stop("Error", call.=FALSE) }  
* if (expression) { stop(" 'x' should be a character vector", call.=FALSE) }  
    * call.=FALSE means that the call to the function should not be shown (???) - Hadley recommends this  
  
One example that commonly creates surprises is the [,] operator for extraction.  Adding [ , , drop=FALSE] ensures that you will still have what you passed (e.g., a matrix or data frame) rather than conversion of a chunk of data to a vector.

Another common source of error is sapply() which will return a vector when it can and a list otherwise.  The map() and map_typ() functions in purrr are designed to be type-stable; if the output is not as expected, they will error out.  
  
Non-standard evaluations take advantage of the existence of something else (e.g., a variable in the parent environment that has not been passed).  This can cause confusion and improper results.  
  
* subset(mtcars, disp > 400) takes advantage of disp being an element of mtcars; disp would crash if called outside subset  
* This can cause problems when it is embedded inside a function  
* ggplot and dplyr frequently have these behaviors also  
    * The risk is that you can also put variables from the global environment in to the same call  
  
Pure functions have the key properties that 1) their output depends only on their inputs, and 2) they do not impact the outside world other than by way of their return value.  Specifically, the function should not depend on how the user has configured their global options as shown in options(), nor should it modify those options() settings upon return of control to the parent environment.  
  
A few examples are shown below:  
```{r}
# Throwing errors to stop a function (cannot actually run these!)
# stopifnot(FALSE)
# if (FALSE) { stop("Error: ", call.=FALSE) }
# if (FALSE) { stop("Error: This condition needed to be set as TRUE", call.=FALSE) }

# Behavior of [,] and [,,drop=FALSE]
mtxTest <- matrix(data=1:9, nrow=3, byrow=TRUE)
class(mtxTest)
mtxTest[1, ]
class(mtxTest[1, ])
mtxTest[1, , drop=FALSE]
class(mtxTest[1, , drop=FALSE])

# Behavior of sapply() - may not get what you are expecting
foo <- function(x) { x^2 }
sapply(1:5, FUN=foo)
class(sapply(1:5, FUN=foo))
sapply(c(1, list(1.5, 2, 2.5), 3, 4, 5), FUN=foo)
class(sapply(c(1, list(1.5, 2, 2.5), 3, 4, 5), FUN=foo))
sapply(list(1, c(1.5, 2, 2.5), 3, 4, 5), FUN=foo)
class(sapply(list(1, c(1.5, 2, 2.5), 3, 4, 5), FUN=foo))

```
  
This was a very enjoyable and instructive course.  
  
  
###_Object Oriented Programming (OOP) in R: S3 and R6_  

Chapter 1 - Introduction to Object Oriented Programming (OOP)

Typical R usage involves a functional programming style - data to function to new data to new function to newer values and etc.
Object Oriented Programming (OOP) instead involves thinking about the data structures (objects), their functionalities, and the like:  
  
* A method is just a function, talked about in an OOP context  
* There are ~20 objects available in R; of particular interest are 1) lists and 2) environments  
* Frequently, OOP is neither desirable nor necessary for data analysis; you actually prefer the functional programming style  
* OOP is often better when you have a limited number of objects and you understand their behavior very well (e.g., industry SME such as Bioconductor)  
    * An example would be the genomic range object  
* OOP can also be better for areas like API where there are limited numbers of responses and they can be stored accordingly  
* OOP can also be better for areas like GUI, as there tend to be just a small number of objects (buttons, drop-downs, and the like)  
* In a nutshell, OOP is great for tool-building, while functional programming is best for data analysis  
  
There are nine different options for OOP in R:  
  
* No need to learn these five (5): R.oo (never really took off), OOP (defunct and no longer available), R5 (experimental and abandoned), mutatr (experimental and banadoned), proto (used early in ggplot2 but mostly deprecated now)  
* S3 (fundamental R skill) - around since the 1980s; mature and widely used; a very simple system that implements functions being able to work differently on different objects; one-trick pony, but "it's a great trick"  
* S4 has been around since S version 4, mostly "a little weird and not necessarily recommended to learn as a first choice"; caveated that Bioconductor is a big user of S4  
* ReferenceClasses is an attempt to behave similarly to Java, C# and the like - encapsulation and inheritance and the like  
* R6 covers much of the same ground as ReferenceClasses, but in a much simpler manner  
* Gist is to 1) use S3 regularly, and 2) use R6 when you need higher power and/or functionality than S3  
  
How does R distinguish types of variables?  
  
* Generally, class() is sufficient to interrogate the type of a variable  
* If class() returns "matrix" then it may be helpful to know what the matrix contains; typeof() will distinguish that it is "integer" or "double" or "character" or the like  
    * The typeof() query and result can be particularly important in S3  
* The functions mode() and storage.mode() exist for compatability with older versions of S; should know they exist but no need to use them per se  
  
Assigning Classes and Implicit Classes:  
  
* The class can be reassigned, for example with class(x) <- "random_numbers"  
* While class() can be overridden, typeof() cannot; typeof(x) will be the same even if class(x) has been reassigned  
* If typeof(x) is "double" then x would be said to have an implicit class of "numeric"  
    * And, as such, is.numeric(x) will still return TRUE  
    * Additionally, length(x) and mean(x) and the like will still work properly, treating x as the numeric that it is  
  
Example code includes:  
```{r}

# Create these variables
a_numeric_vector <- rlnorm(50)
a_factor <- factor(
  sample(c(LETTERS[1:5], NA), 50, replace = TRUE)
)
a_data_frame <- data.frame(
  n = a_numeric_vector,
  f = a_factor
)
a_linear_model <- lm(dist ~ speed, cars)

# Call summary() on the numeric vector
summary(a_numeric_vector)

# Do the same for the other three objects
summary(a_factor)
summary(a_data_frame)
summary(a_linear_model)


type_info <- 
function(x)
{
  c(
    class = class(x), 
    typeof = typeof(x), 
    mode = mode(x), 
    storage.mode = storage.mode(x)
  )
}

# Create list of example variables
some_vars <- list(
  an_integer_vector = rpois(24, lambda = 5),
  a_numeric_vector = rbeta(24, shape1 = 1, shape2 = 1),
  an_integer_array = array(rbinom(24, size = 8, prob = 0.5), dim = c(2, 3, 4)),
  a_numeric_array = array(rweibull(24, shape = 1, scale = 1), dim = c(2, 3, 4)),
  a_data_frame = data.frame(int = rgeom(24, prob = 0.5), num = runif(24)),
  a_factor = factor(month.abb),
  a_formula = y ~ x,
  a_closure_function = mean,
  a_builtin_function = length,
  a_special_function = `if`
)

# Loop over some_vars calling type_info() on each element to explore them
lapply(some_vars, FUN=type_info)

whiteChess <- list(king="g1", queen="h4", bishops=c("c2", "g5"), knights=character(0), rooks=c("f1", "f6"), pawns=c("a2", "b2", "d4", "e3", "g2", "h2"))
blackChess <- list(king="g8", queen="d7", bishops=c("b7", "e7"), knights=character(0), rooks=c("a6", "f8"), pawns=c("a5", "c3", "c4", "d5", "f7", "g6"))
chess <- list(white=whiteChess, black=blackChess)

# Explore the structure of chess
str(chess)

# Override the class of chess
class(chess) <- "chess_game"

# Is chess still a list?
is.list(chess)

# How many pieces are left on the board?
length(unlist(chess))

type_info(chess)  # note that typeof(), mode(), and storage.mode() all remained as list

```
  
Chapter 2 - Using S3

Function overloading is the property of a function of input-dependent behavior:  
  
* The primary purpose is to make coding easier - otherwise, there would need to be many more functions  
* The S3 system exists to make this simpler; specifically, S3 splits a function in to "generic" and "method"  
* Methods always need to be named as generic.class; for example, print.Date or summary.factor or unique.array; the generic.default can be used as the default for all other cases  
    * The generic function will then call UseMethod("<thisGeneric>")  
* The method signatures contain the generic signatures (everything the method needs can be passed by the generic)  
* Arguments can be passed between methods using the ellipsis ( . ); best practice is to include this in both the generic and the method  
* Due to the feature of using generic.Method to call the various functions, naming functions with dots in them is bad practice (known as "lower.leopard.case" and is a bad idea to use)  
	* Preferable is lower_snake_case or lowerCamelCase  
* Can be tested using pryr::is_s3_generic() and pryr::is_s3_method()  
  
Methodical Thinking - determining which methods are available for an S3 generic:  
  
* Can pass the string quoted or not - methods("mean") and methods(mean) will both return the methods of mean  
* Alternately, methods(class = "glm") or methods(class = glm) will show all the generics that have a method for "glm"  
    * This is more generous than just S3; will return both the S3 methods and the S4 methods  
    * For ONLY the S3 methods, use .S3methods(class = "glm")  
    * For ONLY the S4 methods, use .S4methods(class = "glm")  
* Generally, the methods() command is the best to use  
  
S3 and Primitive Functions:  
  
* Most of the time for an R user is typically spent on writing, debugging, and maintaining code; as such, these tasks are often optimized by R  
* However, sometimes the time need to run the code is vital; these functions are typically written in C rather than R  
	* The trade-off is that C code is typically harder to write and also harder to debug  
    * R has several interfaces to the C language  
* Primitive - direct access through a few fundamental features reserved in base R (a function that uses this access is called a "Primitive Function" and will be .Primitive("<command>"))  
    * .S3PrimitiveGenerics will list all of the S3 generic functions with primitive access to C  
    * The primitive generic will have C go directly to the "typeof" without worrying about what class the user may have created; other generics will bomb out if the class cannot be handled  
  
Too Much Class:  
  
* A variable may be a member of more than one class (common with things that are tbl_df and data.frame at the same time)  
* Generally, the most specific class should be listed first with the more generic classes listed last; good practice is to keep the original class at the end of the string  
* The inherits() function is a nice way to see whether something belongs to a class - for example, inherits(x, "numeric") will be TRUE is x can use the generic.numeric functions  
    * Generally, this is slower than using a specific function such as is.numeric(x), so the advice is to use the specific functions as and when they are available  
* The NextMethod("function") in a generic.method will call the next class to be acted on; can only be used if there are additional classes to be acted on (???)  
  
Example code includes:  
```{r}

# Create get_n_elements
get_n_elements <- function(x, ...) {
  UseMethod("get_n_elements")
}

# View get_n_elements
get_n_elements

# Create a data.frame method for get_n_elements
get_n_elements.data.frame <- function(x, ...) {
  nrow(x) * ncol(x)
}

# Call the method on the sleep dataset
n_elements_sleep <- get_n_elements(sleep)

# View the result
n_elements_sleep

# View pre-defined objects
# ls.str()  ## Do not run, this can be a cluster with many variables loaded . . . 

# Create a default method for get_n_elements
get_n_elements.default <- function(x, ...) {
  length(unlist(x))
}

# Call the method on the ability.cov dataset
n_elements_ability.cov <- get_n_elements(ability.cov)


# Find methods for print
methods("print")

# Commented due to no dataset "hair" on my machine
# View the structure of hair
# str(hair)

# What primitive generics are available?
.S3PrimitiveGenerics

# Does length.hairstylist exist?
# exists("length.hairstylist")

# What is the length of hair?
# length(hair)


kitty <- "Miaow!"

# Assign classes
class(kitty) <- c("cat", "mammal", "character")

# Does kitty inherit from cat/mammal/character vector?
inherits(kitty, "cat")
inherits(kitty, "mammal")
inherits(kitty, "character")

# Is kitty a character vector?
is.character(kitty)

# Does kitty inherit from dog?
inherits(kitty, "dog")


what_am_i <-
function(x, ...)
{
  UseMethod("what_am_i")
}

# cat method
what_am_i.cat <- function(x, ...)
{
  # Write a message
  print("I'm a cat")
  # Call NextMethod
  NextMethod("what_am_i")
}

# mammal method
what_am_i.mammal <- function(x, ...)
{
  # Write a message
  print("I'm a mammal")
  # Call NextMethod
  NextMethod("what_am_i")
}

# character method
what_am_i.character <- function(x, ...)
{
  # Write a message
  print("I'm a character vector")
}

# Call what_am_i()
what_am_i(kitty)


```
  
Chapter 3 - Using R6

Object factory - R6 provides a means of storing data and objects within the same variable:  
  
* First step is to create a "class generator" (template for objects) defining what can be stored in it and what actions can be applied to it  
	* Can also be referred to as the "factory"; it can create the objects  
* Factories are defined using R6::R6Class("<ClassInUpperCamelCase>", private=list(<the object's data, must be a named list>), public=<tbd>, active=<tbd>)  
* The $new() method of the defined factory will create a new object based on the factory's pre-defined elements  
  
Hiding Complexity with Encapsulation - should be able to use something even if the internal (hidden) functionality is very complicated:  
  
* The term "encapsulation" means separating the implementation from the user interface  
* Generally, the encapsulation for R6 is contained in the private=list() aspect of the factory  
* The user-interface data for R6 is contained in the public=list() aspect of the factory; each aspect of this list would typically be a function  
    * The function might access field in the private list, using private$<variable> to achieve this  
    * The function might access fields in the public list, using self$<variable> to achieve this  
  
Generally, data available in the "private" area of a class is not available to users:  
  
* From time to time, you may want to grant "controlled access" to this "private" data -- "getting" (OOP for reading) the data or "setting" (OOP for writing) the data  
* R6 achieves this through "Active Bindings"; these are defined like functions, but accessed like data variables  
* The "active bindings" are added to the active=list() component of an R6::R6Class()  
* R6 requires that different names be used throughout; a common best practice is for all "private" variables to start with two periods (..)  
* By convention, "setting" is a function that takes a single argument named "value"  
  
Example code includes:  
```{r}

# Define microwave_oven_factory
microwave_oven_factory <- R6::R6Class(
  "MicrowaveOven",
  private=list(power_rating_watts=800)
)

# View the microwave_oven_factory
microwave_oven_factory

# Make a new microwave oven
microwave_oven <- microwave_oven_factory$new()


# Add a cook method to the factory definition
microwave_oven_factory <- R6::R6Class(
  "MicrowaveOven",
  private = list(
    power_rating_watts = 800
  ),
  public = list(
    cook = function(time_seconds) {
      Sys.sleep(time_seconds)
      print("Your food is cooked!")
    }
  )
)

# Create microwave oven object
a_microwave_oven <- microwave_oven_factory$new()

# Call cook method for 1 second
a_microwave_oven$cook(time_seconds=1)


# Add a close_door() method
microwave_oven_factory <- R6::R6Class(
  "MicrowaveOven",
  private = list(
    power_rating_watts = 800,
    door_is_open = FALSE
  ),
  public = list(
    cook = function(time_seconds) {
      Sys.sleep(time_seconds)
      print("Your food is cooked!")
    },
    open_door = function() {
      private$door_is_open = TRUE
    },
    close_door = function() {
      private$door_is_open = FALSE
    }
  )
)


# Add an initialize method
microwave_oven_factory <- R6::R6Class(
  "MicrowaveOven",
  private = list(
    power_rating_watts = 800,
    door_is_open = FALSE
  ),
  public = list(
    cook = function(time_seconds) {
      Sys.sleep(time_seconds)
      print("Your food is cooked!")
    },
    open_door = function() {
      private$door_is_open = TRUE
    },
    close_door = function() {
      private$door_is_open = FALSE
    },
    # Add initialize() method here
    initialize = function(power_rating_watts, door_is_open) {
      if (!missing(power_rating_watts)) {
        private$power_rating_watts <- power_rating_watts
      }
      if (!missing(door_is_open)) {
        private$door_is_open <- door_is_open
      }
    }
  )
)

# Make a microwave
a_microwave_oven <- microwave_oven_factory$new(power_rating_watts=650, door_is_open=TRUE)


# Add a binding for power rating
microwave_oven_factory <- R6::R6Class(
  "MicrowaveOven",
  private = list(
    ..power_rating_watts = 800
  ),
  active = list(
    # add the binding here
    power_rating_watts = function() {
      private$..power_rating_watts
    }

  )
)

# Make a microwave 
a_microwave_oven <- microwave_oven_factory$new()

# Get the power rating
a_microwave_oven$power_rating_watts


# Add a binding for power rating
microwave_oven_factory <- R6::R6Class(
  "MicrowaveOven",
  private = list(
    ..power_rating_watts = 800,
    ..power_level_watts = 800
  ),
  # Add active list containing an active binding
  active=list(
    power_level_watts = function(value) {
      if (missing(value)) {
        private$..power_level_watts
      } else {
        assertive.types::assert_is_a_number(value, severity="warning")
        assertive.numbers::assert_all_are_in_closed_range(value, 
                                                          lower=0, 
                                                          upper=private$..power_rating_watts, 
                                                          severity="warning"
                                                          )
        private$..power_level_watts <- value
      }
    }
  )
)

# Make a microwave 
a_microwave_oven <- microwave_oven_factory$new()

# Get the power level
a_microwave_oven$power_level_watts

# Try to set the power level to "400"
a_microwave_oven$power_level_watts <- "400"

# Try to set the power level to 1600 watts
a_microwave_oven$power_level_watts <- 1600

# Set the power level to 400 watts
a_microwave_oven$power_level_watts <- 400


```
  
  
Chapter 4 - R6 Inheritance

Inheritance is an attempt to avoid "copy and paste" from one class to another (dependent, fancier, or the like) class:  
  
* "Parent" is the class that you inherit from  
* "Children" are the classes that inherit from you  
* Setting inherit=<myParent> inside R6::R6Class() will send over all the private, public, and active from the parent  
    * You can still add public functions and the like  
* Inheritance works only in one direction - children take from parents, not the other way around  
* The class() argument will be both the "parent" class and the "child" class  
  	
Extend or Override to create additional functionality:  
  
* To override functionality, you define things with the same name as they have in the parent  
* To extend functionality, you define new variables and functions, which will only be available in the child class  
* The prefixes allow for access to elements from the parent, even when those have been overridden  
    * private$ accesses private fields  
    * self$ accesses public methods in self  
    * super$ accesses public methods in parent  
  
Multiple Levels of Inheritance - a can inherit from b that inherited from c and the like:  
  
* By default, R6 classes only have access to their direct parent (no use of super$super$ or the like to get at the grandparent)  
* This can be addressed by an active binding in the child - active=list(super_ = function() super ) # defaults to be named _super since super is a reserved word  
* So, the call would become super$super_$<grandparentAccess>  
  
Example code includes:  
```{r}

microwave_oven_factory <- 
    R6::R6Class("MicrowaveOven", 
                private=list(..power_rating_watts=800, 
                             ..power_level_watts=800, 
                             ..door_is_open=FALSE
                             ), 
                public=list(cook=function(time) Sys.sleep(time), 
                            open_door=function() private$..door_is_open <- TRUE, 
                            close_door = function() private$..door_is_open <- FALSE
                            ),
                active=list(power_rating_watts=function() private$..power_rating_watts, 
                            power_level_watts = function(value) { 
                                if (missing(value)) { 
                                    private$..power_level_watts 
                                    } else { 
                                        private$..power_level_watts <- 
                                            max(0, 
                                                min(private$..power_rating_watts, 
                                                    as.numeric(value)
                                                    )
                                                ) 
                                    }
                                }
                            )
                )

# Explore the microwave oven class
microwave_oven_factory

# Define a fancy microwave class inheriting from microwave oven
fancy_microwave_oven_factory <- R6::R6Class(
  "FancyMicrowaveOven", 
  inherit=microwave_oven_factory
)


# Explore microwave oven classes
microwave_oven_factory
fancy_microwave_oven_factory

# Instantiate both types of microwave
a_microwave_oven <- microwave_oven_factory$new()
a_fancy_microwave <- fancy_microwave_oven_factory$new()

# Get power rating for each microwave
microwave_power_rating <- a_microwave_oven$power_level_watts
fancy_microwave_power_rating <- a_fancy_microwave$power_level_watts

# Verify that these are the same
identical(microwave_power_rating, fancy_microwave_power_rating)

# Cook with each microwave
a_microwave_oven$cook(1)
a_fancy_microwave$cook(1)

# Explore microwave oven class
microwave_oven_factory

# Extend the class definition
fancy_microwave_oven_factory <- R6::R6Class(
  "FancyMicrowaveOven",
  inherit = microwave_oven_factory,
  # Add a public list with a cook baked potato method
  public = list(
    cook_baked_potato=function() {
      self$cook(3)
    }
  )
)

# Instantiate a fancy microwave
a_fancy_microwave <- fancy_microwave_oven_factory$new()

# Call the cook_baked_potato() method
a_fancy_microwave$cook_baked_potato()


# Explore microwave oven class
microwave_oven_factory

# Update the class definition
fancy_microwave_oven_factory <- R6::R6Class(
  "FancyMicrowaveOven",
  inherit = microwave_oven_factory,
  # Add a public list with a cook method
  public = list(
    cook = function(time_seconds) {
      super$cook(time_seconds)
      message("Enjoy your dinner!")
    }
  )
  
)

# Instantiate a fancy microwave
a_fancy_microwave <- fancy_microwave_oven_factory$new()

# Call the cook() method
a_fancy_microwave$cook(1)


# Expose the parent functionality
fancy_microwave_oven_factory <- R6::R6Class(
  "FancyMicrowaveOven",
  inherit = microwave_oven_factory,
  public = list(
    cook_baked_potato = function() {
      self$cook(3)
    },
    cook = function(time_seconds) {
      super$cook(time_seconds)
      message("Enjoy your dinner!")
    }
  ),
  # Add an active element with a super_ binding
  active = list(
    super_ = function() super
  )
)

# Instantiate a fancy microwave
a_fancy_microwave <- fancy_microwave_oven_factory$new()

# Call the super_ binding
a_fancy_microwave$super_


ascii_pizza_slice <- "   __\n // \"\"--.._\n||  (_)  _ \"-._\n||    _ (_)    '-.\n||   (_)   __..-'\n \\\\__..--\"\""


# Explore other microwaves
microwave_oven_factory
fancy_microwave_oven_factory

# Define a high-end microwave oven class
high_end_microwave_oven_factory <- R6::R6Class(
  "HighEndMicrowaveOven", 
  inherit=fancy_microwave_oven_factory,
  public=list(
    cook=function(time_seconds) {
      super$super_$cook(time_seconds)
      message(ascii_pizza_slice)
    }
  )
)

# Instantiate a high-end microwave oven
a_high_end_microwave <- high_end_microwave_oven_factory$new()

# Use it to cook for one second
a_high_end_microwave$cook(1)


```
  
  
Chapter 5 - Advanced R6 Usage

Environments, Reference Behavior, and Static Fields:  
  
* New environments can be called using the new.env()  # environments are always created empty  
* Adding elements to an environment is very similar in syntax to adding elements to a list  # The ls.str() is the best way to look at these  
* One large behavioral change is that if environment A is copied to environment B, then changes made in environment A will be reflected in environment B  
* R typically uses "copy by value", where environment use "copy by reference"  
* The R6 class can take advantage of the "copying by reference", specifically by adding a shared={} to the private list of the environment  
    * e <- new.env()  
    * assign any variables that you like to e in later lines  
    * e # just a return of the environment  
* The fields can then be accessed through an active binding, using private$shared$ # can either retrieve the value or modify the value this way  
  
Cloning Objects - R6 is built using environments, so the "copy by reference" is part and parcel of R6:  
  
* The clone() method in R6 will instead copy by value  
* So, if you set a_clone <- a_thing$clone(), a_clone will be a "copy by value" (and specifically not a "copy by reference") of a_thing  
    * There is also an argument deep=TRUE that can be inside clone(), which will make sure "copy by value" applies to all elements inside the class  
  
Shut it Down - if the R6 object is linked to any databases or has any side effects, it can be a good idea to shut it down:  
  
* Counterpart to initialize() is finalize(), which are the actions to take when the R6 object is detsroyed  
* The rm() function does not always make the finalize() happen; rather, it will occur during garbage collection  
* To force R to run the garbage collection, you can request the gc() at the command line  
  
Example code includes:  
```{r}

# Define a new environment
env <- new.env()
  
# Add an element named perfect
env$perfect <- c(6, 28, 496)

# Add an element named bases
env[["bases"]] <- c("A", "C", "G", "T")


# Assign lst and env
lst <- list(
  perfect = c(6, 28, 496),
  bases = c("A", "C", "G", "T")
)
env <- list2env(lst)

# Copy lst
lst2 <- lst
  
# Change lst's bases element
lst$bases <- c("A", "C", "G", "U")
  
# Test lst and lst2 identical
identical(lst$bases, lst2$bases)
  
# Copy env
env2 <- env
  
# Change env's bases element
env$bases <- c("A", "C", "G", "U")
  
# Test env and env2 identical
identical(env$bases, env2$bases)


# Complete the class definition
env_microwave_oven_factory <- R6::R6Class(
  "MicrowaveOven",
  private = list(
    shared = {
      # Create a new environment named e
      e <- new.env()
      # Assign safety_warning into e
      e$safety_warning <- "Warning. Do not try to cook metal objects."
      # Return e
      e
    }
  ),
  active = list(
    # Add the safety_warning binding
    safety_warning = function(value) {
      if (missing(value)) {
        private$shared$safety_warning
      } else {
        private$shared$safety_warning <- value
      }
    }
  )
)

# Create two microwave ovens
a_microwave_oven <- env_microwave_oven_factory$new()
another_microwave_oven <- env_microwave_oven_factory$new()
  
# Change the safety warning for a_microwave_oven
a_microwave_oven$safety_warning <- "Warning. If the food is too hot you may scald yourself."
  
# Verify that the warning has change for another_microwave
another_microwave_oven$safety_warning


# Still uses microwave_oven_factory as defined in Chapter 4
# Create a microwave oven
a_microwave_oven <- microwave_oven_factory$new()

# Copy a_microwave_oven using <-
assigned_microwave_oven <- a_microwave_oven
  
# Copy a_microwave_oven using clone()
cloned_microwave_oven <- a_microwave_oven$clone()
  
# Change a_microwave_oven's power level  
a_microwave_oven$power_level_watts <- 400
  
# Check a_microwave_oven & assigned_microwave_oven same 
identical(a_microwave_oven$power_level_watts, assigned_microwave_oven$power_level_watts)

# Check a_microwave_oven & cloned_microwave_oven different 
!identical(a_microwave_oven$power_level_watts, cloned_microwave_oven$power_level_watts)  


# Commented, due to never defined power_plug  
# Create a microwave oven
# a_microwave_oven <- microwave_oven_factory$new()

# Look at its power plug
# a_microwave_oven$power_plug

# Copy a_microwave_oven using clone(), no args
# cloned_microwave_oven <- a_microwave_oven$clone()
  
# Copy a_microwave_oven using clone(), deep = TRUE
# deep_cloned_microwave_oven <- a_microwave_oven$clone(deep=TRUE)
  
# Change a_microwave_oven's power plug type  
# a_microwave_oven$power_plug$type <- "British"
  
# Check a_microwave_oven & cloned_microwave_oven same 
# identical(a_microwave_oven$power_plug$type, cloned_microwave_oven$power_plug$type)

# Check a_microwave_oven & deep_cloned_microwave_oven different 
# !identical(a_microwave_oven$power_plug$type, deep_cloned_microwave_oven$power_plug$type)  


# Commented due to not having this SQL database
# Microwave_factory is pre-defined
# microwave_oven_factory

# Complete the class definition
# smart_microwave_oven_factory <- R6::R6Class(
#   "SmartMicrowaveOven",
#   inherit = microwave_oven_factory, # Specify inheritance
#   private = list(
#     conn = NULL
#   ),
#   public = list(
#     initialize = function() {
#       # Connect to the database
#       private$conn = dbConnect(SQLite(), "cooking-times.sqlite")
#     },
#     get_cooking_time = function(food) {
#       dbGetQuery(
#         private$conn,
#         sprintf("SELECT time_seconds FROM cooking_times WHERE food = '%s'", food)
#       )
#     },
#     finalize = function() {
#       message("Disconnecting from the cooking times database.")
#       dbDisconnect(private$conn)
#     }
#   )
# )

# Create a smart microwave object
# a_smart_microwave <- smart_microwave_oven_factory$new()
  
# Call the get_cooking_time() method
# a_smart_microwave$get_cooking_time("soup")

# Remove the smart microwave
# rm(a_smart_microwave)

# Force garbage collection
# gc()


```
  
A nice introduction to S3 and R6.
  
## Data Manipulation (dplyr, data.table, xts/zoo)  
###_Data Manipulation (dplyr)_  
The library(dplyr) is a grammar of data manipulation.  It is written in C++ so you get the speed of C with the convenience of R.  It is in essence the data frame to data frame portion of plyr (plyr was the original Split-Apply-Combine).  May want to look in to count, transmute, and other verbs added post this summary.  
  
The examples use data(hflights) from library(hflights):  
```{r}
library(dplyr)
library(hflights)
data(hflights)
head(hflights)
summary(hflights)
```
  
The "tbl" is a special type of data frame, which is very helpful for printing:  
  
* tbl_df(myFrame)  # can store or whatever - will be a tbl_df, tbl, and data.frame  
    * Display is modified to fit the window display - will scale with the window  
* glimpse(myFrame) # lets you see al the variables and first few records for each (sort of like str)  
* as.data.frame(tbl_df(myFrame)) # this will be the data frame  
    * identical(as.data.frame(tbl_df(hflights)), hflights)  # FALSE  
    * sum(is.na(as.data.frame(tbl_df(hflights))) != is.na(hflights))  # 0  
    * sum(as.data.frame(tbl_df(hflights)) != hflights, na.rm=TRUE)  # 0  
  
An interesting way to do a lookup table:  
  
* two <- c("AA", "AS")  
* lut <- c("AA" = "American",  "AS" = "Alaska",  "B6" = "JetBlue")  
* two <- lut[two]  
* two  
  
See for example:  
```{r}
lut <- c("AA" = "American", "AS" = "Alaska", "B6" = "JetBlue", "CO" = "Continental", 
         "DL" = "Delta", "OO" = "SkyWest", "UA" = "United", "US" = "US_Airways", 
         "WN" = "Southwest", "EV" = "Atlantic_Southeast", "F9" = "Frontier", 
         "FL" = "AirTran", "MQ" = "American_Eagle", "XE" = "ExpressJet", "YV" = "Mesa"
         )
hflights$Carrier <- lut[hflights$UniqueCarrier]  
glimpse(hflights)  
```
  
There are five main verbs in dplyr:  
  
* select - subset of columns from a dataset  
    * select(df, . . . ) where . . . Are the columns to be kept  
	* starts_with("X"): every name that starts with "X",  
	* ends_with("X"): every name that ends with "X",  
	* contains("X"): every name that contains "X",  
	* matches("X"): every name that matches "X", where "X" can be a regular expression,  
	* num_range("x", 1:5): the variables named x01, x02, x03, x04 and x05,  
	* one_of(x): every name that appears in x, which should be a character vector.  
	* filter - subset of rows from a dataset  
        * filter(df, .)  where ... are 1+ logical tests (so make sure to use == or all.equal() or the like)  
* arrange - reorder rows in a dataset  
    * arrange(df, .) where . are the colunns to reorder by  
* mutate - create new columns in a dataset  
    * mutate(df, .) where each . is a formula for a new variable to be created  
* summarize - create summary statistics for a dataset  
    * summarize(df, .) where each . is a formula like newVar = thisEquation  
        * only aggregate functions (vector as input, single number as output) should be used  
    * dplyr adds several additional aggregate functions such as first, last, nth, n, n_distinct  
		* first(x) - The first element of vector x.  
		* last(x) - The last element of vector x.  
		* nth(x, n) - The nth element of vector x.  
		* n() - The number of rows in the data.frame or group of observations that summarise() describes.  
		* n_distinct(x) - The number of unique values in vector x.  
  
* In general:  
    * select and mutate operate on the variables  
    * filter and arrange operate on the observations  
    * summarize operates on groups of observations  
	* All of these are much cleaner if the data are tidy  
  
* There is also the option to use chaining %>% to process multiple commands		
    * Especially useful for memory storage and readability  
	* The pipe operator (%>%) comes from the magrittr package by Stefan Bache  
	* object %>% function(object will go first)  
	* c(1, 2, 3) %>% sum() # 6  
	* c(1, 2, 3, NA) %>% mean(na.rm=TRUE) # 2  
  
There is also the group_by capability for summaries of sub-groups:  
  
* group_by(df, .) where the . is what to group the data by  
    * The magic is when you run summarize() on data with group_by run on it; results will be by group  
	* If you have group_by(df, a, b) %>% summarize(timeSum = sum(time)) # all observations by a-b  
	* If you have group_by(df, a, b) %>% summarize(timeSum = sum(time)) %>% summarize(timeA = sum(timeSum)) # all observations by a  
	* If you have group_by(df, a, b) %>% summarize(timeSum = sum(time)) %>% summarize(timeA = sum(timeSum)) %>% summarize(timeAll = sum(timeA)) # all observations  
  
The dplyr library can also work with databases.  It only loads the data that you need, and you do not need to know the relevant SQL code -- dplyr writes the SQL code for you.  
  
Basic select and mutate examples include:  
```{r}
data(hflights)

# Make it faster, as well as a prettier printer
hflights <- tbl_df(hflights)
hflights
class(hflights)

# Select examples
select(hflights, ActualElapsedTime, AirTime, ArrDelay, DepDelay)
select(hflights, Origin:Cancelled)
select(hflights, Year:DayOfWeek, ArrDelay:Diverted)
select(hflights, ends_with("Delay"))
select(hflights, UniqueCarrier, ends_with("Num"), starts_with("Cancel"))
select(hflights, ends_with("Time"), ends_with("Delay"))

# Mutate example
m1 <- mutate(hflights, loss = ArrDelay - DepDelay, loss_ratio = loss / DepDelay)
class(m1)
m1
glimpse(m1)

```
  
Additionally, examples for filter and arrange:  
```{r}

# Examples for filter

filter(hflights, Distance >= 3000)  # All flights that traveled 3000 miles or more
filter(hflights, UniqueCarrier %in% c("B6", "WN", "DL"))
filter(hflights, (TaxiIn + TaxiOut) > AirTime)  # Flights where taxiing took longer than flying
filter(hflights, DepTime < 500 | ArrTime > 2200)  # Flights departed before 5am or arrived after 10pm
filter(hflights, DepDelay > 0, ArrDelay < 0)  # Flights that departed late but arrived ahead of schedule
filter(hflights, Cancelled == 1, DepDelay > 0) # Flights that were cancelled after being delayed

c1 <- filter(hflights, Dest == "JFK")  # Flights that had JFK as their destination: c1
c2 <- mutate(c1, Date = paste(Year, Month, DayofMonth, sep="-"))  # Create a Date column: c2
select(c2, Date, DepTime, ArrTime, TailNum)  # Print out a selection of columns of c2
dtc <- filter(hflights, Cancelled == 1, !is.na(DepDelay))  # Definition of dtc


# Examples for arrange

arrange(dtc, DepDelay)  # Arrange dtc by departure delays
arrange(dtc, CancellationCode)  # Arrange dtc so that cancellation reasons are grouped
arrange(dtc, UniqueCarrier, DepDelay)  # Arrange dtc according to carrier and departure delays
arrange(hflights, UniqueCarrier, desc(DepDelay))  # Arrange by carrier and decreasing departure delays
arrange(hflights, DepDelay + ArrDelay)  # Arrange flights by total delay (normal order)

```
  
Additionally, examples for the summarize verb:  
```{r}
# Print out a summary with variables min_dist and max_dist
summarize(hflights, min_dist = min(Distance), max_dist = max(Distance))

# Print out a summary with variable max_div
summarize(filter(hflights, Diverted == 1), max_div = max(Distance))

# Remove rows that have NA ArrDelay: temp1
temp1 <- filter(hflights, !is.na(ArrDelay))

# Generate summary about ArrDelay column of temp1
summarize(temp1, earliest=min(ArrDelay), average=mean(ArrDelay), latest=max(ArrDelay), sd=sd(ArrDelay))

# Keep rows that have no NA TaxiIn and no NA TaxiOut: temp2
temp2 <- filter(hflights, !is.na(TaxiIn), !is.na(TaxiOut))

# Print the maximum taxiing difference of temp2 with summarise()
summarize(temp2, max_taxi_diff = max(abs(TaxiIn - TaxiOut)))

# Generate summarizing statistics for hflights
summarize(hflights, n_obs = n(), n_carrier = n_distinct(UniqueCarrier), n_dest = n_distinct(Dest))

# All American Airline flights
aa <- filter(hflights, UniqueCarrier == "AA")

# Generate summarizing statistics for aa 
summarize(aa, n_flights = n(), n_canc = sum(Cancelled), avg_delay = mean(ArrDelay, na.rm=TRUE))

```
  
Additionally, examples for the pipe/chain as per magrittr:  
```{r}
# Find the average delta in taxi times
hflights %>%
    mutate(diff = (TaxiOut - TaxiIn)) %>%
    filter(!is.na(diff)) %>%
    summarize(avg = mean(diff))

# Find flights that average less than 70 mph assuming 100 wasted minutes per flight
hflights %>%
    mutate(RealTime = ActualElapsedTime + 100, mph = 60 * Distance / RealTime) %>%
    filter(!is.na(mph), mph < 70) %>%
    summarize(n_less = n(), n_dest = n_distinct(Dest), min_dist = min(Distance), max_dist = max(Distance))

# Find flights that average less than 105 mph, or that are diverted/cancelled
hflights %>%
  mutate(RealTime = ActualElapsedTime + 100, mph = Distance / RealTime * 60) %>%
  filter(mph < 105 | Cancelled == 1 | Diverted == 1) %>%
  summarize(n_non = n(), n_dest = n_distinct(Dest), min_dist = min(Distance), max_dist = max(Distance))

# Find overnight flights
filter(hflights, !is.na(DepTime), !is.na(ArrTime), DepTime > ArrTime) %>%
    summarize(num = n())

```
  
There is also the group_by capability, typically for use with summarize:  
```{r}
# Make an ordered per-carrier summary of hflights
group_by(hflights, UniqueCarrier) %>%
    summarize(p_canc = 100 * mean(Cancelled, na.rm=TRUE), avg_delay = mean(ArrDelay, na.rm=TRUE)) %>%
    arrange(avg_delay, p_canc)

# Ordered overview of average arrival delays per carrier
hflights %>%
    filter(!is.na(ArrDelay), ArrDelay > 0) %>%
    group_by(UniqueCarrier) %>%
    summarize(avg = mean(ArrDelay)) %>%
    mutate(rank = rank(avg)) %>%
    arrange(rank)

# How many airplanes only flew to one destination?
hflights %>%
  group_by(TailNum) %>%
  summarise(destPerTail = n_distinct(Dest)) %>%
  filter(destPerTail == 1) %>%
  summarise(nplanes=n())

# Find the most visited destination for each carrier
hflights %>%
  group_by(UniqueCarrier, Dest) %>%
  summarise(n = n()) %>%
  mutate(rank = rank(-n)) %>%
  filter(rank == 1)

# Use summarise to calculate n_carrier
library(data.table)
hflights2 <- as.data.table(hflights)
hflights2 %>%
    summarize(n_carrier = n_distinct(UniqueCarrier))

```
  
And, dplyr can be used with databases, including writing the SQL query that matches to the dplyr request.  The results are cached to avoid constantly pinging the server:  
```{r, cache=TRUE}
# Set up a connection to the mysql database
my_db <- src_mysql(dbname = "dplyr", 
                   host = "courses.csrrinzqubik.us-east-1.rds.amazonaws.com", 
                   port = 3306, 
                   user = "student",
                   password = "datacamp")

# Reference a table within that source: nycflights
nycflights <- tbl(my_db, "dplyr")

# glimpse at nycflights
glimpse(nycflights)

# Ordered, grouped summary of nycflights
nycflights %>%
    group_by(carrier) %>%
    summarize(n_flights = n(), avg_delay = mean(arr_delay)) %>%
    arrange(avg_delay)

```
  
  
###_Data Manipulation (dplyr joins)_  

Overall Course Overview - Goal is to have data in a single, tidy table

However, real-world data is typically split across multiple tables; this course will be about handling that:  
  
* Chapter 1 - Mutating Joins (matching data from different tables even if they occur in a different order)  
* Chapter 2 - Filtering Joins (surgically extract rows from combinations of datasets  
* Chapter 3 - Assembling Data (best practices such as bind.rows, bind.columns, and data.frame)  
* Chapter 4 - Advanced Joining (diagnose and avoid errors)  
* Chapter 5 - Case Study  
  
Builds on the above course about basic dplyr.  More than one way to handle things, as is common in R; base::merge() has some similar functions, however:  
  
* dplyr joining preserves row orders better than merge  
* dplyr joining has easier syntax  
* dplyr joining can act on databases, spark, and the like  
* dplyr is a front-end languages, allowing connections to many different back-ends (useful for big data)  
  

Chapter 1 - Mutating Joins

Keys are the columns that are "matched" between datasets that are being joined:  
  
* Keys can be single columns or combinations of columns, where matched keys identify data from multiple tables that belongs together  
* dplyr will treat the first table as the "primary" table; thus, this will be the "primary key"  
* Keys appearing in other tables will be "secondary keys" or "foreign keys"  
  	
Joins can be run in several manners:  
  
* The left_join(table1, table2, by="quotedVariable") syntax will keep all rows of table1 in their original order, with matches from table2 (NA if a row in table1 is not matched to table2)  
    * The by variable can be a concatenation, for example, by=c("mergeVar1", "mergeVar2")  
* The right_join(table1, table2, by="quotedVariable") is identical to left_join, except that table2 is now primary (order and all records preserved) and table1 is secondary (merged in where possible)  
* The dplyr joins will work with many types of "tables" - data frames, tibbles (tbl_df), and tbl references  
* A nice way to see the tibble printing on a data frame is to write tibble::as_tibble(myFrame)  
  
Variations on joins - the left_join and right_join are "mutating joins", which is to say that they return a copy of the "primary" data with columns added as appropriate:  
  
* The inner_join() is somewhat different in that it will only return the full-on matches (it will be a subset of both datasets in the command)  
* The full_join() is somewhat different in that it will return the data from both tables, with NA to reflect non-matched data (it will be a superset of both datasets in the command)  
* The joins take frame and return frames, making them ideal for the pipe operator ( %>% )  
  
Example code includes:
```{r}

artFirst <- "Jimmy ; George ; Mick ; Tom ; Davy ; John ; Paul ; Jimmy ; Joe ; Elvis ; Keith ; Paul ; Ringo ; Joe ; Brian ; Nancy"
artLast <- "Buffett ; Harrison ; Jagger ; Jones ; Jones ; Lennon ; McCartney ; Page ; Perry ; Presley ; Richards ; Simon ; Starr ; Walsh ; Wilson ; Wilson"
artInstrument <- "Guitar ; Guitar ; Vocals ; Vocals ; Vocals ; Guitar ; Bass ; Guitar ; Guitar ; Vocals ; Guitar ; Guitar ; Drums ; Guitar ; Vocals ; Vocals"
bandFirst <- "John ; John Paul ; Jimmy ; Robert ; George ; John ; Paul ; Ringo ; Jimmy ; Mick ; Keith ; Charlie ; Ronnie"
bandLast <- "Bonham ; Jones ; Page ; Plant ; Harrison ; Lennon ; McCartney ; Starr ; Buffett ; Jagger ; Richards ; Watts ; Woods"
bandBand <- "Led Zeppelin ; Led Zeppelin ; Led Zeppelin ; Led Zeppelin ; The Beatles ; The Beatles ; The Beatles ; The Beatles ; The Coral Reefers ; The Rolling Stones ; The Rolling Stones ; The Rolling Stones ; The Rolling Stones"

artists <- data.frame( first=strsplit(artFirst, " ; ")[[1]] , 
                       last=strsplit(artLast, " ; ")[[1]] , 
                       instrument=strsplit(artInstrument, " ; ")[[1]] , 
                       stringsAsFactors=FALSE 
                       )
bands <- data.frame( first=strsplit(bandFirst, " ; ")[[1]] , 
                     last=strsplit(bandLast, " ; ")[[1]] , 
                     band=strsplit(bandBand, " ; ")[[1]] , 
                     stringsAsFactors=FALSE 
                     )

library(dplyr)


# Complete the code to join artists to bands
bands2 <- left_join(bands, artists, by = c("first", "last"))

# Examine the results
bands2

# Note how this would be WRONG even though the code executes fine
left_join(bands, artists, by = c("first"))

# Finish the code below to recreate bands3 with a right join
bands2 <- left_join(bands, artists, by = c("first", "last"))
bands3 <- right_join(artists, bands, by = c("first", "last"))

# Check that bands3 is equal to bands2
setequal(bands2, bands3)


songData <- "Come Together : Abbey Road : John : Lennon ; Dream On : Aerosmith : Steven : Tyler ; Hello, Goodbye : Magical Mystery Tour : Paul : McCartney ; It's Not Unusual : Along Came Jones : Tom : Jones"
albumsData <- "A Hard Day's Night : The Beatles : 1964 ; Magical Mystery Tour : The Beatles : 1967 ; Beggar's Banquet : The Rolling Stones : 1968 ; Abbey Road : The Beatles : 1969 ; Led Zeppelin IV : Led Zeppelin : 1971 ; The Dark Side of the Moon : Pink Floyd : 1973 ; Aerosmith : Aerosmith : 1973 ; Rumours : Fleetwood Mac : 1977 ; Hotel California : Eagles : 1982"

songs <- as.data.frame( t(sapply(strsplit(songData, " ; ")[[1]], 
                                 FUN=function(x) { strsplit(x, " : ")[[1]] } , 
                                 USE.NAMES=FALSE
                                 )
                          ) , stringsAsFactors=FALSE
                        )
albums <- as.data.frame( t(sapply(strsplit(albumsData, " ; ")[[1]], 
                                  FUN=function(x) { strsplit(x, " : ")[[1]] } , 
                                  USE.NAMES=FALSE
                                  ))
                         , stringsAsFactors=FALSE
                         )
names(songs) <- c("song", "album", "first", "last")
names(albums) <- c("album", "band", "year")


# Join albums to songs using inner_join()
inner_join(songs, albums, by="album")

# Join bands to artists using full_join()
full_join(artists, bands, by=c("first", "last"))


# Find guitarists in bands dataset (don't change)
temp <- left_join(bands, artists, by = c("first", "last"))
temp <- filter(temp, instrument == "Guitar")
select(temp, first, last, band)

# Reproduce code above using pipes
bands %>% 
  left_join(artists, by = c("first", "last")) %>%
  filter(instrument == "Guitar") %>%
  select(first, last, band)

goalData <- "Tom : John : Paul ; Jones : Lennon : McCartney ; Vocals : Guitar : Bass ; NA : The Beatles : The Beatles ; It's Not Unusual : Come Together : Hello, Goodbye ; Along Came Jones : Abbey Road : Magical Mystery Tour"
goal <- as.data.frame( sapply(strsplit(goalData, " ; ")[[1]], 
                              FUN=function(x) { strsplit(x, " : ")[[1]] } , 
                              USE.NAMES=FALSE
                              ) , stringsAsFactors=FALSE
                       )
names(goal) <- c("first", "last", "instrument", "band", "song", "album")
goal[goal == "NA"] <- NA  # Fix the text that is "NA"

# Examine the contents of the goal dataset
goal

# Create goal2 using full_join() and inner_join() 
goal2 <- artists %>%
  full_join(bands, by=c("first", "last")) %>%
  inner_join(songs, by=c("first", "last"))
  
  
# Check that goal and goal2 are the same
setequal(goal, goal2)
sum(goal != goal2, na.rm=TRUE)


# Create one table that combines all information
artists %>%
  full_join(bands, by=c("first", "last")) %>%
  full_join(songs, by=c("first", "last")) %>%
  full_join(albums, by=c("album", "band"))


```
  
Chapter 2

Filtering joins return a copy of the primary data frame that has been filtered rather than augmented:  
  
* semi_join(a, b, by="x")  # returns a copy of a, filtered to include only those rows that have a matching by="x" record within b  
* semi_join() is a way to quickly check which rows will match for a planned mutating join (advance QC/QA)  
* semi_join() can also be a clever way to filter, saving steps in writing a very long filter statement  
  
The anti_join() is the opposite of the semi_join() in that it keeps only rows that DO NOT have a match:  
  
* anti_join(a, b, by="x")  # returns a copy of a, filtered to include only those rows that DO NOT have a matching by="x" record within b  
  
Set operations are used when two datasets contain the exact same variables:  
  
* union() will be the union of the two datasets  # rows are only returned once, even if they were duplicates in an input dataset and/or appeared in both datasets  
* intersect() will be the overlap of the two datasets  
* setdiff() will be the observations in dataset number one that are not in dataset number two  
  
Comparing datasets can also be run using setequal():  
  
* setequal(a, b) will return TRUE if every row of a is also a row of b, even if the rows happen to be in different orders  
* The identical() function is much less robust since it requires that the data be in the same order  
  
Example code includes:  
```{r}

# Data sets still available from the previous module

# View the output of semi_join()
artists %>% 
  semi_join(songs, by = c("first", "last"))

# Create the same result
artists %>% 
  right_join(songs, by = c("first", "last")) %>% 
  filter(!is.na(instrument)) %>% 
  select(first, last, instrument)


albums %>% 
  # Collect the albums made by a band
  semi_join(bands, by="band") %>% 
  # Count the albums made by a band
  nrow()


# Create data set tracks and matches

trackTrack <- "Can't Buy Me Love ; I Feel Fine ; A Hard Day's Night ; Sound of Silence ; Help! ; Ticket to Ride ; I am a Rock ; Yellow Submarine / Eleanor Rigby ; Homeward Bound ; Scarborough Fair ; Penny Lane ; Strawberry Fields Forever ; Hello, Goodbye ; Ruby Tuesday ; All You Need Is Love ; Hey Jude ; Lady Madonna ; Get Back ; Sympathy for the Devil ; Brown Sugar ; Happy"
trackBand <- "The Beatles ; The Beatles ; The Beatles ; Simon and Garfunkel ; The Beatles ; The Beatles ; Simon and Garfunkel ; The Beatles ; Simon and Garfunkel ; Simon and Garfunkel ; The Beatles ; The Beatles ; The Beatles ; The Rolling Stones ; The Beatles ; The Beatles ; The Beatles ; The Beatles ; The Rolling Stones ; The Rolling Stones ; The Rolling Stones"
trackLabel <- "Parlophone ; Parlophone ; Parlophone ; Columbia ; Parlophone ; Parlophone ; Columbia ; Parlophone ; Columbia ; Columbia ; Parlophone ; Parlophone ; Parlophone ; Decca ; Parlophone ; Apple ; Parlophone ; Apple ; Decca ; Rolling Stones Records ; Rolling Stones Records"
trackYear <- "1964 ; 1964 ; 1964 ; 1964 ; 1965 ; 1965 ; 1965 ; 1966 ; 1966 ; 1966 ; 1967 ; 1967 ; 1967 ; 1967 ; 1967 ; 1968 ; 1968 ; 1969 ; 1969 ; 1971 ; 1972"
trackFirst <- "Paul ; John ; John ; Paul ; John ; John ; Paul ; Paul ; Paul ; unknown ; Paul ; John ; Paul ; Keith ; John ; Paul ; Paul ; Paul ; Mick ; Mick ; Keith"
trackLast <- "McCartney ; Lennon ; Lennon ; Simon ; Lennon ; Lennon ; Simon ; McCartney ; Simon ; unknown ; McCartney ; Lennon ; McCartney ; Richards ; Lennon ; McCartney ; McCartney ; McCartney ; Jagger ; Jagger ; Richards"


tracks <- data.frame(track=strsplit(trackTrack, " ; ")[[1]], 
                     band=strsplit(trackBand, " ; ")[[1]], 
                     label=strsplit(trackLabel, " ; ")[[1]], 
                     year=as.integer(strsplit(trackYear, " ; ")[[1]]), 
                     first=strsplit(trackFirst, " ; ")[[1]], 
                     last=strsplit(trackLast, " ; ")[[1]], 
                     stringsAsFactors = FALSE
                     )
matches <- data.frame(band=c("The Beatles", "The Beatles", "Simon and Garfunkel"), 
                      year=c(1964L, 1965L, 1966L), 
                      first=c("Paul", "John", "Paul"), 
                      stringsAsFactors=FALSE
                      )

# Comparison of effort required
tracks %>% semi_join(
  matches,
  by = c("band", "year", "first")
)

tracks %>% filter(
  (band == "The Beatles" & 
     year == 1964 & first == "Paul") |
    (band == "The Beatles" & 
       year == 1965 & first == "John") |
    (band == "Simon and Garfunkel" & 
       year == 1966 & first == "Paul")
)


# Return rows of artists that don't have bands info
artists %>% 
  anti_join(bands, by=c("first", "last"))

# Return rows of artists that don't have bands info
artists %>% 
  anti_join(bands, by=c("first", "last"))

albumMyLabel <- "Abbey Road ; A Hard Days Night ; Magical Mystery Tour ; Led Zeppelin IV ; The Dark Side of the Moon ; Hotel California ; Rumours ; Aerosmith ; Beggar's Banquet"
labelMyLabel <- "Apple ; Parlophone ; Parlophone ; Atlantic ; Harvest ; Asylum ; Warner Brothers ; Columbia ; Decca"
myLabels <- data.frame(album=strsplit(albumMyLabel, " ; ")[[1]], 
                       label=strsplit(labelMyLabel, " ; ")[[1]], 
                       stringsAsFactors=FALSE
                       )

# Check whether album names in labels are mis-entered
myLabels %>% 
  anti_join(albums, by="album")

# Determine which key joins labels and songs
myLabels
songs

# Check your understanding
songs %>% 
  # Find the rows of songs that match a row in labels
  semi_join(myLabels, by="album") %>% 
  # Number of matches between labels and songs
  nrow()


songAerosmith <- "Make It ; Somebody ; Dream On ; One Way Street ; Mama Kin ; Write me a Letter ; Moving Out ; Walking the Dog"
lengthAerosmith <- "13260 ; 13500 ; 16080 ; 25200 ; 15900 ; 15060 ; 18180 ; 11520"
songGreatestHits <- "Dream On ; Mama Kin ; Same Old Song and Dance ; Seasons of Winter ; Sweet Emotion ; Walk this Way ; Big Ten Inch Record ; Last Child ; Back in the Saddle ; Draw the Line ; Kings and Queens ; Come Together ; Remember (Walking in the Sand) ; Lightning Strikes ; Chip Away the Stone ; Sweet Emotion (remix) ; One Way Street (live)"
lengthGreatestHits <- "16080 ; 16020 ; 11040 ; 17820 ; 11700 ; 12780 ; 8100 ; 12480 ; 16860 ; 12240 ; 13680 ; 13620 ; 14700 ; 16080 ; 14460 ; 16560 ; 24000"
songLive <- "Back in the Saddle ; Sweet Emotion ; Lord of the Thighs ; Toys in the Attic ; Last Child ; Come Together ; Walk this Way ; Sick as a Dog ; Dream On ; Chip Away the Stone ; Sight for Sore Eyes ; Mama Kin ; S.O.S. (Too Bad) ; I Ain't Got You ; Mother Popcorn/Draw the Line ; Train Kept A-Rollin'/Strangers in the Night"
lengthLive <- "15900 ; 16920 ; 26280 ; 13500 ; 12240 ; 17460 ; 13560 ; 16920 ; 16260 ; 15120 ; 11880 ; 13380 ; 9960 ; 14220 ; 41700 ; 17460"

aerosmith <- data.frame(song=strsplit(songAerosmith, " ; ")[[1]], 
                        length=as.integer(strsplit(lengthAerosmith, " ; ")[[1]]), 
                        stringsAsFactors=FALSE
                        )
greatest_hits <- data.frame(song=strsplit(songGreatestHits, " ; ")[[1]], 
                            length=as.integer(strsplit(lengthGreatestHits, " ; ")[[1]]), 
                            stringsAsFactors=FALSE
                            )
myLive <- data.frame(song=strsplit(songLive, " ; ")[[1]], 
                     length=as.integer(strsplit(lengthLive, " ; ")[[1]]), 
                     stringsAsFactors=FALSE
                     )

aerosmith %>% 
  # Create the new dataset using a set operation
  union(greatest_hits) %>% 
  # Count the total number of songs
  nrow()

# Create the new dataset using a set operation
aerosmith %>% 
  intersect(greatest_hits)

# Select the song names from live
live_songs <- myLive %>% select(song)

# Select the song names from greatest_hits
greatest_songs <- greatest_hits %>% select(song)

# Create the new dataset using a set operation
live_songs %>% 
  setdiff(greatest_songs)


# Select songs from live and greatest_hits
live_songs <- select(myLive, song)
greatest_songs <- select(greatest_hits, song)

# Return the songs that only exist in one dataset
union(setdiff(live_songs, greatest_songs), setdiff(greatest_songs, live_songs))


# DO NOT HAVE DATA - NEED TO SKIP
# Check if same order: definitive and complete
# identical(definitive, complete)

# Check if any order: definitive and complete
# setequal(definitive, complete)

# Songs in definitive but not complete
# setdiff(definitive, complete)

# Songs in complete but not definitive
# setdiff(complete, definitive)


# Return songs in definitive that are not in complete
# definitive %>% 
#   anti_join(complete, by=c("song", "album"))

# Return songs in complete that are not in definitive
# complete %>% 
#   anti_join(definitive, by=c("song", "album"))


# Check if same order: definitive and union of complete and soundtrack
# identical(definitive, union(complete, soundtrack))

# Check if any order: definitive and union of complete and soundtrack
# setequal(definitive, union(complete, soundtrack))


```
  
Chapter 3 - Assembling Data

Binding is the process of either combining columns for datasets that have the same rows, or combining rows for datasets that have the same columns:  
  
* dplyr::bind_rows(a, b, ...) is the dplyr equivalent for rbind  
* dplyr::bind_cols(a, b, ...) is the dplyr equivalent for cbind  
* Binding, especially by column, can be dangerous since if the data had ever been re-sorted the join would be meaningless  
* Binding through dplyr is generally faste and returns a tibble  
* Binding rows through dplyr allows a .id to reflect the original table - so bind_rows(a, b, .id="band") will create a new column "band" describing the source for that row  
  
Building a better data frame - equivalents for data.frame and as.data.frame:  
  
* The dplyr equivalents are data_frame() and as_data_frame()  
* data_frame() will 1) never change underlying vector types (specifically, no strings to factors conversions), 2) never add row names, 3) never change column names, 4) never recycle vectors of length greater than one  
* data_frame() evaluates arguments lazily, and in order, meaning that the first column can be used as an input to the second column; it also returns a tibble (tbl_df)  
  
Working with data types - R typically behaves intuitively:  
  
* Combining data sometimes leads to creating a column that consists of two different data types (e.g., numbers stored as integer vectors and numbers stored as character vectors)  
* Atomic data types include "logical", "character", "double", "integer", "complex", and "raw"; these can be ascertained using typeof()  
* The class() of a vector can be assigned using attributes; a common example is attributes(x) <- list(class="factor", levels=LETTERS[1:4])  
	
General coercion rules - more specific types of data will generally be converted to less specific types of data:  
  
* If there are any characters, the whole thing will become a character  
* If there are any doubles, the integers and logicals (TRUE -> 1, FALSE -> 0) will become doubles  
* If there are any integers, the logicals will become integers  
* Factors are a somewhat special case, in that as.character() will return the factor labels, while as.numeric() will return the number for the factor  
    * Sometimes, as.numeric(as.character(<myFactor>)) is needed  
* The dplyr functions will typically throw an error if a combination of data would require coercion  
* The one exception to this is with combining factors, where dplyr converts the factors to strings, combines them, and then throws a warning  
    * This further means that dplyr will coerce a factor to a character in the event that a factor and a character are requested to be combined  
  
Example code includes:  
```{r}

songSideOne <- "Speak to Me ; Breathe ; On the Run ; Time ; The Great Gig in the Sky"
lengthSideOne <- "5400 ; 9780 ; 12600 ; 24780 ; 15300"
songSideTwo <-"Money ; Us and Them ; Any Colour You Like ; Brain Damage ; Eclipse"
lengthSideTwo <-"23400 ; 28260 ; 12240 ; 13800 ; 7380"

side_one <- data.frame(song=strsplit(songSideOne, " ; ")[[1]], 
                       length=as.integer(strsplit(lengthSideOne, " ; ")[[1]]), 
                       stringsAsFactors=FALSE
                       )
side_two <- data.frame(song=strsplit(songSideTwo, " ; ")[[1]], 
                       length=as.integer(strsplit(lengthSideTwo, " ; ")[[1]]), 
                       stringsAsFactors=FALSE
                       )

# Examine side_one and side_two
side_one
side_two

# Bind side_one and side_two into a single dataset
side_one %>% 
  bind_rows(side_two)


# Create shorter version of jimi
jimi <- list(data.frame(song=c("Purple Haze", "Hey Joe", "Fire"), 
                        length=c(9960L, 12180L, 9240L), 
                        stringsAsFactors=FALSE
                        ), 
             data.frame(song=c("EXP", "Little Wing", "Little Miss Lover", "Bold as Love"), 
                        length=c(6900L, 8640L, 8400L, 15060L), 
                        stringsAsFactors=FALSE
                        ), 
             data.frame(song=c("Voodoo Chile", "Gypsy Eyes"), 
                        length=c(54000L, 13380L), 
                        stringsAsFactors=FALSE
                        )
             )
names(jimi) <- c("Are You Experienced", "Axis: Bold As Love", "Electric Ladyland")
discography <- data.frame(album=names(jimi), 
                          year=c(1967L, 1967L, 1968L), 
                          stringsAsFactors=FALSE
                          )


# Examine discography and jimi
discography
jimi

jimi %>% 
  # Bind jimi into a single data frame
  bind_rows(.id="album") %>% 
  # Make a complete data frame
  left_join(discography, by="album")



# Create the hank data
songHankYears <- "Move It On Over ; My Love for You (Has Turned to Hate) ; Never Again (Will I Knock on Your Door) ; On the Banks of the Old Ponchartrain ; Pan American ; Wealth Won't Save Your Soul ; A Mansion on the Hill ; Honky Tonkin' ; I Saw the Light ; I'm a Long Gone Daddy ; My Sweet Love Ain't Around ; I'm So Lonesome I Could Cry ; Lost Highway ; Lovesick Blues ; Mind Your Own Business ; My Bucket's Got a Hole in It ; Never Again (Will I Knock on Your Door) ; Wedding Bells ; You're Gonna Change (Or I'm Gonna Leave) ; I Just Don't Like This Kind of Living ; Long Gone Lonesome Blues ; Moanin' the Blues ; My Son Calls Another Man Daddy ; Nobody's Lonesome for Me ; They'll Never Take Her Love from Me ; Why Don't You Love Me ; Why Should We Try Anymore ; (I Heard That) Lonesome Whistle ; Baby, We're Really in Love ; Cold, Cold Heart ; Crazy Heart ; Dear John ; Hey Good Lookin' ; Howlin' At the Moon ; I Can't Help It (If I'm Still in Love With You) ; Half as Much ; Honky Tonk Blues ; I'll Never Get Out of This World Alive ; Jambalaya (On the Bayou) ; Settin' the Woods on Fire ; You Win Again ; Calling You ; I Won't Be Home No More ; Kaw-Liga ; Take These Chains from My Heart ; Weary Blues from Waitin' ; Your Cheatin' Heart ; (I'm Gonna) Sing, Sing, Sing ; How Can You Refuse Him Now ; I'm Satisfied with You ; You Better Keep It on Your Mind ; A Teardrop on a Rose ; At the First Fall of Snow ; Mother Is Gone ; Please Don't Let Me Love You ; Thank God ; A Home in Heaven ; California Zephyr ; Singing Waterfall ; There's No Room in My Heart for the Blues ; Leave Me Alone with the Blues ; Ready to Go Home ; The Waltz of the Wind ; Just Waitin' ; The Pale Horse and His Rider ; Kaw-Liga ; There's a Tear in My Beer"
yearHankYears <- "1947 ; 1947 ; 1947 ; 1947 ; 1947 ; 1947 ; 1948 ; 1948 ; 1948 ; 1948 ; 1948 ; 1949 ; 1949 ; 1949 ; 1949 ; 1949 ; 1949 ; 1949 ; 1949 ; 1950 ; 1950 ; 1950 ; 1950 ; 1950 ; 1950 ; 1950 ; 1950 ; 1951 ; 1951 ; 1951 ; 1951 ; 1951 ; 1951 ; 1951 ; 1951 ; 1952 ; 1952 ; 1952 ; 1952 ; 1952 ; 1952 ; 1953 ; 1953 ; 1953 ; 1953 ; 1953 ; 1953 ; 1954 ; 1954 ; 1954 ; 1954 ; 1955 ; 1955 ; 1955 ; 1955 ; 1955 ; 1956 ; 1956 ; 1956 ; 1956 ; 1957 ; 1957 ; 1957 ; 1958 ; 1965 ; 1966 ; 1989"
songHankCharts <- "(I Heard That) Lonesome Whistle ; (I'm Gonna) Sing, Sing, Sing ; A Home in Heaven ; A Mansion on the Hill ; A Teardrop on a Rose ; At the First Fall of Snow ; Baby, We're Really in Love ; California Zephyr ; Calling You ; Cold, Cold Heart ; Crazy Heart ; Dear John ; Half as Much ; Hey Good Lookin' ; Honky Tonk Blues ; Honky Tonkin' ; How Can You Refuse Him Now ; Howlin' At the Moon ; I Can't Help It (If I'm Still in Love With You) ; I Just Don't Like This Kind of Living ; I Saw the Light ; I Won't Be Home No More ; I'll Never Get Out of This World Alive ; I'm a Long Gone Daddy ; I'm Satisfied with You ; I'm So Lonesome I Could Cry ; Jambalaya (On the Bayou) ; Just Waitin' ; Kaw-Liga ; Kaw-Liga ; Leave Me Alone with the Blues ; Long Gone Lonesome Blues ; Lost Highway ; Lovesick Blues ; Mind Your Own Business ; Moanin' the Blues ; Mother Is Gone ; Move It On Over ; My Bucket's Got a Hole in It ; My Love for You (Has Turned to Hate) ; My Son Calls Another Man Daddy ; My Sweet Love Ain't Around ; Never Again (Will I Knock on Your Door) ; Never Again (Will I Knock on Your Door) ; Nobody's Lonesome for Me ; On the Banks of the Old Ponchartrain ; Pan American ; Please Don't Let Me Love You ; Ready to Go Home ; Settin' the Woods on Fire ; Singing Waterfall ; Take These Chains from My Heart ; Thank God ; The Pale Horse and His Rider ; The Waltz of the Wind ; There's a Tear in My Beer ; There's No Room in My Heart for the Blues ; They'll Never Take Her Love from Me ; Wealth Won't Save Your Soul ; Weary Blues from Waitin' ; Wedding Bells ; Why Don't You Love Me ; Why Should We Try Anymore ; You Better Keep It on Your Mind ; You Win Again ; You're Gonna Change (Or I'm Gonna Leave) ; Your Cheatin' Heart"
peakHankCharts <- "9 ; NA ; NA ; 12 ; NA ; NA ; 4 ; NA ; NA ; 1 ; 4 ; 8 ; 2 ; 1 ; 2 ; 14 ; NA ; 3 ; 2 ; 5 ; NA ; 4 ; 1 ; 6 ; NA ; 2 ; 1 ; NA ; 1 ; NA ; NA ; 1 ; 12 ; 1 ; 5 ; 1 ; NA ; 4 ; 2 ; NA ; 9 ; NA ; NA ; 6 ; 9 ; NA ; NA ; 9 ; NA ; 2 ; NA ; 1 ; NA ; NA ; NA ; 7 ; NA ; 5 ; NA ; 7 ; 2 ; 1 ; 9 ; NA ; 10 ; 4 ; 1"

hank_years <- data.frame(year=as.integer(strsplit(yearHankYears, " ; ")[[1]]), 
                         song=strsplit(songHankYears, " ; ")[[1]], 
                         stringsAsFactors=FALSE
                         )
hank_charts <- data.frame(song=strsplit(songHankCharts, " ; ")[[1]], 
                          peak=as.integer(strsplit(peakHankCharts, " ; ")[[1]]), 
                          stringsAsFactors=FALSE
                          )


# Examine hank_years and hank_charts
tibble::as_tibble(hank_years)
tibble::as_tibble(hank_charts)

a <- hank_years %>% 
  # Reorder hank_years alphabetically by song title
  arrange(song) %>% 
  # Select just the year column
  select(year) %>% 
  # Bind the year column
  bind_cols(hank_charts) %>% 
  # Arrange the finished dataset
  arrange(year, song)

a # see the results


hank_year <- a$year
hank_song <- a$song
hank_peak <- a$peak


# Make combined data frame using data_frame()
data_frame(year=hank_year, song=hank_song, peak=hank_peak) %>% 
  # Extract songs where peak equals 1
  filter(peak == 1)


hank <- list(year=hank_year, song=hank_song, peak=hank_peak)


# Examine the contents of hank
hank

# Convert the hank list into a data frame
as_data_frame(hank) %>% 
  # Extract songs where peak equals 1
  filter(peak == 1)


### ** DO NOT RUN DUE TO NOT HAVING DATASET
# Examine the contents of michael
# michael

# bind_rows(michael, .id="album") %>% 
#   group_by(album) %>% 
#   mutate(rank = min_rank(peak)) %>% 
#   filter(rank == 1) %>% 
#   select(-rank, -peak)


y <- factor(c(5, 6, 7, 6))
y
unclass(y)
as.character(y)
as.numeric(y)
as.numeric(as.character(y))


### ** DO NOT RUN DUE TO NOT HAVING DATASET
# seventies %>% 
  # Coerce seventies$year into a useful numeric
  # mutate(year = as.numeric(as.character(year))) %>% 
  # Bind the updated version of seventies to sixties
  # bind_rows(sixties) %>% 
  # arrange(year)

```
  
  
Chapter 4 - Advanced Joining
  
What can go wrong?  General issues can be considered as a 2x2 matrix, where key values and/or key columns can be either missing and/or duplicated:  
  
* A missing key value is when you have an NA as one of the key columns - sometimes, just filter these out prior to joining  
* Sometimes, a missing key column can be "located" in the rownames() of the underlying database  
    * These can also be accessed using tibble::rownames_to_column(myDB, var="newName")  
* Duplicate key values are often a sign that you need to expand the key - for exampe, from "last" to c("last", "first")  
	* dplyr will permit for duplicate key values, but it will do a full join on the matches (meaning the data can blow out very quickly)  
  
Defining the keys - expanding on the previous approaches that have always used by= explicitly in the join function:  
  
* If the by statement is ommitted, dplyr will join on all variable names that are in common across the datasets, throwing a note about the join variables used  
* If the variables really have different names, dplyr prefers a named list in the by argument; for example, by=c("member" = "name") # member in data1 will match to name in data2  
* If variables excluded from the by statement have the same names, dplyr will keep the columns from both datasets, appending the .x (primary) and .y (match) to the variable name  
	* If .x and .y are not desired, can instead pass the argument suffix=c("1", "2")  # in this case, it will add 1 to the end of key and 2 to the end of match  
  
Joining multiple tables is an extension of joining two tables:  
  
* The purrr package helps facilitate this, with the purrr::reduce() applying functions in a recursive manner  
* Basically, create a list of tables, specifically using list()  
* Then, purrr::reduce(myList, <dplyrfunction>, <args>)  
	* If the dplyr function is a join, then by might by one of the arguments - for example, purrr::reduce(myList, left_join, by="name")  
  
Other implementations can be available:  
  
* The merge() function in base R is a super-function, attemptint to enable every type of join in a single statement  
* Can connect to databases - see vignette("databases", package="dplyr")  
  
Example code includes:  
```{r}

stage_songs <- data.frame(musical=c("Into the Woods", "West Side Story", 
                                    "Cats", "Phantom of the Opera"
                                    ), 
                          year=c(1986L, 1957L, 1981L, 1986L), 
                          stringsAsFactors=FALSE
                          )
rownames(stage_songs) <- c("Children Will Listen", "Maria", 
                           "Memory", "The Music of the Night"
                           )
stage_writers <- data.frame(song=rownames(stage_songs), 
                            composer=c("Stephen Sondheim", "Louis Bernstein", 
                                       "Andrew Lloyd Webber", "Andrew Lloyd Webber"
                                       ), 
                            stringsAsFactors=FALSE
                            )


stage_songs %>% 
  # Add row names as a column named song
  tibble::rownames_to_column(var="song") %>% 
  # Left join stage_writers to stage_songs
  left_join(stage_writers, by="song")


singers <- data.frame(movie=c(NA, "The Sound of Music"), 
                      singer=c("Arnold Schwarzenegger", "Julie Andrews"), 
                      stringsAsFactors=FALSE
                      )
two_songs <- data.frame(movie=c("The Sound of Music", NA), 
                        song=c("Do-Re-Mi", "A Spoonful of Sugar"), 
                        stringsAsFactors=FALSE
                        )

# Examine the result of joining singers to two_songs
two_songs %>% inner_join(singers, by = "movie")

# Remove NA's from key before joining
two_songs %>% 
  filter(!is.na(movie)) %>% 
  inner_join(singers, by = "movie")


movieMovieYears <- "The Road to Morocco ; Going My Way ; Anchors Aweigh ; Till the Clouds Roll By ; White Christmas ; The Tender Trap ; High Society ; The Joker is Wild ; Pal Joey ; Can-Can"
nameMovieYears <- "Bing Crosby ; Bing Crosby ; Frank Sinatra ; Frank Sinatra ; Bing Crosby ; Frank Sinatra ; Bing Crosby ; Frank Sinatra ; Frank Sinatra ; Frank Sinatra"
yearMovieYears <- "1942 ; 1944 ; 1945 ; 1946 ; 1954 ; 1955 ; 1956 ; 1957 ; 1957 ; 1960"
movieMovieStudios <- "The Road to Morocco ; Going My Way ; Anchors Aweigh ; Till the Clouds Roll By ; White Christmas ; The Tender Trap ; High Society ; The Joker is Wild ; Pal Joey ; Can-Can"
nameMovieStudios <- "Paramount Pictures ; Paramount Pictures ; Metro-Goldwyn-Mayer ; Metro-Goldwyn-Mayer ; Paramount Pictures ; Metro-Goldwyn-Mayer ; Metro-Goldwyn-Mayer ; Paramount Pictures ; Columbia Pictures ; Twentieth-Century Fox"

movie_years <- data.frame(movie=strsplit(movieMovieYears, " ; ")[[1]], 
                          name=strsplit(nameMovieYears, " ; ")[[1]], 
                          year=as.integer(strsplit(yearMovieYears, " ; ")[[1]]), 
                          stringsAsFactors=FALSE
                          )
movie_studios <- data.frame(movie=strsplit(movieMovieStudios, " ; ")[[1]], 
                            name=strsplit(nameMovieStudios, " ; ")[[1]], 
                            stringsAsFactors=FALSE
                            )


movie_years %>% 
  # Left join movie_studios to movie_years
  left_join(movie_studios, by="movie") %>% 
  # Rename the columns: artist and studio
  rename(artist=name.x, studio=name.y)


elvis_movies <- data.frame(name=c("Jailhouse Rock", "Blue Hawaii", 
                                  "Viva Las Vegas", "Clambake"
                                  ), 
                           year=c(1957L, 1961L, 1963L, 1967L), 
                           stringsAsFactors=FALSE
                           )
elvTemp <- "(You're So Square) Baby I Don't Care ; I Can't Help Falling in Love ; Jailhouse Rock ; Viva Las Vegas ; You Don't Know Me"
elvis_songs <- data.frame(name=strsplit(elvTemp, " ; ")[[1]], 
                          movie=elvis_movies$name[c(1, 2, 1, 3, 4)], 
                          stringsAsFactors=FALSE
                          )


# Identify the key column
elvis_songs
elvis_movies

elvis_movies %>% 
  # Left join elvis_songs to elvis_movies by this column
  left_join(elvis_songs, by=c("name"="movie")) %>% 
  # Rename columns
  rename(movie=name, song=name.y)


mdData <- "Anchors Aweigh ; Can-Can ; Going My Way ; High Society ; Pal Joey ; The Joker is Wild ; The Road to Morocco ; The Tender Trap ; Till the Clouds Roll By ; White Christmas : George Sidney ; Walter Lang ; Leo McCarey ; Charles Walters ; George Sidney ; Charles Vidor ; David Butler ; Charles Walters ; Richard Whorf ; Michael Curtiz : Metro-Goldwyn-Mayer ; Twentieth-Century Fox ; Paramount Pictures ; Metro-Goldwyn-Mayer ; Columbia Pictures ; Paramount Pictures ; Paramount Pictures ; Metro-Goldwyn-Mayer ; Metro-Goldwyn-Mayer ; Paramount Pictures"
myData <- "The Road to Morocco ; Going My Way ; Anchors Aweigh ; Till the Clouds Roll By ; White Christmas ; The Tender Trap ; High Society ; The Joker is Wild ; Pal Joey ; Can-Can : Bing Crosby ; Bing Crosby ; Frank Sinatra ; Frank Sinatra ; Bing Crosby ; Frank Sinatra ; Bing Crosby ; Frank Sinatra ; Frank Sinatra ; Frank Sinatra : 1942 ; 1944 ; 1945 ; 1946 ; 1954 ; 1955 ; 1956 ; 1957 ; 1957 ; 1960"

movie_directors <- as.data.frame(lapply(strsplit(mdData, " : "), 
                                        FUN=function(x) { strsplit(x, " ; ") }
                                        ), 
                                 stringsAsFactors=FALSE
                                 )
names(movie_directors) <- c("name", "director", "studio")
movie_years <- as.data.frame(lapply(strsplit(myData, " : "), 
                                    FUN=function(x) { strsplit(x, " ; ") }
                                    ), 
                             stringsAsFactors=FALSE
                             )
names(movie_years) <- c("movie", "name", "year")
movie_years$year <- as.integer(movie_years$year)


# Identify the key columns
movie_directors
movie_years

movie_years %>% 
  # Left join movie_directors to movie_years
  left_join(movie_directors, by=c("movie"="name")) %>% 
  # Arrange the columns using select()
  rename(artist=name) %>%
  select(year, movie, artist, director, studio)



### *** DO NOT RUN DUE TO NOT HAVING DATA
# Place supergroups, more_bands, and more_artists into a list
# list(supergroups, more_bands, more_artists) %>% 
  # Use reduce to join together the contents of the list
  # purrr::reduce(left_join, by=c("first", "last"))

# list(more_artists, more_bands, supergroups) %>% 
  # Return rows of more_artists in all three datasets
  # purrr::reduce(semi_join, by=c("first", "last"))

# Data is available from previous
# Alter the code to perform the join with a dplyr function
merge(bands, artists, by = c("first", "last"), all.x = TRUE) %>%
  arrange(band)
  
bands %>%
  left_join(artists, by=c("first", "last"))


```
  
  
Chapter 5 - Case Study
  
###_Data Manipulation (data.table)_  
The data.table library is designed to simplify and speed up work with large datasets.  The language is broadly analogous to SQL, with syntax that includes equivalents for SELECT, WHERE, and GROUP BY.  Some general attributes of a data.table object include:  
  
* Set of columns; every column is the same length but may be of different type  
* Goal #1: Reduce programming time (fewer function calls, less variable name repetition)  
* Goal #2: Reduce compute time (fast aggregation, update by reference  
* Currently in-memory (64-bit and 100 GB is routine; one-quarter-terabyte RAM is available through Amazon EC2 for a few dollars per hours)  
* Ordered joins (useful in finance/time series and also genomics)  
  
NOTE - all data.table are also data.frame, and if a package is not aware of data.table, then it will act as data.frame for that package.  
  
General syntax is:  
  
* myDataTable[condition, data/transforms, order by]  
    * Extracts all rows that meet condition, provides the requested data/transforms, and orders accordingly  
    * Analogous to SQL - WHERE, SELECT, GROUP BY  
    * DT[i, j, by]  
  
Example table creation:  
  
* DT <- data.table(A = 1:6, B=c("a", "b", "c"), C=rnorm(6), D=TRUE)  
    * "We like character vectors in data.table"  
    * Need to use 1L for integer, and NA_integer_ for NA/integer (rather than boolean)  
    * DT[3:5, ] is the same as DT[3:5] -- either will return rows 3-5  
    * Note that .N contains the number of rows  
  
* Select columns in data.table (second argument)  
    * .(B, C) is the same as list(B, C) and will select the columns named "B" and "C"  
	* .(mysum = sum(B)) will sum the entirety of column B for the rows requested and call the column mysum  
	* .(B, C= sum(C)) will recycle sum(C) everywhere and also pull B  
	* DT[,plot(A, C)] will plot A vs C  
	* DT[ , B] will return a VECTOR and not a data.table  
	* DT[ , .(B)] will return a data.table  
  	
* Using a by variable allows for sum/mean/etc. by grouping:  
	* DT[ , .(mysum = sum(B)), by=.(C)] will sum column B BY each C for the rows requested, and call the column mysum  
	* DT[ , .(mysum = sum(B)), by=.(myMod = C%%2)] will sum column B BY each Cmod2 for the rows requested, and call the column mysum  
	* Can skip the .() if you have just a single SELECT or a single GROUP BY  
		* Order depends on what it finds first -- not necessarily sorted, just aggregated BY  
  
Some example code includes:  
```{r}
library(data.table)

DT <- data.table(a = c(1, 2), b=LETTERS[1:4])
str(DT)
DT

# Print the second to last row of DT using .N
DT[.N-1]

# Print the column names of DT
names(DT)

# Print the number or rows and columns of DT
dim(DT)

# Select row 2 twice and row 3, returning a data.table with three rows where row 2 is a duplicate of row 1.
DT[c(2, 2:3)]


DT <- data.table(A = 1:5, B = letters[1:5], C = 6:10)
str(DT)
DT

# Subset rows 1 and 3, and columns B and C
DT[c(1, 3), .(B, C)]

# Assign to ans the correct value
ans <- DT[ , .(B, val=A*C)]
ans

# Fill in the blanks such that ans2 equals target
target <- data.table(B = c("a", "b", "c", "d", "e", "a", "b", "c", "d", "e"), 
                     val = as.integer(c(6:10, 1:5))
                     )
ans2 <- DT[, .(B, val = c(C, A))]
identical(target, ans2)


DT <- as.data.table(iris)
str(DT)

# For each Species, print the mean Sepal.Length
DT[ , mean(Sepal.Length), Species]

# Print mean Sepal.Length, grouping by first letter of Species
DT[ , mean(Sepal.Length), substr(Species, 1, 1)]
str(DT)
identical(DT, as.data.table(iris))


# Group the specimens by Sepal area (to the nearest 10 cm2) and count how many occur in each group.
DT[, .N, by = 10 * round(Sepal.Length * Sepal.Width / 10)]

# Now name the output columns `Area` and `Count`
DT[, .(Count=.N), by = .(Area = 10 * round(Sepal.Length * Sepal.Width / 10))]


# Create the data.table DT
set.seed(1L)
DT <- data.table(A = rep(letters[2:1], each = 4L), 
                 B = rep(1:4, each = 2L), 
                 C = sample(8)
                 )
str(DT)
DT


# Create the new data.table, DT2
DT2 <- DT[, .(C = cumsum(C)), by = .(A, B)]
str(DT2)
DT2


# Select from DT2 the last two values from C while you group by A
DT2[, .(C = tail(C, 2)), by = A]

```
  
The chaining operation in data.table is run as [statement][next statement].  
  
* The .SD means "Subset of Data"  
    * By default, .SD means all of the columns other than the columns specified in by (and only accessible in j)  
	* DT[ , lapply(.SD, median), by = Species]  
	* Recall that .() is just an alias to a list, so it is not needed for lapply (which always returns a list anyway)  
  
* The := operator is for adding by reference  
	* If it already exists, it is updated as per the call  
	* If it does not already exist, it is created  
	* DT[ , c("x", "z") := .(rev(x), 10:6)]  # will reverse x and create z as 10-9-8-7-6]  
	* Anything with := NULL will remove the columns instantly  
	* DT[ , MyCols :=NULL] will look for a column called MyCols  
	* DT[, (MyCols) := NULL] will use whatever MyCols references, allowing for MyCols to be a variable  
	* DT[2:4, z:=sum(y), by=x]  # Will create z as requested for rows 2:4 and create z=NA everywhere else; interesting (and risky perhaps .)  
  
* The set() syntax is another option:  
	* for (i in 1:5) DT[i, z := i+1]  
	* for (i in 1:5) set(DT, i, 3L, i+1])  # take DT, act on column 3 (happens to be z in this example) and makes it i+1  
  
* The setnames() syntax is yet another option  
	* setnames(DT, "old", "new")  
  
* The setcolorder() syntax is yet another option  
	* setcolorder(DT, c(new_order))  
  
* A wrap up of the set() family:  
	* set() is a loopable, low overhead version of :=  
	* You can use setnames() to set or change column names  
	* setcolorder() lets you reorder the columns of a data.table  
  
Example code includes:  
```{r}
set.seed(1L)
DT <- data.table(A = rep(letters[2:1], each = 4L), 
                 B = rep(1:4, each = 2L), 
                 C = sample(8)) 
str(DT)
DT


# Perform operation using chaining
DT[ , .(C = cumsum(C)), by = .(A, B)][ , .(C = tail(C, 2)), by=.(A)]


data(iris)
DT <- as.data.table(iris)
str(DT)


# Perform chained operations on DT
DT[ , .(Sepal.Length = median(Sepal.Length), Sepal.Width = median(Sepal.Width), 
        Petal.Length = median(Petal.Length), Petal.Width = median(Petal.Width)), 
        by=.(Species)][order(-Species)]

# Mean of columns
# DT[ , lapply(.SD, FUN=mean), by=.(x)]

# Median of columns
# DT[ , lapply(.SD, FUN=median), by=.(x)]

# Calculate the sum of the Q columns
# DT[ , lapply(.SD, FUN=sum), , .SDcols=2:4]

# Calculate the sum of columns H1 and H2 
# DT[ , lapply(.SD, FUN=sum), , .SDcols=paste0("H", 1:2)]

# Select all but the first row of groups 1 and 2, returning only the grp column and the Q columns
# foo = function(x) { x[-1] }
# DT[ , lapply(.SD, FUN=foo), by=.(grp), .SDcols=paste0("Q", 1:3)]

# Sum of all columns and the number of rows
# DT[, c(lapply(.SD, FUN=sum), .N), by=.(x), .SDcols=names(DT)]

# Cumulative sum of column x and y while grouping by x and z > 8
# DT[, lapply(.SD, FUN=cumsum), by=.(by1=x, by2=(z>8)), .SDcols=c("x", "y")]

# Chaining
# DT[, lapply(.SD, FUN=cumsum), by=.(by1=x, by2=(z>8)), .SDcols=c("x", "y")][ , lapply(.SD, FUN=max), by=.(by1), .SDcols=c("x", "y")]


# The data.table DT
DT <- data.table(A = letters[c(1, 1, 1, 2, 2)], B = 1:5)
str(DT)
DT


# Add column by reference: Total
DT[ , Total:=sum(B), by=.(A)]
DT

# Add 1 to column B
DT[c(2,4) , B:=B+1L, ]
DT

# Add a new column Total2
DT[2:4, Total2:=sum(B), by=.(A)]
DT

# Remove the Total column
DT[ , Total := NULL, ]
DT

# Select the third column using `[[`
DT[[3]]

# A data.table DT has been created for you
DT <- data.table(A = c(1, 1, 1, 2, 2), B = 1:5)
str(DT)
DT


# Update B, add C and D
DT[ , c("B", "C", "D") := .(B + 1, A + B, 2), ]
DT

# Delete my_cols
my_cols <- c("B", "C")
DT[ , (my_cols) := NULL, ]
DT

# Delete column 2 by number
DT[[2]] <- NULL
DT

# Set the seed
# set.seed(1)

# Check the DT that is made available to you
# DT

# For loop with set
# for(i in 2:4) { set(DT, sample(nrow(DT), 3), i, NA) }

# Change the column names to lowercase
# setnames(DT, letters[1:4])

# Print the resulting DT to the console
# DT

# Define DT
DT <- data.table(a = letters[c(1, 1, 1, 2, 2)], b = 1)
str(DT)
DT


# Add a suffix "_2" to all column names
setnames(DT, paste0(names(DT), "_2"))
DT

# Change column name "a_2" to "A2"
setnames(DT, "a_2", "A2")
DT

# Reverse the order of the columns
setcolorder(DT, 2:1)
DT

```
  
* Section 8 - Indexing (using column names in i)  
	* DT[A == "a"]  # returns only the rows where column A has value "a"  
	* w <- DT[, A == "a"]  # creates a new variable w that is the boolean evaluation of A == "a"  
		* Note that this is a vector and not a list since it is not wrapped in .()  
	* DT[w] will return the same thing as DT[A == "a"]  
	* The data.table() package automatically creates an index the first time you use the variable  
		* DT[A == "a"]  # takes however long it needs  
		* DT[A == "b"]  # now runs very fast since it is indexed  
  
* Section 9 - creating and using a key  
	* setkey(DT, varname)  
	* DT["b"]  # will find where varname that has been set as key is equal to "b"  
	* DT["b", mult="first"]  # will return only the first match  
	* DT["b", mult="last"]  # will return only the last match  
	* If one of the requested keys is not found, a row with NA is returned  
		* DT[c("b", "d")] could return an NA  
		* DT[c("b", "d"), nomatch = 0] will never return an NA; instead it will just skip the rows  
	* If you create setkey(DT, A, B) then it will be indexed by both A and B  
		* DT[.("b", 5)]  # this will pull rows where A == "b" and B == 5  
  
* Section 10 - Rolling joins (typically used for time series)  
	* DT[.("b", 4), roll=TRUE]  # If there is a "b", 4 then it will find it; if not, then it will find the closest previous match  
	* DT[.("b", 4), roll="nearest"]  # If there is a "b", 4 then it will find it; if not, then it will find the nearest match  
	* DT[.("b", 4), roll=+Inf]  # If there is a "b", 4 then it will find it; if not, then it will find the closest previous match  
	* DT[.("b", 4), roll=-Inf]  # If there is a "b", 4 then it will find it; if not, then it will find the closest succeeding match  
	* DT[.("b", 4), roll=2]  # If there is a "b", 4 then it will find it; if not, then it will find the closest previous match provided it was within 2  
	* DT[.("b", 4), roll=-2]  # If there is a "b", 4 then it will find it; if not, then it will find the closest succeeding match provided it was within 2  
	* DT[.("b", 4), roll=TRUE, rollends=FALSE]  # If there is a "b", 4 then it will find it; if not, then it will find the closest previous match, except it will not go beyond the data  
  
Example code includes:  
```{r}
# iris as a data.table
iris <- as.data.table(iris)

# Remove the "Sepal." prefix
names(iris) <- gsub("Sepal\\.", "", names(iris))

# Remove the two columns starting with "Petal"
iris[, c("Petal.Length", "Petal.Width") := NULL, ]

# Cleaned up iris data.table
str(iris)

# Area is greater than 20 square centimeters
iris[ Width * Length > 20 ]

# Add new boolean column
iris[, is_large := Width * Length > 25]

# Now large observations with is_large
iris[is_large == TRUE]
iris[(is_large)] # Also OK


# The 'keyed' data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)], 
                 B = c(5, 4, 1, 9, 8, 8, 6), 
                 C = 6:12)
setkey(DT, A, B)
str(DT)
DT

# Select the "b" group
DT["b"]

# "b" and "c" groups
DT[c("b", "c")]

# The first row of the "b" and "c" groups
DT[c("b", "c"), mult = "first"]

# First and last row of the "b" and "c" groups
DT[c("b", "c"), .SD[c(1, .N)], by = .EACHI]

# Copy and extend code for instruction 4: add printout
DT[c("b", "c"), { print(.SD); .SD[c(1, .N)] }, by = .EACHI]


# Keyed data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)], 
                 B = c(5, 4, 1, 9, 8, 8, 6), 
                 C = 6:12, 
                 key = "A,B")
str(DT)
DT

# Get the key of DT
key(DT)

# Row where A == "b" and B == 6
DT[.("b", 6)]

# Return the prevailing row
DT[.("b", 6), roll=TRUE]

# Return the nearest row
DT[.("b", 6), roll="nearest"]

# Keyed data.table DT
DT <- data.table(A = letters[c(2, 1, 2, 3, 1, 2, 3)], 
                 B = c(5, 4, 1, 9, 8, 8, 6), 
                 C = 6:12, 
                 key = "A,B")
str(DT)
DT


# Print the sequence (-2):10 for the "b" group
DT[.("b", (-2):10)]

# Add code: carry the prevailing values forwards
DT[.("b", (-2):10), roll=TRUE]

# Add code: carry the first observation backwards
DT[.("b", (-2):10), roll=TRUE, rollends=TRUE]

```
  
###_Data Manipulation (xts and zoo)_  
Jeff Ryan, the creator of quantmod and organizer of the R/Finance conference, has developed xts and zoo to simplify working with time series data.  The course will cover five areas (chapters):  
  
* Chapter 1: Create, import, and export time series  
* Chapter 2: Subset, extract, and more  
* Chapter 3: Merge and modify time series  
* Chapter 4: Apply and aggregate by time  
* Chapter 5: Advanced and extra features of xts  
  
"xts" stands for extensible time series.  The core of each "xts" is a "zoo" object, consisting of a matrix plus an index.  
  
* Basically, it is data plus an array of times  
	* x <- matrix(data=1:4, ncol=2)  
	* idx <- as.Date(c("2015-01-01", "2015-02-01"))  
	    * The idx needs to be "time based", though the type of time object can be flexible - Date, POSIX times, timeData, chron, . . . 	
	    * The index should be in increasing order of time (earlier at the type)  

* The xts functions allow for joining the index and the data  
	* X <- xts(x, order.by = idx)  # Can add arguments unique=TRUE (force times to be unique) and tzone="<what you want>" to override the system time-zone  
	* If the "idx" that you passed is not sorted ascending (earliest times first), the xts call will sort both the "x" and the "idx" such that the resulting xts object is ascending in time  

There are a few special behaviors of xts:  
  
* The xts object is a matrix with associated times for each object  
* Subsets will preserve the matrix form (even if taking just a single row or a single column -- no drop=TRUE default)  
* Attributes are (generally) preserved even when you subset  
* The "xts" object is a subset of "zoo", meaning that it preserves all the power of the "zoo" capability  
  
The "xts" object can be de-constructed when needed:  
  
* coredata(x, fmt=FALSE) brings back the matrix  
* index(x) brings back the index  
  
Data usually already exists and needs to be "wrangled" in to a proper format for xts/zoo.  The easiest way to convert is using as.xts().  You can coerce truly external data after loading it, and can also save data with Can also save with write.zoo(x, "file").  

Subsetting based on time is a particular strength of xts.  xts supports ISO8601:2004 (the standard, "right way", to unambiguously consider times):  
  
* Moving left-to-right for the most significant to least significant impact  
* YYYY-MM-DDTHH:MM:SS format  
* Specifying only the year (e.g., 2014) is fine, while specifying only the month (e.g., "02") is not  
  
xts allows for four methods of specifying dates or intervals:  
  
1) One and two-sided intervals ("2004" or "2001/2005")  
2) Truncated representation ("201402/03")  
3) Time support ("2014-02-22 08:30:00")  
4) Repeating intervals ("T08:00/T09:00")  
  
Can also use some traditional R-like methods (since xts extends zoo, and zoo extends base R):  
  
* Integer indexing - x[c(1, 2, 3), ]  
* Logical vectors - x[index(x) > "2016-08-20"]  
* Date objects - x[index(as.POSIXct(c("2016-06-25", "2016-06-27")))]  
  
Can set the flag which.i = TRUE to get back the correct records (row numbers).  For example, index <- x["2007-06-26/2007-06-28", which.i = TRUE].  
  
Description of key behaviors when working with an xts object:  
  
* All subsets will preserve the matrix (drop=FALSE)  
* Order is always preserved - cannot intentionally or uninetntionally reorder the data - requesting c(1, 2) or c(2, 1) returns the same thing  
* Binary search and memcpy are leveraged, meaning that it works faster than base R  
* Index and object attributes are always preserved  
  
xts introduces a few relatives of the head() and tail() functionality.  These are the first() and last() functions.  
  
* first(edhec[, "Funds of Funds"], "4 months")  
* last(edhec[, "Funds of Funds"], "1 year")  
* Can uses a negative to mean "except", such as "-4 months"  
* The first() and last() can be nested within one another  

Math operations using xts - xts is a matrix - need to be careful about matrix operations.  Math operations are run only on the intersection of items:  
  
* Only the intersecting observations will be (for example) added together -- others are dropped! 
* Sometimes it may be necessary to drop the xts class -- drop=TRUE, coredata(), as.numeric(), etc.  
* Special handling (described in the next chapter) may be needed when you want the union of dates  
  
Merging time series is common.  Merge (cbind, merge) combines by columns, but joining based on index.  
  
* Syntax is merge (<time series to merge>, join="outer", fill=NA)  # Defaults are "outer" and NA
join can also be "inner", "left", or "right"  
* fill is available to allow missing values to be coerced as needed  
* If you merge(x, as.Date(c("2016-08-14"))) then you will have a new date (2016-08-14) in your database  
  
Merge (rbind( combine by rows, though all rows must already have an index.  Basically, the rbind MUST be used on a time series.  
  
Missing data is common, and xts inherits all of the zoo methods for dealing with missing data.  The locf is the "last observation carry forward" (latest value that is not NA) - called with na.locf:  
  
* na.locf(object, na.rm=TRUE, fromLast = FALSE, maxgap = Inf)  
* Generic function for replacing eachNAwith the most recent non-NAprior to it.  
  
The NA can be managed in several ways:  
  
* na.fill(object, fill, . )  # fill the NA with the fill value  
* na.trim(object, . )  # remove NA that are at the beginning or end  
* na.omit(object, . )  # remove all NA  
* na.approx(object, . )  # interpolate NA based on distance from object  
  
Lag operators and difference operations.  Seasonality is a repeating pattern.  There is often a need to compare seasonality -- for example, compare Mondays.  Stationarity refers to some bound of the series.
  
The lag() function will change the timestamp, so that (for example) today can be merged as last week:  
  
* lag(x, k=1, na.pad=TRUE, . )  # positive k will shift the values FORWARD  
* Note that base R and zoo are the opposite, where lag(k=<negative>) means move forward  
* This is not what the literature recommends, and zoo follows the literature, with k=<positive> shifting time forward  
  
The "one period lag first difference" is calculated as diff(x, lag=1, differences=1, arithmetic=TRUE, log=FALSE, na.pad=TRUE, . ).
  
There are two main approaches for applying functions on discrete periods or intervals:  
  
* period.apply(x, INDEX, FUN, . )  
    * INDEX should be a vector of end-points of a period  
    * The end-point will be the last observation per interval  
        * endpoints(x, on="years") will create an endpoint vector by year  ## can be "days" or "seconds" or the like; always starts with 0  
    * data(PerformanceAnalytics::edhec); edhec_4yr <- edhec["1997/2001"]; ep <- endpoints(edhec_4yr, "years"); period.apply(edhec_4yr, INDEX=ep, FUN=mean)  
    * There are shortcut functions like apply.yearly() which take care of all the indexing and endpoints automatically  
* split(x, f="months")  
    * This will split the data by month  
    * Outcome would be a list by months  
  
Time series aggregation can also be handled by xts:  
  
* Useful to convert a univariate series to range bars (OHLC = Open, High, Low, Close)  
    * Provides a summary of a particular period - start, max, min, end  
    * to.period(x, period="months", k=1, indexAt, name=NULL, OHLC=TRUE, . )  
        * indexAt lets you adjust labelling of outputs (default is end of period), while name lets you define the roots used in the columns  
    * to.period(edhec["1997/2001", 1], "years", name="EDHEC")  
    * to.period(edhec["1997/2001", 1], "years", name="EDHEC", indexAt="firstof")  
    * to.period(edhec["1997/2001", 1], "years", name="EDHEC", OHLC=FALSE)  # will pull the last observation only  
  
Time series data can also be managed in a "rolling" manner - discrete or continuous:  
  
* Discrete rolling windows would be things like "month to date"  
    * split() followed by lapply() using FUN=cumsum, cumprod, cummin, cummax  
    * edhec.yrs <- split(edhec[, 1], f="years")  
    * edhec.yrs <- lapply(edhec.yrs, FUN=cumsum)  
    * edhec.ytd <- do.call(rbind, edhec.yrs)  
* Continuous rolling windows are managed through:  
    * rollapply(data, width, FUN, . , by=1, by.column = TRUE, fill= if (na.pad) NA, na.pad=TRUE, partial=TRUE, align=c("right", "center", "left"))  
  
Internals of xts such as indices and timezones:  
  
* The index is always stored as fractional seconds since midnight 1970-01-01 UTC  
* xts will use tclass (attribute for extraction) - if you passed in a date, you get back a date -- indexClass()  
* xts will use tzone (attribute for time zone) -- indexTZ()  
* xts will use indexFormat (attribute for optional display preferences) -- indexFormat() <- <valid sprintf command>  
* Sys.setenv(TZ = "America/Chicago")  
    * help(OlsonNames)  
  
Final topics:  
  
* Periodicity - identify underlying regularity in the data (what type of data do we have)  
    * May be irregular data, so this is just an estimate -- periodicity()  
* Counting -- number of discrete periods (unique endpoints) -- note that monthly data has the same answer for ndays() and nmonths()  
    * Only makes sense to count periods if the data have HIGHER frequency than what you are trying to count  
* Broken down time can be extracted with .index  
    * index(Z); .indexmday(Z) # month day; .indexyday(Z) # year day; .indexyear(Z) + 1900  
* Can align timing -- align.time(x, n=60) # n is in seconds  
    * make.index.unique(x, eps=1e-06, drop=FALSE, fromLast=FALSE, . ) will help to manage duplicates  
  
Example code includes:  
```{r}
library(xts)
library(zoo)

x <- matrix(data=1:4, ncol=2)
idx <- as.Date(c("2015-01-01", "2015-02-01"))

# Create the xts
X <- xts(x, order.by = idx)

# Decosntruct the xts
coredata(X, fmt=FALSE)
index(X)

# Working with the sunspots data
data(sunspots)
class(sunspots)
sunspots_xts <- as.xts(sunspots)
class(sunspots_xts)
head(sunspots_xts)

# Example from chapter #1
ex_matrix <- xts(matrix(data=c(1, 1, 1, 2, 2, 2), ncol=2), 
                 order.by=as.Date(c("2016-06-01", "2016-06-02", "2016-06-03"))
                 )
core <- coredata(ex_matrix)

# View the structure of ex_matrix
str(ex_matrix)

# Extract the 3rd observation of the 2nd column of ex_matrix
ex_matrix[3, 2]

# Extract the 3rd observation of the 2nd column of core 
core[3, 2]

# Create the object data using 5 random numbers
data <- rnorm(5)

# Create dates as a Date class object starting from 2016-01-01
dates <- seq(as.Date("2016-01-01"), length = 5, by = "days")

# Use xts() to create smith
smith <- xts(x = data, order.by = dates)

# Create bday (1899-05-08) using a POSIXct date class object
bday <- as.POSIXct("1899-05-08")

# Create hayek and add a new attribute called born
hayek <- xts(x = data, order.by = dates, born = bday)

# Extract the core data of hayek
hayek_core <- coredata(hayek)

# View the class of hayek_core
class(hayek_core)

# Extract the index of hayek
hayek_index <- index(hayek)

# View the class of hayek_index
class(hayek_index)

# Create dates
dates <- as.Date("2016-01-01") + 0:4

# Create ts_a
ts_a <- xts(x = 1:5, order.by = dates)

# Create ts_b
ts_b <- xts(x = 1:5, order.by = as.POSIXct(dates))

# Extract the rows of ts_a using the index of ts_b
ts_a[index(ts_b)]

# Extract the rows of ts_b using the index of ts_a
ts_b[index(ts_a)]


data(austres)

# Convert austres to an xts object called au
au <- as.xts(austres)

# Convert your xts object (au) into a matrix am
am <- as.matrix(au)

# Convert the original austres into a matrix am2
am2 <- as.matrix(austres)

# Create dat by reading tmp_file
tmp_file <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1127/datasets/tmp_file.csv"
dat <- read.csv(tmp_file)  

# Convert dat into xts
xts(dat, order.by = as.Date(rownames(dat), "%m/%d/%Y"))

# Read tmp_file using read.zoo
dat_zoo <- read.zoo(tmp_file, index.column = 0, sep = ",", format = "%m/%d/%Y")

# Convert dat_zoo to xts
dat_xts <- as.xts(dat_zoo)

# Convert sunspots to xts using as.xts(). Save this as sunspots_xts
sunspots_xts <- as.xts(sunspots)

# Get the temporary file name
tmp <- tempfile()

# Write the xts object using zoo to tmp 
write.zoo(sunspots_xts, sep = ",", file = tmp)

# Read the tmp file. FUN = as.yearmon converts strings such as Jan 1749 into a proper time class
sun <- read.zoo(tmp, sep = ",", FUN = as.yearmon)

# Convert sun into xts. Save this as sun_xts
sun_xts <- as.xts(sun)



data(edhec, package="PerformanceAnalytics")

head(edhec["2007-01", 1])
head(edhec["2007-01/2007-03", 1])
head(edhec["200701/03", 1])

first(edhec[, "Funds of Funds"], "4 months")
last(edhec[, "Funds of Funds"], "1 year")



```
  
