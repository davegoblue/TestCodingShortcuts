---
title: "Test Parallel"
author: "davegoblue"
date: "May 3, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview and Background  
The parallel package in R allows for some very nice improvements in run time.  So far, I have been using 3 workers with Windows (number of threads minus 1), but I am curious more generally about the gains driven by parallel.  This program is a first effort to test speed vs. number of clusters.  
  
## Analysis  
First, the parallel and doParalel libraries are called, and information about the specific setup is printed:  
```{r}
library(parallel)
library(doParallel)

nLogical <- detectCores() ## defaults to logical=TRUE
nCore <- detectCores(logical=FALSE) ## will only find physical cores

print(paste0("This set-up has ",nLogical," cores, with ",nCore," being physical cores."))
```
  
Next, a time-waster function is set-up.  This function is designed to repeatedly do the maths on a vector, then to return the final vector.  It is purely to get the CPU cranking; there is no other purpose to the function:  
  
```{r}
timeWaster <- function(vecLen=factorial(8), nRuns=factorial(8)) {
    vecTemp <- rep(0, vecLen) ## Create numeric vector
    vecMeans <- rep(0, nRuns) ## Create the storage vector
    
    for (intCtr in 1:nRuns) {
        vecTemp <- vecTemp * rnorm(vecLen)
        vecTemp <- vecTemp + rnorm(vecLen)
        vecMeans[intCtr] <- mean(vecTemp)
    }
    
    return(vecMeans)
}
```
  
First, the time waster function is called sequentially (normally) for a timing benchmark:  
```{r, cache=TRUE}
baseTime <- proc.time()

temp <- timeWaster()
str(temp)
summary(temp)

seqTime <- proc.time() - baseTime

print("Ran sequentially: Time taken")
print(seqTime)
```
  
Next, the parallel processing routine is called with the following parameters:  
  
* The number of clusters will be the number of logical clusters minus 1 (3 total on my machine)  
* Each cluster will run the same timeWaster() function; importantly, there is no splitting up of the workload, so the 3 parallel clusters will do (in aggregate) 3 times as much work  
* Processing will run by way of foreach() %dopar% with .combine=c (concatenate it all in to one jumbo vector)  
  
The intent of the above is to establish a baseline for the inefficiencies introduced by running in parallel.  The machine needs to create its clusters, parse out work to them, and integrate their results.  This is sort of a fixed cost that will (likely) never be overcome.  
```{r, cache=TRUE}
baseTime <- proc.time()

nPars <- nLogical - 1 ## Default is to save 1 logical core for other processing
clCores <- makeCluster(nPars)
registerDoParallel(clCores)

temp <- foreach(parCtr=1:nPars, .combine=c) %dopar% {
    timeWaster()
}

stopCluster(clCores)
registerDoSEQ()

str(temp)
summary(temp)

parTime <- proc.time() - baseTime

print("Ran in parallel: Time taken")
print(parTime)
```
  
The parallel run is doing 300% of the work in ~140% of the time, suggestive of just over a 50% decrease in elapsed time per unit of work.  

Next, the parallel process is run more properly, with nRuns divided by the number of clusters.  As the same total volume of work will be completed, the time comparison will be more interesting:  
```{r, cache=TRUE}
baseTime <- proc.time()

nPars <- nLogical - 1 ## Default is to save 1 logical core for other processing
clCores <- makeCluster(nPars)
registerDoParallel(clCores)

## Yes, the below is mathematically a mess if you want timeWaster() to do "real" analysis!
temp <- foreach(parCtr=1:nPars, .combine=c) %dopar% {
    timeWaster(nRuns=ceiling(factorial(8)/3))
}

stopCluster(clCores)
registerDoSEQ()

str(temp)
summary(temp)

parSameTime <- proc.time() - baseTime

print("Ran in parallel for same workload: Time taken")
print(parSameTime)
```
  
The parallel process is now doing 100% of the sequential workload in ~45% of the sequential time.  
  
An additional question of interest is whether the parallel process has a "fixed" inefficiency or a scalable inefficiency.  This can be assessed by putting the routine to work on jobs of various sizes.  For example, we could try the following:  
  
* Parallel has just been run for the defaults of vecLen=factorial(8), nRuns=factorial(8)/3 but 3 times    
* Suppose we triple vecLen to be 3 * factorial(8) and see how the processing time scales  
* Suppose we also triple nRuns to be factorial(8) run three times and see how the processing time scales  
  
```{r, cache=TRUE}
## Run with triple vecLen
baseTime <- proc.time()

nPars <- nLogical - 1 ## Default is to save 1 logical core for other processing
clCores <- makeCluster(nPars)
registerDoParallel(clCores)

## Yes, the below is mathematically a mess if you want timeWaster() to do "real" analysis!
temp <- foreach(parCtr=1:nPars, .combine=c) %dopar% {
    timeWaster(vecLen=3*factorial(8), nRuns=ceiling(factorial(8)/3))
}

stopCluster(clCores)
registerDoSEQ()

str(temp)
summary(temp)

parTripLenTime <- proc.time() - baseTime

print("Ran in parallel for triple workload (due vecLen): Time taken")
print(parTripLenTime)
```
  
This routine takes roughly triple the time and does roughly triple the work, suggestive that there is a scalable inefficiency more so than a fixed inefficiency.  
  
We then run the same routine but for triple vecLen AND triple nRuns:  
```{r, cache=TRUE}
## Run with triple vecLen and triple nRuns (each of three parallel doing full nRuns)
baseTime <- proc.time()

nPars <- nLogical - 1 ## Default is to save 1 logical core for other processing
clCores <- makeCluster(nPars)
registerDoParallel(clCores)

## Yes, the below is mathematically a mess if you want timeWaster() to do "real" analysis!
temp <- foreach(parCtr=1:nPars, .combine=c) %dopar% {
    timeWaster(vecLen=3*factorial(8), nRuns=ceiling(factorial(8)))
}

stopCluster(clCores)
registerDoSEQ()

str(temp)
summary(temp)

parNineTime <- proc.time() - baseTime

print("Ran in parallel for 9x workload (due triple vecLen and triple nRuns): Time taken")
print(parNineTime)
```
  
This routine does ~900% of the base parallel work and take ~900% of the base parallel processing time, again suggestive that (at least for how this function works) there are few economies of scale.  
  
The above have all been cached so that we can next explore the impact of changing the number of clusters.  