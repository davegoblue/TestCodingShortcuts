---
title: "Mapping and Plotting"
author: "davegoblue"
date: "3/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background

This document is to provide some plotting examples for reference.

***

#### _Example #1: US State and County Maps_ 
The package usmap contains maps of US states and counties.  There is also some associated data available about state and county demographics.

Example code includes:  
```{r}

library(tidyverse)

# Population by county
data(countypop, package="usmap")
# Population by state
data(statepop, package="usmap")
# Poverty rate by county
data(countypov, package="usmap")
# Poverty rate by state
data(statepov, package="usmap")
# Population of largest city by state
data(citypop, package="usmap")
# Location of earthquakes
data(earthquakes, package="usmap")


# Included datasets
countypop
statepop
countypov
statepov
citypop
earthquakes

# Basic, empty US maps
usmap::plot_usmap(regions="states")
usmap::plot_usmap(regions="counties")

# Basic, empty US maps subsetted to an area
usmap::plot_usmap(regions="states", 
                  include=c("WA", "OR", "CA", "NV", "ID", "MT", "WY", "UT", "CO", "AZ", "NM")
                  )
usmap::plot_usmap(regions="counties", include=c("MN", "WI", "MI", "OH", "PA", "NY", "IN", "IL"))

# Basic, subsetted state map with poverty rates included
usmap::plot_usmap(regions="states", 
                  include=c("WA", "OR", "CA", "NV", "ID", "MT", "WY", "UT", "CO", "AZ", "NM"), 
                  values="pct_pov_2014", data=statepov, labels=TRUE
                  ) + 
    scale_fill_continuous(low="lightblue", high="darkblue", "Poverty Rate (%)") + 
    labs(title="Poverty Rates by Western and Mountain States")

# Basic, subsetted county map with poverty rates included
usmap::plot_usmap(regions="counties", include=c("MN", "WI", "MI", "OH", "PA", "NY", "IN", "IL"),
                  values="pct_pov_2014", data=countypov, labels=FALSE
                  ) + 
    scale_fill_continuous(low="lightblue", high="darkblue", "Poverty Rate (%)") + 
    labs(title="Poverty Rates by County in Great Lakes States")

```

#### _Example #2: Converting and adding lat/lon data_ 
The latitude and longitude data can be converted to a form suitable for usmap by using the usmap_transform function.

Example code includes:  
```{r}

# Transform the earthquakes data
trQuakes <- usmap::usmap_transform(earthquakes)
str(trQuakes)

# Add as a layer to the state map
usmap::plot_usmap(regions="states") + 
    geom_point(data=trQuakes, aes(x=lon.1, y=lat.1, size=mag), alpha=0.4) + 
    labs(title="Earthquakes of Magnitude 2.5+ (H1 2019)")

# Transform the largest city data
trCity <- usmap::usmap_transform(citypop)
str(trCity)

# Add as a layer to the state map
usmap::plot_usmap(regions="states") + 
    geom_point(data=trCity, aes(x=lon.1, y=lat.1, size=city_pop)) + 
    labs(title="Largest City by State")

```
  
#### _Example #3: Filtering and coloring by region_ 
The census region definitions are included, and can be used to filter or color the maps.

Example code includes:  
```{r}

# Filter the map to include only new_england, mid_atlantic, and south_atlantic
usmap::plot_usmap(regions="states", 
                  include=c(usmap::.new_england, usmap::.mid_atlantic, usmap::.south_atlantic)
                  )

# Create regions data for US states
regionData <- usmap::statepop %>%
    mutate(region=as.factor(ifelse(abbr %in% usmap::.midwest_region, 1, 0)))
usmap::plot_usmap(regions="states", data=regionData, values="region") + 
    scale_fill_discrete("Midwest") + 
    labs(title="Midwest Region US States")

# Enhanced Coloring and Labelling
usmap::plot_usmap(regions="states", data=regionData, values="region") + 
    scale_fill_manual(values=c("lightgray", "lightblue"), "", labels=c("Other", "Midwest")) + 
    labs(title="Midwest Region US States")

```

#### _Example #4: Labelling geographies_ 
Since usmap is built on ggplot2, the standard techniques from ggplot2 can be used to enhance the geography labelling.  Further, centroids for the geographies are available in loadable files.

Example code includes:  
```{r}

# Base state map labelled with defaults
usmap::plot_usmap(regions="states", labels=TRUE, label_color="red")

# Base county map labelled with defaults
usmap::plot_usmap(regions="counties", include=c("TX", "OK"), labels=TRUE, label_color="grey")

# Load state centroid data
stCenter <- utils::read.csv(system.file("extdata", 
                                        paste0("us_", "states", "_centroids.csv"), package = "usmap"
                                        ),
                            colClasses = c(rep("numeric", 2), rep("character", 3)), stringsAsFactors = FALSE
                            )

# Load county centroid data
ctCenter <- utils::read.csv(system.file("extdata", 
                                        paste0("us_", "counties", "_centroids.csv"), package = "usmap"
                                        ),
                            colClasses = c(rep("numeric", 2), rep("character", 4)), stringsAsFactors = FALSE
                            )

# Add state labels using geom_text
regionData <- usmap::statepop %>%
    mutate(region=as.factor(ifelse(abbr %in% usmap::.midwest_region, 1, 0))) %>%
    left_join(stCenter %>% select(x, y, full, fips) %>% rename(fname=full)) %>%
    mutate(fname=ifelse(fname=="District of Columbia", "DC", str_replace_all(fname, " ", "\n")))

usmap::plot_usmap(regions="states", data=regionData[, c("fips", "region")], values="region") + 
    scale_fill_manual(values=c("lightgray", "lightblue"), "", labels=c("Other", "Midwest")) + 
    labs(title="Midwest Region US States") + 
    geom_text(data=filter(regionData, region==1), aes(x=x, y=y, label=fname), size=2.5)


# Add county labels using geom_text
regionData <- usmap::countypop %>%
    mutate(region=as.factor(case_when(abbr=="OK" ~ 1, abbr=="TX" ~ 2, TRUE ~ 0))) %>%
    left_join(ctCenter %>% select(x, y, county, fips) %>% rename(cname=county)) %>%
    mutate(cname=str_replace_all(str_replace(cname, " County", ""), " ", "\n"))

usmap::plot_usmap(regions="counties", include=c("TX", "OK"), 
                  data=regionData[, c("fips", "region")], values="region") + 
    scale_fill_manual(values=c("red", "orange"), "", labels=c("Oklahoma", "Texas")) + 
    labs(title="Texas and Oklahoma Counties") + 
    geom_text(data=filter(regionData, abbr %in% c("TX", "OK")), 
              aes(x=x, y=y, label=cname), size=2.5, 
              color=ifelse(pull(filter(regionData, abbr %in% c("TX", "OK")), abbr)=="OK", "white", "black")
              )

```

#### _Example #5: Adding population centers_ 
Separate data exists for key population centers, which can be loaded and then added to maps.

Example code includes:  
```{r}

# Transform the largest city data
str(maps::us.cities)
trCity <- usmap::usmap_transform(select(maps::us.cities, long, lat, everything())) %>% 
    mutate(useName=str_replace_all(str_sub(name, 1, -4), " ", "\n"))
str(trCity)

# Define a key region for plotting
rgnPlot <- c(usmap::.west_south_central, usmap::.east_south_central)
popFilter <- 100000

# Add cities as a layer to the state map
usmap::plot_usmap(regions="states", include=rgnPlot, fill="lightblue") + 
    labs(title=paste0("South Central Cities with Population >= ", popFilter/1000, "k")) + 
    geom_point(data=filter(trCity, pop >= popFilter, country.etc %in% rgnPlot), 
               aes(x=long.1, y=lat.1, size=pop), alpha=0.5
               )

# Plot the full nation for cities of 250k +
rgnPlot <- c(usmap::.midwest_region, usmap::.northeast_region, 
             usmap::.south_region, usmap::.west_region
             )
popFilter <- 250000

# Add cities as a layer to the state map
usmap::plot_usmap(regions="states", include=rgnPlot, fill="lightblue") + 
    labs(title=paste0("US Cities with Population >= ", popFilter/1000, "k")) + 
    geom_point(data=filter(trCity, pop >= popFilter, country.etc %in% rgnPlot), 
               aes(x=long.1, y=lat.1, size=pop), alpha=0.5
               )

# Plot cities by name for the Four Corners region
rgnPlot <- c("UT", "CO", "NM", "AZ")
popFilter <- 125000

# Add cities as a layer to the state map (points)
usmap::plot_usmap(regions="counties", include=rgnPlot, fill="lightblue") + 
    labs(title=paste0("Four Corners Cities with Population >= ", popFilter/1000, "k")) + 
    geom_point(data=filter(trCity, pop >= popFilter, country.etc %in% rgnPlot), 
               aes(x=long.1, y=lat.1, size=pop), alpha=0.5
               )

# Add cities as a layer to the state map (text)
usmap::plot_usmap(regions="counties", include=rgnPlot, fill="lightblue") + 
    labs(title=paste0("Four Corners Cities with Population >= ", popFilter/1000, "k")) + 
    geom_text(data=filter(trCity, pop >= popFilter, country.etc %in% rgnPlot), 
               aes(x=long.1, y=lat.1, size=pop, label=useName)
               )

popFilter <- 50000
popFilter2 <- 250000

# Add cities as a layer to the state map (points and text)
usmap::plot_usmap(regions="counties", include=rgnPlot, fill="lightblue") + 
    labs(title=paste0("Four Corners Cities with Population >= ", popFilter/1000, "k")) + 
    geom_point(data=filter(trCity, pop >= popFilter, country.etc %in% rgnPlot), 
               aes(x=long.1, y=lat.1, size=pop), alpha=0.5
               ) + 
    geom_text(data=filter(trCity, pop >= popFilter2, country.etc %in% rgnPlot), 
               aes(x=long.1, y=lat.1, size=pop, label=useName), color="red", show.legend=FALSE
               )

```
  
#### _Example #6: Custom coloring geographies_  
Using scale_fill_manual(), custom colors can be created by geography.

Example code includes:  
```{r}

# Basic county population map with continuous colors
usmap::countypop %>% 
    filter(abbr %in% c("OH", "IN", "KY")) %>% 
    mutate(pop=pop_2015/1000, name=str_replace(str_replace(county, " County", ""), " ", "\n")) %>%
    usmap::plot_usmap(regions="counties", include=c("OH", "IN", "KY"), data=., values="pop") +
    scale_fill_continuous(low="lightblue", high="darkblue", "Pop. (000)") + 
    labs(title="Indiana, Ohio, and Kentucky - Population by County")

# Custom county population map with colors - red for Indiana, blue for Kentucky, grey for Ohio
popBucket <- c(0, 100, 500)
popLabels <- sapply(1:(length(popBucket)-1), FUN=function(x){paste0(popBucket[x], "-", popBucket[x+1])})
popLabels <- c(popLabels, paste0(popBucket[length(popBucket)], "+"))
guideLabels <- paste(rep(c("OH", "KY", "IN"), each=3), popLabels)

usmap::countypop %>% 
    filter(abbr %in% c("OH", "KY", "IN")) %>% 
    mutate(pop=pop_2015/1000, name=str_replace(str_replace(county, " County", ""), " ", "\n"), 
           pBucket=findInterval(pop, popBucket), 
           pColor=rgb(abbr=="IN", 0, abbr=="KY", pBucket/length(popBucket))
           ) %>%
    usmap::plot_usmap(regions="counties", include=c("OH", "IN", "KY"), data=., values="pColor") +
    scale_fill_identity(guide="legend", "Pop. (000)", labels=guideLabels) + 
    labs(title="Indiana, Ohio, and Kentucky - Population by County") + 
    theme(legend.position = "bottom") + 
    guides(fill=guide_legend(nrow=3))

# Custom county poverty rate map with colors - red for Indiana, blue for Kentucky, grey for Ohio
povBucket <- c(0, 15, 30)
povLabels <- sapply(1:(length(povBucket)-1), FUN=function(x){paste0(povBucket[x], "-", povBucket[x+1])})
povLabels <- c(povLabels, paste0(povBucket[length(povBucket)], "+"))
guideLabels <- paste(rep(c("OH", "KY", "IN"), each=3), povLabels)

usmap::countypov %>% 
    filter(abbr %in% c("OH", "KY", "IN")) %>% 
    mutate(name=str_replace(str_replace(county, " County", ""), " ", "\n"), 
           pBucket=findInterval(pct_pov_2014, povBucket), 
           pColor=rgb(abbr=="IN", 0, abbr=="KY", pBucket/length(povBucket))
           ) %>%
    usmap::plot_usmap(regions="counties", include=c("OH", "IN", "KY"), data=., values="pColor") +
    scale_fill_identity(guide="legend", "Poverty Rate (%)", labels=guideLabels) + 
    labs(title="Indiana, Ohio, and Kentucky - Poverty Rate by County") + 
    theme(legend.position = "bottom") + 
    guides(fill=guide_legend(nrow=3))

```

#### _Example #7: Custom labeling of key geographies_  
The above techniques can be combined for custom labeling of key geographies.

Example code includes:  
```{r}

# Basic state population data
stateData <- usmap::statepop %>% 
    mutate(pop=round(pop_2015/1000000, 1), 
           name=ifelse(full=="District of Columbia", "DC", str_replace(full, " ", "\n")), 
           lab=paste0(abbr, "\n(", pop, ")\n")
           )

# Load state centroid data
stCenter <- utils::read.csv(system.file("extdata", 
                                        paste0("us_", "states", "_centroids.csv"), package = "usmap"
                                        ),
                            colClasses = c(rep("numeric", 2), rep("character", 3)), stringsAsFactors = FALSE
                            )

# Grab centroids for top 5 states
top5State <- stateData %>%
    top_n(5, pop) %>% 
    left_join(select(stCenter, x, y, fips))

# Plot state population with continuous colors and custom labels
stateData %>% 
    usmap::plot_usmap(regions="states", data=., values="pop") +
    scale_fill_continuous(low="lightblue", high="darkblue", "Pop. (millions)") + 
    labs(title="Population by State", subtitle="Top 5 in millions") + 
    geom_text(data=top5State, aes(x=x, y=y, label=lab), color="white", size=4, fontface="bold")


# Load county centroid data
ctCenter <- utils::read.csv(system.file("extdata", 
                                        paste0("us_", "counties", "_centroids.csv"), package = "usmap"
                                        ),
                            colClasses = c(rep("numeric", 2), rep("character", 4)), stringsAsFactors = FALSE
                            )

# Custom county population map with colors - red for Wisconsin, blue for Michigan
popBucket <- c(0, 100, 500)
popLabels <- sapply(1:(length(popBucket)-1), FUN=function(x){paste0(popBucket[x], "-", popBucket[x+1])})
popLabels <- c(popLabels, paste0(popBucket[length(popBucket)], "+"))
guideLabels <- paste(rep(c("MI", "WI"), each=3), popLabels)

# Grab county data for counties exceeding the top popBucket
ctyData <- usmap::countypop %>%
    filter(abbr %in% c("MI", "WI")) %>%
    mutate(pop=round(pop_2015/1000, 0), 
           name=str_replace(str_replace(county, " County", ""), " ", "\n"), 
           lab=paste0(name, "\n(", pop, ")\n")
           )

topCounty <- ctyData %>%
    filter(pop >= max(popBucket)) %>%
    left_join(select(ctCenter, x, y, fips))

# Create county population map
usmap::countypop %>% 
    filter(abbr %in% c("MI", "WI")) %>% 
    mutate(pop=pop_2015/1000, name=str_replace(str_replace(county, " County", ""), " ", "\n"), 
           pBucket=findInterval(pop, popBucket), 
           pColor=rgb(abbr=="WI", 0, abbr=="MI", pBucket/length(popBucket))
           ) %>%
    usmap::plot_usmap(regions="counties", include=c("WI", "MI"), data=., values="pColor") +
    scale_fill_identity(guide="legend", "Pop. (000)", labels=guideLabels) + 
    geom_text(data=topCounty, aes(x=x, y=y, label=lab), size=3, fontface="bold", color="white") +
    labs(title="Michigan and Wisconsin - Population by County", subtitle="Labelled Pop. (000) for 500k+") + 
    theme(legend.position = "bottom") + 
    guides(fill=guide_legend(nrow=3)) + 
    theme(panel.background=element_rect(color="black", fill="lightgrey"))

```

#### _Example #8: Plotting Weather Data (Temperatures and Dew Points)_  
The ggridges package has weather data for Lincoln, NE in the data file 'lincoln_weather'.  The data are captured once per day for 366 days of 2016.  Simple plots can be made of the average temperatures and dew points.

Example code includes:  
```{r}

data(lincoln_weather, package="ggridges")
str(lincoln_weather, give.attr=FALSE)

# Extract temperature and dew point data
tdData <- lincoln_weather %>%
    select(CST, maxT=`Max Temperature [F]`, minT=`Min Temperature [F]`, meanT=`Mean Temperature [F]`, 
           maxD=`Max Dew Point [F]`, minD=`Min Dewpoint [F]`, meanD=`Mean Dew Point [F]`
           ) %>%
    mutate(date=as.Date(CST))
str(tdData)

# Plot temperatures by day
tdData %>%
    select(date, maxT, meanT, minT) %>%
    pivot_longer(-date) %>%
    ggplot(aes(x=date, y=value, group=name)) + 
    geom_line(aes(color=name))

# Plot dew points by day
tdData %>%
    select(date, maxD, meanD, minD) %>%
    pivot_longer(-date) %>%
    ggplot(aes(x=date, y=value, group=name)) + 
    geom_line(aes(color=name))


library(xts)

# Create an XTS for temperature data
tdXTS <- xts(select(tdData, minT, meanT, maxT), order.by=tdData$date)

# Create and plot weekly and monthly averages
tdXTS %>%
    apply.weekly(FUN=mean, na.rm=TRUE) %>%
    plot(main="Weekly Temperature Average (Lincoln, NE 2016)")

tdXTS %>%
    apply.monthly(FUN=mean, na.rm=TRUE) %>%
    plot(main="Monthly Temperature Average (Lincoln, NE 2016)")


# Create an XTS for dew-point data
tdXTS <- xts(select(tdData, minD, meanD, maxD), order.by=tdData$date)

# Create and plot weekly and monthly averages
tdXTS %>%
    apply.weekly(FUN=mean, na.rm=TRUE) %>%
    plot(main="Weekly Dew Point Average (Lincoln, NE 2016)")

tdXTS %>%
    apply.monthly(FUN=mean, na.rm=TRUE) %>%
    plot(main="Monthly Dew Point Average (Lincoln, NE 2016)")

```

#### _Example #9: Combining xts and ggplot2_  
The xts package is good for working with time series data, while ggplot2 is strong for customizing plots.  The packages can be combined in using the weather data.

Example code includes:  
```{r}

# Create an XTS for temperature and dewpoint data
tdXTS <- xts(select(tdData, minT, meanT, maxT, minD, meanD, maxD), order.by=tdData$date)

# Use xts for monthly average and ggplot2 for plotting
basePlot <- tdXTS %>%
    apply.monthly(FUN=mean, na.rm=TRUE) %>% 
    data.frame(date=index(.), row.names=NULL) %>% 
    ggplot(aes(x=date-lubridate::days(15))) + 
    geom_ribbon(aes(ymin=minT, ymax=maxT), color="lightblue", fill="lightblue", alpha=0.5) +
    geom_line(aes(y=meanT), color="blue", lwd=1) + 
    labs(x="Month", y="Avg. Temperature (F)", title="Lincoln, NE Weather (2016)", 
         subtitle="Monthly Avg. Temperature (F)"
         )
basePlot

# Add labelling for the three elements
hiMonth <- index(tdXTS %>% apply.monthly(FUN=mean))[3]
loMonth <- index(tdXTS %>% apply.monthly(FUN=mean))[9]
muMonth <- index(tdXTS %>% apply.monthly(FUN=mean))[6]
hiPoint <- c(60, 75)
loPoint <- c(45, 25)
muPoint <- c(72.5, 45)

labFrame <- data.frame(x=c(hiMonth, loMonth, muMonth), 
                       yend=c(hiPoint[1], loPoint[1], muPoint[1]),
                       y=c(hiPoint[2], loPoint[2], muPoint[2]), 
                       text=c("Avg. Monthly High", "Avg. Monthly Low", "Avg. Monthly Mean")) %>%
    mutate(xend=x)

basePlot + 
    geom_segment(data=labFrame, aes(x=x, y=y, xend=xend, yend=yend), arrow=arrow()) + 
    geom_text(data=labFrame, aes(x=x, y=y+c(5, -5, -5), label=text), fontface="bold", size=4)


# Can also create and plot a custom rolling average
baseData <- tdXTS %>%
    data.frame(date=index(.), row.names=NULL)

base7Day <- rollapply(tdXTS, 7, FUN=mean, na.rm=TRUE) %>% 
    data.frame(date=index(.), row.names=NULL)

base30Day <- rollapply(tdXTS, 30, FUN=mean, na.rm=TRUE) %>% 
    data.frame(date=index(.), row.names=NULL)

plotFrame <- bind_rows(baseData, base7Day, base30Day, .id="rolling") %>%
    mutate(rollLabel=case_when(rolling==1 ~ "Daily", 
                               rolling==2 ~ "7 Day Rolling", 
                               rolling==3 ~ "30 Day Rolling",
                               TRUE ~ "ERROR"
                               )
           )
            
plotFrame %>%
    ggplot(aes(x=date)) + 
    geom_line(aes(y=meanT, color=rollLabel, group=rollLabel), lwd=1) + 
    labs(x="Month", y="Avg. Temperature (F)", title="Lincoln, NE Weather (2016)", 
         subtitle="Daily Avg. Temperature (F)"
         )

```

#### _Example #10: Plotting Weather Data (Humidity)_  
Humidity data are also available in the lincoln_weather dataset.  There is a relationship between temperature, dewpoint, and humidity.

Example code includes:  
```{r}

htdData <- lincoln_weather %>%
    select(CST, meanT=`Mean Temperature [F]`, meanD=`Mean Dew Point [F]`, meanH=`Mean Humidity`) %>%
    mutate(date=as.Date(CST), month=lubridate::month(date))
str(htdData)

# Histogram for average humidity
htdData %>%
    ggplot(aes(x=meanH)) + 
    geom_histogram() + 
    labs(title="Mean Humidity Histogram", subtitle="Lincoln, NE (2016)", x="Mean Humidity (%)", y="Count")

htdData %>%
    filter((meanH < 25) | is.na(meanH))

htdData <- htdData %>%
    filter(!((meanH < 25) | is.na(meanH)))

# Updated Histogram for average humidity
htdData %>%
    ggplot(aes(x=meanH)) + 
    geom_histogram() + 
    labs(title="Mean Humidity Histogram", subtitle="Lincoln, NE (2016)", x="Mean Humidity (%)", y="Count")

# Histogram for dewpoint depression (T - D)
htdData %>%
    ggplot(aes(x=meanT-meanD)) + 
    geom_histogram() + 
    labs(title="Mean Dewpoint Depression Histogram", subtitle="Lincoln, NE (2016)", 
         x="Mean Dewpoint Depression (F)", y="Count")

htdData %>% 
    filter(meanD >= meanT)

htdData <- htdData %>%
    filter(meanT >= meanD)

# Updated Histogram for dewpoint depression (T - D)
htdData %>%
    ggplot(aes(x=meanT-meanD, y=..density..)) + 
    geom_histogram(binwidth=1) + 
    geom_density(color="red") + 
    labs(title="Mean Dewpoint Depression Histogram", subtitle="Lincoln, NE (2016)", 
         x="Mean Dewpoint Depression (F)", y="Proportion")

# Average humidity by month
htdData %>%
    group_by(month) %>%
    summarize(meanH=mean(meanH, na.rm=TRUE)) %>%
    ggplot(aes(x=as.factor(month), y=meanH)) + 
    geom_col() + 
    labs(title="Average Humidity by Month", subtitle="Lincoln, NE (2016)", x="Month", y="Mean Humidity (%)")

# Relationship between temperature and dewpoint
htdData %>%
    ggplot(aes(x=meanD, y=meanT)) + 
    geom_point() + 
    geom_abline(slope=1, intercept=0) + 
    labs(title="Daily Averages", subtitle="Lincoln, NE (2016)", 
         x="Mean Dewpoint (F)", y="Mean Temperature (F)"
         )

# Relationship between dewpoint depression and humidity
htdData %>%
    mutate(dpD=meanT-meanD) %>%
    ggplot(aes(x=dpD, y=meanH)) + 
    geom_point() + 
    labs(title="Daily Averages", subtitle="Lincoln, NE (2016)", 
         x="Mean Dewpoint Depression (F)", y="Mean Humidity (%)"
         )

# Relationship between temperature and dewpoint and humidity
humInts <- c(0, 50, 60, 70, 80)
humLabel <- sapply(1:(length(humInts)-1), FUN=function(x) { paste0(humInts[x], "-", humInts[x+1]) })
humLabel <- c(humLabel, paste0(humInts[length(humInts)], "+"))

htdData %>%
    mutate(humBin=factor(findInterval(meanH, humInts), levels=1:length(humInts), labels=humLabel)) %>%
    ggplot(aes(x=meanD, y=meanT, color=humBin)) + 
    geom_point() + 
    geom_smooth(se=FALSE) +
    geom_abline(slope=1, intercept=0) + 
    labs(title="Daily Averages", subtitle="Lincoln, NE (2016)", 
         x="Mean Dewpoint (F)", y="Mean Temperature (F)"
         )

# Expressed using dewpoint depression vs. dewpoint
htdData %>%
    mutate(humBin=factor(findInterval(meanH, humInts), levels=1:length(humInts), labels=humLabel)) %>%
    ggplot(aes(x=meanD, y=meanT-meanD, color=humBin)) + 
    geom_point() + 
    geom_smooth() +
    labs(title="Daily Averages", subtitle="Lincoln, NE (2016)", 
         x="Mean Dewpoint (F)", y="Dewpoint Depression (F)"
         )

# Expressed using dewpoint depression vs. temperature
htdData %>%
    mutate(humBin=factor(findInterval(meanH, humInts), levels=1:length(humInts), labels=humLabel)) %>%
    ggplot(aes(x=meanT, y=meanT-meanD, color=humBin)) + 
    geom_point() + 
    geom_smooth(se=FALSE, method="lm") +
    labs(title="Daily Averages", subtitle="Lincoln, NE (2016)", 
         x="Mean Temperature (F)", y="Dewpoint Depression (F)"
         )

# Linear regression for temperature, dewpoint, and humidity
htdReg <- htdData %>%
    mutate(dpD=meanT-meanD) %>%
    lm(meanH ~ meanT + dpD, data=.)
summary(htdReg)

htdData %>%
    mutate(dpD=meanT-meanD) %>%
    mutate(predH=predict(htdReg, newdata=.)) %>%
    ggplot(aes(x=predH, y=meanH)) + 
    geom_point() + 
    geom_abline(slope=1, intercept=0) + 
    labs(title="Daily Averages", subtitle="Lincoln, NE (2016)", 
         x="Predicted Humidity (%)", y="Actual Humidity (%)"
         )

```

#### _Example #11: Plotting Weather Data (Wind)_  
Wind data (speed, gust, direction) are also available in the lincoln_weather dataset..

Example code includes:  
```{r}

# Extract wind data
wdData <- lincoln_weather %>%
    select(CST, maxW=`Max Wind Speed [MPH]`, maxG=`Max Gust Speed [MPH]`, meanW=`Mean Wind Speed[MPH]`, 
           dirW=`WindDir [Degrees]`
           ) %>%
    mutate(date=as.Date(CST))
str(wdData)

# Manage missing data
wdData[!complete.cases(wdData), ]

wdData <- wdData %>%
    filter(dirW != -1, !is.na(dirW)) %>%
    mutate(maxG=ifelse(is.na(maxG), maxW, maxG))
summary(wdData)

# Manage very high wind data
wdData[wdData$maxG >= 60, ]
wdData <- wdData %>%
    filter(maxG <= 80)
summary(wdData)

# Density of wind speeds
wdData %>%
    select(date, meanW, maxW, maxG) %>%
    pivot_longer(-date) %>%
    ggplot(aes(x=value, fill=name)) + 
    geom_density(alpha=0.5) + 
    scale_fill_discrete(name="Wind Speed [MPH]", labels=c("Max Gust", "Max", "Mean")) + 
    labs(title="Lincoln, NE (2016) Wind Speeds", y="Density", x="Wind Speed [MPH]")

# Density of wind direction
wdData %>%
    select(date, dirW) %>%
    ggplot(aes(x=dirW)) + 
    geom_density(alpha=0.5, fill="blue") + 
    labs(title="Winds are mainly from the S and NW", subtitle="Lincoln, NE (2016)", 
         y="Density", x="Wind Direction"
         )

# Wind speed and direction
wdData %>% 
    ggplot(aes(x=meanW, y=dirW)) + 
    geom_point(alpha=0.25) + 
    coord_polar(theta="y") + 
    labs(title="Lincoln, NE (2016)", subtitle="Direction vs. Mean Wind Speed", x="Mean Wind Speed [MPH]") + 
    scale_y_continuous(limits=c(0, 360), breaks=c(0, 90, 180, 270, 360)) + 
    scale_x_continuous(limits=c(0, 30), breaks=c(0, 5, 10, 15, 20, 25, 30)) + 
    geom_point(aes(x=0, y=0), color="red", size=2)

# Wind speed and direction as factors
windDirs <- c("N", "NE", "E", "SE", "S", "SW", "W", "NW")
windSpeeds <- c(0, 5, 10, 15)
windLabels <- sapply(1:(length(windSpeeds)-1), FUN=function(x){ paste0(windSpeeds[x], "-", windSpeeds[x+1]) })
windLabels <- c(windLabels, paste0(windSpeeds[length(windSpeeds)], "+"))
wdData <- wdData %>% 
    mutate(wd=factor(floor(((dirW+22.5)/45) %% 8), levels=0:7, labels=windDirs), 
           ws=factor(findInterval(meanW, windSpeeds), levels=length(windSpeeds):1, labels=rev(windLabels))
           )

# Summary of interaction between wind speed and wind direction 
wdData %>%
    group_by(wd) %>% 
    summarize(n=n(), avgMean=mean(meanW), avgMax=mean(maxW), avgGust=mean(maxG))
table(wdData$wd, wdData$ws)

# Graph of wind speed and wind direction
wdData %>%
    ggplot(aes(x=wd, fill=ws)) + 
    geom_bar() + 
    scale_fill_discrete(name="Wind Speed [MPH]") + 
    labs(title="Lincoln, NE (2016) Wind Speeds and Directions", y="# Days", x="Wind Direction")

# Graph of wind speed and wind direction (polar coordinates)
wdData %>%
    ggplot(aes(x=wd, fill=ws)) + 
    geom_bar() + 
    scale_fill_discrete(name="Wind Speed [MPH]") + 
    labs(title="Lincoln, NE (2016) Wind Speeds and Directions", y="# Days", x="Wind Direction") + 
    coord_polar(start=-0.4)
```

#### _Example #12: Archived granular weather Data (METAR)_  
Iowa State has a great database of archived weather data, including the historical METAR data (meteorological aerodrome report) for a number of reporting stations.

[METAR](https://en.wikipedia.org/wiki/METAR) include information on visibility, wind, temperature, dew point, precipitation, clouds, barometric pressure, and other features that may impact safe aviation.

The data for station KLNK (Lincoln, NE airport) was saved as a CSV from [Iowa State](https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?station=LNK&data=all&year1=2015&month1=12&day1=31&year2=2017&month2=1&day2=2&tz=Etc%2FUTC&format=onlycomma&latlon=no&missing=M&trace=T&direct=no&report_type=2)

Some processing is required before using the METAR data:

Example code includes:  
```{r}

# Load METAR data
klnk <- readr::read_csv("./RInputFiles/metar_klnk_2016.txt", na=c("", "NA", "M"))
str(klnk, give.attr=FALSE)

# Filter to only data that ends with times ending in 54Z
metarKLNK <- klnk %>%
    filter(str_detect(metar, "54Z"))
dim(metarKLNK)


# There should be 24*368=8832 records, so there are a handful (19) of missing METAR observations
minDate <- min(metarKLNK$valid)
expDate <- minDate + lubridate::hours(0:(24*368 - 1))

# Observations expected but not recorded
as.POSIXct(setdiff(expDate, metarKLNK$valid), origin="1970-01-01", tz="UTC")

# Observations recorded but not expected
setdiff(metarKLNK$valid, expDate)

# Confirmation of uniqueness
length(unique(metarKLNK$valid)) == length(metarKLNK$valid)


# Extract wind speeds and direction
# The general wind format is dddssGssKT where ddd is the direction (VRB meaning variable), the main ss is the speed, and the Gss is the gust speed (optional and not always displayed)

mtxWind <- metarKLNK %>%
    pull(metar) %>%
    str_match(pattern="(\\d{3}|VRB)(\\d{2})(G\\d{2})?KT")
head(mtxWind)

table(mtxWind[, 2], useNA="ifany")
table(mtxWind[, 3], useNA="ifany")
table(mtxWind[, 4], useNA="ifany")

# Verify that winds not captured are in fact missing from the METAR
metarKLNK[which(is.na(mtxWind[, 2])), "metar"]

metarKLNK <- metarKLNK %>%
    mutate(dirW=mtxWind[, 2], 
           spdW=as.numeric(mtxWind[, 3]), 
           gustW=as.numeric(str_replace(mtxWind[, 4], "G", ""))
           )

# Plot for the wind direction
metarKLNK %>%
    ggplot(aes(x=dirW)) + 
    geom_bar() + 
    labs(title="Lincoln, NE Wind Direction", subtitle="KLNK METAR (2016)", 
         y="# Hourly Observations", x="Wind Direction"
         )

# Plot for the minimum, average, and maximum wind speed by wind direction
# Wind direction 000 is reserved for 0 KT wind, while VRB is reserved for 3-6 KT variable winds
metarKLNK %>%
    filter(!is.na(dirW)) %>%
    group_by(dirW) %>%
    summarize(minWind=min(spdW), meanWind=mean(spdW), maxWind=max(spdW)) %>%
    ggplot(aes(x=dirW)) + 
    geom_point(aes(y=meanWind), color="red", size=2) + 
    geom_errorbar(aes(ymin=minWind, ymax=maxWind)) + 
    labs(title="Lincoln, NE Wind Direction", subtitle="KLNK METAR (2016)", 
         y="Wind Speed [KT]", x="Wind Direction"
         )

# Plot for the wind speed
# Roughly 10% of the time, there is no wind in Lincoln
metarKLNK %>%
    ggplot(aes(x=spdW)) + 
    geom_bar(aes(y=..count../sum(..count..))) + 
    labs(title="Roughly 10% of wind speeds in Lincoln, NE measure 0 Knots", subtitle="KLNK METAR (2016)", 
         y="% Hourly Observations", x="Wind Speed {KT]"
         )

metarKLNK %>% 
    filter(!is.na(dirW), dirW != "VRB", dirW != "000") %>%
    mutate(dirW=as.numeric(dirW)) %>%
    group_by(dirW, spdW) %>%
    summarize(n=n()) %>%
    ggplot(aes(x=spdW, y=dirW)) + 
    geom_point(alpha=0.1, aes(size=n)) + 
    coord_polar(theta="y") + 
    labs(title="Lincoln, NE (2016)", subtitle="Direction vs. Wind Speed", x="Wind Speed [KT]") + 
    scale_y_continuous(limits=c(0, 360), breaks=c(0, 90, 180, 270, 360)) + 
    scale_x_continuous(limits=c(0, 30), breaks=c(0, 5, 10, 15, 20, 25, 30)) + 
    geom_point(aes(x=0, y=0), color="red", size=2)

```

#### _Example #13: Extracting Key Elements from METAR_  
A properly formatted METAR includes the following information in order, though with variable amounts of other information in between.

dddd54Z ddddd[Gdd]KT dSM [M]dd/[M]dd Adddd RMK SLPddd Tdddddddd

* dddd54Z is the two-digit date and four-digit Zulu time (KLNK METAR are taken at 54 minutes past the hour)  
* ddddd[Gdd]KT is the three-digit wind direction (can be VRB), two digit wind speed in knots, and sometimes the two digit maximum gust in knots  
* dSM is the visibility in statute miles.  This is somewhat tricky in that d can be any of 0-10 but can also be 1/4, 1/2, 3/4, 1 1/4, 1 1/2, 1 3/4, 2 1/2  
* [M]dd/[M]dd is the temperature in celsius and dewpoint in celsius.  M means negative  
* Adddd is the four-digit altimeter reading  
* RMK notes that the remarks are beginning  
* SLPddd notes the three-digit sea-level pressure  
* Tdddddddd notes the four digit temperature in Celsius and the four digit dewpoint in celsius.  If it begins with 1 it is negative.  The fourth digit is the decimal.  It will always be a Celsius reading that best corresponds to integer degrees of Fahrenheit  
  
Example code includes:  
```{r}

metAll <- metarKLNK %>%
    pull(metar)

# Create a search string for METAR
valMet <- "54Z.*?(VRB|\\d{3})(\\d{2})(G\\d{2})?KT(.*?)(\\d{1,2}SM).*?\\s(M?\\d{2})/(M?\\d{2}).*?(A\\d{4}).*?RMK.*?(SLP\\d{3}).*?(T\\d{8})"

# Find the number of matching elements
str_detect(metAll, pattern=valMet) %>% table()

# The strings that do not match have errors in the raw data (typically, missing wind speed)
metAll[!str_detect(metAll, pattern=valMet)]

# A matrix of string matches can be obtained
mtxParse <- str_match(metAll, pattern=valMet)
head(mtxParse)

# Create a data frame
dfParse <- data.frame(mtxParse, stringsAsFactors=FALSE)
names(dfParse) <- c("METAR", "WindDir", "WindSpeed", "WindGust", "Dummy", "Visibility", 
                    "TempC", "DewC", "Altimeter", "SLP", "FahrC"
                    )
dfParse <- tibble::as_tibble(dfParse)
str(dfParse)

# Convert to numeric where appropriate
dfParse <- dfParse %>%
    mutate(WindSpeed = as.integer(WindSpeed), 
           WindGust = as.numeric(WindGust), 
           Visibility = as.numeric(str_replace(Visibility, "SM", "")),
           TempC = as.integer(str_replace(TempC, "M", "-")), 
           DewC = as.integer(str_replace(DewC, "M", "-")), 
           Altimeter = as.integer(str_replace(Altimeter, "A", "")), 
           SLP = as.integer(str_replace(SLP, "SLP", "")), 
           TempF = 32 + 1.8 * as.integer(str_replace(str_sub(FahrC, 2, 5), pattern="^1", "-"))/10, 
           DewF = 32 + 1.8 * as.integer(str_replace(str_sub(FahrC, 6, 9), pattern="^1", "-"))/10
           )

# Investigate the data
set.seed(2003211416)
str(dfParse)
head(dfParse)
tail(dfParse)
dfParse %>% 
    sample_n(20)

# Check for NA values
colSums(is.na(dfParse))

# Plot of counts by key metric
keyMetric <- c("WindDir", "WindSpeed", "WindGust", "Visibility", "TempC", 
               "DewC", "Altimeter", "SLP", "TempF", "DewF"
               )

for (x in keyMetric) {
    p <- dfParse %>%
        group_by_at(vars(all_of(x))) %>%
        summarize(n=n()) %>%
        ggplot(aes_string(x=x, y="n")) + 
        geom_col() + 
        labs(title=x, y="Count")
    print(p)
}

# There are three obvious issues
# Visibility is not correctly picked up when there is a / such as 1/2 SM
# Wind gusts are never picked up
# Sea Level Pressure is missing a digit

# Correct for visibility
# Areas that have \\d \\d/\\dSM
sm1 <- which(str_detect(metAll, pattern=" \\d/\\dSM"))
sm2 <- which(str_detect(metAll, pattern=" \\d \\d/\\dSM"))

valSM1 <- str_match(metAll, pattern="\\d/\\dSM")[sm1]
valSM1 <- str_replace(valSM1, "SM", "")
valSM1 <- as.integer(str_sub(valSM1, 1, 1)) / as.integer(str_sub(valSM1, 3, 3))

valSM2 <- str_match(metAll, pattern=" \\d \\d/\\dSM")[sm2]
valSM2 <- as.integer(str_sub(valSM2, 2, 2))

dfParse[sm1, "Visibility"] <- valSM1
dfParse[sm2, "Visibility"] <- dfParse[sm2, "Visibility"] + valSM2

dfParse %>% 
    count(Visibility)


# Correct for wind gusts
gustCheck <- which(str_detect(metAll, pattern="\\d{5}G\\d{2}KT"))
valGust <- str_match(metAll, pattern="\\d{5}G\\d{2}KT")[gustCheck]
valGust <- as.integer(str_sub(valGust, 7, 8))

dfParse[gustCheck, "WindGust"] <- valGust

dfParse %>% 
    count(WindGust) %>% 
    as.data.frame

# Correct for SLP
dfParse <- dfParse %>%
    mutate(modSLP=ifelse(dfParse$SLP < 500, 1000 + dfParse$SLP/10, 900 + dfParse$SLP/10))

dfParse %>%
    group_by(SLP, modSLP) %>%
    summarize(n=n()) %>%
    ggplot(aes(x=SLP, y=modSLP, size=n)) + 
    geom_point(alpha=0.3)

# Check updated plots
keyMetric <- c("WindGust", "Visibility", "modSLP")
for (x in keyMetric) {
    p <- dfParse %>%
        group_by_at(vars(all_of(x))) %>%
        summarize(n=n()) %>%
        ggplot(aes_string(x=x, y="n")) + 
        geom_col() + 
        labs(title=x, y="Count")
    print(p)
}

```

#### _Example #14: Relationships Between METAR Variables_  
Many of the METAR variables are correlated/associated to one another.

Example code includes:  
```{r}

# Define key numeric variables
coreNum <- c("TempC", "TempF", "DewC", "DewF", "Altimeter", "modSLP", "WindSpeed", "Visibility")

# Add the date back to the file (should edit the above instead)
dfParse <- dfParse %>%
    mutate(month=lubridate::month(metarKLNK$valid))
str(dfParse)

# Keep only complete cases and find correlations
mtxCorr <- dfParse %>%
    mutate(month=lubridate::month(metarKLNK$valid)) %>%
    select_at(vars(all_of(coreNum))) %>%
    filter(complete.cases(.)) %>%
    cor()

# Print the correlations and show a heatmap
mtxCorr %>%
    round(2)

corrplot::corrplot(mtxCorr, method="color", title="Lincoln, NE Hourly Weather Correlations (2016)")

# Create a function for plotting two variables against each other
plotNumCor <- function(var1, var2, title=NULL) {
    if (is.null(title)) 
        { title <- paste0("Lincoln, NE (2016) Hourly Correlations of ", var1, " and ", var2) }
    p <- dfParse %>%
        group_by_at(vars(all_of(c(var1, var2)))) %>%
        summarize(n=n()) %>%
        ggplot(aes_string(x=var1, y=var2)) + 
        geom_point(alpha=0.5, aes_string(size="n")) + 
        geom_smooth(method="lm", aes_string(weight="n")) + 
        labs(x=var1, y=var2, title=title)
    print(p)
}

# The three linear or almost linear relationships
plotNumCor("TempC", "TempF")
plotNumCor("DewC", "DewF")
plotNumCor("Altimeter", "modSLP")

# Strongly and positively related
plotNumCor("TempF", "DewF")

# Moderately negatively correlated
plotNumCor("TempF", "Altimeter")
plotNumCor("TempF", "modSLP")
plotNumCor("Altimeter", "WindSpeed")

# Predict modSLP from Altimeter
lmSLP1 <- lm(modSLP ~ Altimeter, data=dfParse)
lmSLP2 <- lm(modSLP ~ Altimeter + TempF, data=dfParse)
summary(lmSLP1)
summary(lmSLP2)

# Plot predictions vs. actual (model 1)
dfParse %>%
    filter(!is.na(modSLP)) %>%
    mutate(pred1=predict(lmSLP1)) %>%
    count(modSLP, pred1) %>%
    ggplot(aes(x=modSLP, y=pred1)) + 
    geom_point(alpha=0.25, aes(size=n)) + 
    geom_smooth(method="lm", aes(weight=n)) + 
    labs(title="Predicted vs. Actual Sea Level Pressure - Altitude Only as Predictor", 
         subtitle="Lincoln, NE (2016) Hourly METAR", x="Sea Level Pressure", y="Predicted"
         )

# Plot predictions vs. actual (model 2)
dfParse %>%
    filter(!is.na(modSLP)) %>%
    mutate(pred2=predict(lmSLP2)) %>%
    count(modSLP, pred2) %>%
    ggplot(aes(x=modSLP, y=pred2)) + 
    geom_point(alpha=0.25, aes(size=n)) + 
    geom_smooth(method="lm", aes(weight=n)) + 
    labs(title="Predicted vs. Actual Sea Level Pressure - Altitude and Temperature as Predictor", 
         subtitle="Lincoln, NE (2016) Hourly METAR", x="Sea Level Pressure", y="Predicted"
         )

```

#### _Example #15: Extracting Cloud Data from METAR_  
[Cloud data](https://en.wikipedia.org/wiki/METAR#Cloud_reporting) is also included in the METAR, with the type of clouds being described as:

* CLR - there are no clouds below 12,000 feet 
* VVddd - there is a vertical visibility of ddd hundred feet (cannot tell where the clouds are above that)  
* FEWddd - there are clouds with bases at ddd feet, and they obscure 25% or less of the sky  
* SCTddd - there are clouds with bases at ddd feet, and they obscure 25%-50% of the sky  
* BKNddd - there are clouds with bases at ddd feet, and they obscure 50%-99% of the sky  
* OVCddd - there is a full overcast with base at ddd feet  
  
The ceiling is considered the lowest height that is measured as any of OVC, BKN, or VV.

Example code includes:  
```{r}

# Extract the CLR records
mtxCLR <- str_extract_all(metarKLNK$metar, pattern=" CLR ", simplify=TRUE)
if (dim(mtxCLR)[[2]] != 1) { stop("Extracted 2+ CLR from some METAR; investigate") }
isCLR <- ifelse(mtxCLR[, 1] == "", 0, 1)

# Extract the VV records
mtxVV <- str_extract_all(metarKLNK$metar, pattern="VV(\\d{3})", simplify=TRUE)
if (dim(mtxVV)[[2]] != 1) { stop("Extracted 2+ VV from some METAR; investigate") }
isVV <- ifelse(mtxVV[, 1] == "", 0, 1)
htVV <- ifelse(mtxVV[, 1] == "", NA, as.integer(str_replace(mtxVV[, 1], "VV", ""))*100)

# Extract the FEW records
mtxFEW <- str_extract_all(metarKLNK$metar, pattern="FEW(\\d{3})", simplify=TRUE)
numFEW <- apply(mtxFEW, 1, FUN=function(x) { sum((x!=""))} )

# Extract the SCT records
mtxSCT <- str_extract_all(metarKLNK$metar, pattern="SCT(\\d{3})", simplify=TRUE)
numSCT <- apply(mtxSCT, 1, FUN=function(x) { sum((x!=""))} )

# Extract the BKN records
mtxBKN <- str_extract_all(metarKLNK$metar, pattern="BKN(\\d{3})", simplify=TRUE)
numBKN <- apply(mtxBKN, 1, FUN=function(x) { sum((x!=""))} )

# Extract the OVC records
mtxOVC <- str_extract_all(metarKLNK$metar, pattern="OVC(\\d{3})", simplify=TRUE)
numOVC <- apply(mtxOVC, 1, FUN=function(x) { sum((x!=""))} )

# Summarize as a data frame
tblClouds <- tibble::tibble(isCLR=isCLR, isVV=isVV, htVV=htVV, numFEW=numFEW, 
                            numSCT=numSCT, numBKN=numBKN, numOVC=numOVC
                            )

# Get the counts
# As expected, if isCLR then nothing else, and if isVV then nothing else
tblClouds %>% 
    count(isCLR, isVV, numFEW, numSCT, numBKN, numOVC) %>%
    as.data.frame()

# Investigate the problem data
metarKLNK$metar[rowSums(tblClouds, na.rm=TRUE)==0]

# Get the counts of most obscuration
tblClouds %>%
    filter(rowSums(., na.rm=TRUE) > 0) %>%
    mutate(wType=factor(case_when(isCLR==1 ~ "CLR", isVV==1 ~ "VV", numOVC > 0 ~ "OVC", 
                                  numBKN > 0 ~ "BKN", numSCT > 0 ~ "SCT", numFEW > 0 ~ "FEW", 
                                  TRUE ~ "Error"
                                  ), levels=c("VV", "OVC", "BKN", "SCT", "FEW", "CLR", "Error")
                  )
           ) %>%
    ggplot(aes(x=wType, y=..count../sum(..count..))) + 
    geom_bar() + 
    labs(title="Highest Obscuration by Cloud - Lincoln, NE (2016)", x="Cloud Type", 
         y="Proportion of Hourly Measurements"
         )

# Integrate the clouds data
mtxCloud <- cbind(mtxVV, mtxOVC, mtxBKN, mtxSCT, mtxFEW, mtxCLR)

# Cycle through to find levels of a given type
ckClouds <- function(cloudType) {
    isKey <- which(apply(mtxCloud, 2, FUN=function(x) {sum(str_detect(x, cloudType))}) > 0)
    as.integer(str_replace(mtxCloud[, min(isKey)], cloudType, "")) * 100
}
lowOVC <- ckClouds("OVC")
lowVV <- ckClouds("VV")
lowBKN <- ckClouds("BKN")
lowSCT <- ckClouds("SCT")
lowFEW <- ckClouds("FEW")

# Integrate the lowest cloud type by level
lowCloud <- tibble::tibble(lowVV, lowOVC, lowBKN, lowSCT, lowFEW)
lowCloud

# Get the lowest cloud level
minCloud <- lowCloud
minCloud[is.na(minCloud)] <- 999999
minCloudLevel <- apply(minCloud, 1, FUN=min)
minCeilingLevel <- apply(minCloud[, c("lowVV", "lowOVC", "lowBKN")], 1, FUN=min)

noCloudPct <- mean(minCloudLevel == 999999)
noCeilingPct <- mean(minCeilingLevel == 999999)

# Plot the minimum cloud level (where it exists)
data.frame(minCloudLevel, minCeilingLevel) %>%
    filter(minCloudLevel != 999999) %>%
    ggplot(aes(x=minCloudLevel)) + 
    geom_bar(aes(y=..count../sum(..count..))) + 
    geom_text(aes(x=2500, y=0.04, 
                  label=paste0(round(100*noCloudPct), "% of obs. have no clouds")
                  )
              ) + 
    labs(x="Height [ft]", y="Proportion", title="Minimum Cloud Height (when some clouds exist)", 
         subtitle="Lincoln, NE (2016)"
         )

# Plot the minimum ceiling level (where it exists)
data.frame(minCloudLevel, minCeilingLevel) %>%
    filter(minCeilingLevel != 999999) %>%
    ggplot(aes(x=minCeilingLevel)) + 
    geom_bar(aes(y=..count../sum(..count..))) + 
    geom_text(aes(x=2500, y=0.04, 
                  label=paste0(round(100*noCeilingPct), "% of obs. have no ceiling")
                  )
              ) + 
    labs(x="Height [ft]", y="Proportion", title="Minimum Ceiling Height (when a ceiling exists)", 
         subtitle="Lincoln, NE (2016)"
         )

```

