---
title: "Taveras Examples - Excel for R"
author: "davegoblue"
date: "February 17, 2016"
output: html_document
---

This document captures some useful tips and tricks from John Taveras' book "R for Excel Users".  John has a nice style for comparing Excel with R.  One of my objectives is to get R to "behave more like Excel" in some instances.


### Chapter 4 Cells vs. Vectors  

This chapter contains some useful string functions.  I expand on them a bit with some other searching.
  
####_Standard Excel text functions_  
Standard Excel functions like LEN, SUBSTR, UPPER, and LOWER can be replicated:  
```{r}
fakeName <- "AbcDe FFGhiJL mfoP"

nchar(fakeName)  ## Number of characters including spaces - 18
length(fakeName)  ## Not what you want!  It is of length 1 (1 item)

substr(fakeName,1,3)  ## Start at position 1 and stop at position 3 (left(fakeName,3))
substr(fakeName,nchar(fakeName)-2,nchar(fakeName))  ## Start at len-2 and stop at len (right(fakeName,3))

toupper(fakeName)
tolower(fakeName)

```
  
  
####_String splitting is available_  
Additionally, a string can be split on a key character, with the results then manipulated as needed in one of many different ways:  
```{r}
strsplit(fakeName," ")  ## Split by " "

length(strsplit(fakeName," "))  ## It is still 1 because it is a list
nchar(strsplit(fakeName," "))  ## It is now 29!  Not totally sure why though . . . 

strsplit(fakeName," ")[c(1,3)]  ## Prints the full list, with 3 being NULL (list has only 1 item)
strsplit(fakeName," ")[[1]][1:3]  ## Prints each item separately (list of length 3)

length(strsplit(fakeName," ")[[1]])  ## 3
length(strsplit(fakeName," ")[[1]][1:3])  ## 3

nchar(strsplit(fakeName," ")[[1]][1:3])  ## 5 7 4
sum(nchar(strsplit(fakeName," ")[[1]][1:3]))  ## 16 (5+7+4)

strsplit(fakeName," ")[[1]][c(1,3)]  ## Grab the first and third item - "AbcDe" and "mfoP"

```
  
  
####_Pattern substitution is available:_  
Pattern substitution is available, with sub finding/replacing the first instance with gsub finding/replacing all instances:  
```{r}
sub(pattern=" ",replacement="_-_",fakeName)  ## Replace just the first space
gsub(pattern=" ",replacement="_-_",fakeName)  ## Replace all spaces
nchar(gsub(pattern=" ",replacement="_-_",fakeName))  ## Grew from 18->22 due to each space getting 2 bigger
gsub(pattern=" ",replacement="",fakeName)  ## compressed vector
nchar(gsub(pattern=" ",replacement="",fakeName))  ## Shrank from 18->16 by compressing away the fakes

```
  
  
####_Pattern identification and location ID is available_  
The regexpr function finds the first match and provides a list with attributes about it:  
```{r}
regexpr("f",fakeName)  ## Provides first match, length of match, and then useBytes
regexpr("f",fakeName)[1]  ## shows the location of the first match
attr(regexpr("f",fakeName),"match.length")  ## Shows the length of match
attr(regexpr("f",fakeName),"useBytes")  ## Shows the useBytes of match (TRUE/FALSE)

regexpr("f",fakeName,ignore.case=TRUE)  ## finds the F which comes before f
regexpr("f",fakeName,ignore.case=TRUE)[1] ## shows the location of the first match

regexpr("2/4","2/4/16")  ## Returns 1 3 TRUE (result is 1 with match.length 3 and useBytes TRUE)
regexpr("2/4","2/4/16",fixed=TRUE)  ## No difference

```
  
  
####_This can be expanded to identify all instances of the pattern_  
The gregexpr does the same thing but returns the lists/attributes for all the matches:  
```{r}
gregexpr("f",fakeName,ignore.case=TRUE)  ## Finds positions 7, 8, and 16
length(gregexpr("f",fakeName,ignore.case=TRUE)[[1]]) ## Reports the 3 matches

gregexpr("f",fakeName,ignore.case=TRUE)[[1]][1] ## Returns 7
gregexpr("f",fakeName,ignore.case=TRUE)[[1]][2] ## Returns 8
gregexpr("f",fakeName,ignore.case=TRUE)[[1]][3] ## Returns 16

attr(gregexpr("f",fakeName,ignore.case=TRUE)[[1]],"match.length") ## Returns 1 1 1
attr(gregexpr("f",fakeName,ignore.case=TRUE)[[1]],"match.length")[2] ## Returns 1

gregexpr("fGh",fakeName,ignore.case=TRUE)  ## Finds just position 8 with length 3

```
  
  
####_Not sure I understand this_  
There is also a regexec command, but I do not yet see where it comes in handy:  
```{r}
regexec("f",fakeName,ignore.case=TRUE) ## Not so sure, get back 7 and attr(,"match.lenght") 1
regexec("fGh",fakeName,ignore.case=TRUE)  ## Not so sure, get back 8 and 3
```
  
  
####_There are a few handy preset variables available in base_  
Further, R contains some handy presets to help with common processing needs:  
```{r}
letters ## all the lower case letters a-z
length(letters)  ## 26
letters[c(1,4,9,16,25)]  ## a d i p y
nchar(letters[c(1,4,9,16,25)])  ## 1 1 1 1 1

LETTERS ## all the upper case letters A-Z

month.abb ## all the 3-character month abbreviations in form Jan
month.abb[c(1,10)]  ## "Jan" "Oct"

month.name ## full month names in form February
length(month.name) ## 12
nchar(month.name) ## 7 8 5 5 3 4 4 6 9 7 8 8

month.name[c(1,13)]  ## "January" NA
length(month.name[c(1,13)])  ## 2

month.name[c(0,12)]  ## "December"
length(month.name[c(0,12)])  ## 1

month.name[c(0,13)]  ## NA
length(month.name[c(0,13)])  ## 1

pi ## 3.141593 etc.
```
  
  
### Chapter 5 Formulae vs. Functions  

I am mostly OK with functions already, but it will be good to have a few key operations documented.  

####_Rounding functions_  
It will be helpful to document how R handles a few key rounding functions:  
```{r}
## Note that there is no option to pass a digit to ceiling - it is always to nearest 1
ceiling(0.2)  ## 1
ceiling(0)  ## 0
ceiling (-0.2) ## 0
ceiling(10*pi)/10 ## 3.2 (this will round up to the nearest 0.1)

floor(0.2) ## 0
floor(0) ## 0
floor(-0.2)  ## -1
floor(10*pi)/10 ## 3.1 (this will round down to the nearest 0.1)

round(2.6)  ## 3 (default is round to nearest integer)
round(2.5)  ## 2 (NOTE the goof-ball algorithm where 0.5 always rounds to even)
round(1.5)  ## 2 (default is round to nearest integer)
round(-2.5)  ## -2 (NOTE the goof-ball algorithm where 0.5 always rounds to even)
round(-1.5)  ## -2 (default is round to nearest integer)

round(pi,4)  ## 3.1416 (the four means four post-decimal)
signif(pi,4)  ## 3.142 (the four means four total)

round(pi/1000,4)  ## .0031 (still four post-decimal)
signif(pi/1000,4) ## .003142 (still four total)

trunc (1.8)  ## 1 (truncate is TOWARDS 0)
trunc(-1.8)  ## -1 (truncate is TOWARDS 0)

log(10)  ## default is LN
log(10, base=10)  ## back to 1
log10(10)  ## Same as setting log and base=10 but may be faster
```
  
  
####_Ranking variables in R_  
It is also handy sometimes to gather the rank of something - see below:  
```{r}
str(rank)
## na.last: default TRUE (NA last) or FALSE (NA first) or NA (NA removed) or "keep" (rank NA)
## ties.method: default "average" (all ties get their average rank) or "random" (ties break randomly)
##              or "min" (typicaly sports ranking, all ties get the best rank)
##              or "max" (all ties get worst rank) or "first" (ties break by order found)

set.seed(0218160926)
x <- c(1,2,2,2,3,4,NA,NA,7,7,9,10)

rank(x)  ## The 2 all get rank 3, the 7 both get rank 7.5 and the NA get rank 11 and 12
rank(x,na.last=TRUE)  ## Same
rank(x,na.last=FALSE)  ## NA promoted to 1 and 2
rank(x,na.last=NA)  ## NA vector shortened as NA discarded from results vector (seems risky . . . )
rank(x,na.last="keep")  ## Same as above, but vector stays same length with rank as NA

rank(x,ties.method="average")  ## Same as default
rank(x,ties.method="first")  ## Ties broken so the 2's rank 2 3 4 and the 7's rank 7 8
rank(x,ties.method="random")  ## Ties broken so the 2's rank randomly 2-4 and the 7's rank randomly 7-8
rank(x,ties.method="random")  ## Ranks change with different random numbers
rank(x,ties.method="max")  ## The 2's all rank 4 and the 7's both rank 8
rank(x,ties.method="min")  ## The 2's all rank 2 and the 7's both rank 7
```

  
  
### Chapter 7: Data Inspection  

Remember the unique() call which is handy in certain cases:  
```{r}
fakeName <- "AbcDe FFGhiJL mfoP"
unique(strsplit(toupper(fakeName),"")[[1]])  ## A B C D E " " F G H I J K L M O P
```
  
  
Remember also the pairs() function for getting pairwise plots:  
```{r}
pairs(iris)  ## Default dataset in R
```
  
  
There may be benefit to further studying xtabs (cross tabulation):  
```{r}
str(xtabs)
xtabs(~ Species + Petal.Width, data=iris) ## counts of Species x Petal.Width
xtabs(Petal.Width ~ Species, data=iris) ## Sum of Petal.Width by Species
xtabs(Petal.Width + Petal.Length ~ Species, data=iris) ## Straight sums Width/Length, by Species
xtabs(Petal.Length ~ Species + Petal.Width, data=iris) ## Sum of Petal Length for Species x Petal Width
```
  
  
### Chapter 8: Column Operations  
  
I am mostly OK with these, but good to have a refresher of ifelse()  
```{r}
ifelse(iris$Species[c(1:2,100,150)]=="setosa","yes","no")  ## yes yes no no
```
  
  
Quick refresher on some some helpful grep syntax:  
```{r}
fakeName <- "AbcDe FFGhiJL mfoP"
grep("$",strsplit(gsub(" ","$",fakeName),"")[[1]])  ## Returns 1 2 3 4 . . . $ is a special character
grep("\\$",strsplit(gsub(" ","$",fakeName),"")[[1]])  ## Returns 6 14 since $ is escaped by \\
grep("\\$|f|F",strsplit(gsub(" ","$",fakeName),"")[[1]])  ## Returns 6 7 8 14 16 since | is OR
```
  
  
####_Removing unwanted columns_  
Sometimes you do not want a column anymore -- there are several ways to delete it:  
```{r}
## myFrame$badColumn <- NULL ## Incredibly, thet gets rid of a column!
## myFrame <- myFrame[ , c(-2,-4,-6)]  ## Will remove columns 2, 4, 6
```


### Chapter 10: sqldf and dplyr  
Some examples for running SQL code or dplyr.  
  
####_Running sqldf_  
With sqldf, you basically have access to on-board SQL but without the hassles of loading RMySQL:  
```{r}

library(sqldf) ## The sqldf library
batting <- read.csv("Lahman/Batting.csv",stringsAsFactors=FALSE) ## The baseball dataset

sqldf("SELECT playerID, yearID, teamID, AB  
       FROM batting                         
       WHERE yearID=2009                    
       ORDER BY AB DESC                     
       LIMIT 10")


```
  
  
####_Manipulating data with dplyr (basics)_  
The dplyr package is an amazing way to work with data - key verbs:  
* select() select columns  
* mutate() add or reformat columns  
* filter() select rows  
* arrange() sort rows  
* summarize() summarize datasets  
  

```{r}
library(dplyr)
## Core frame is listed first in each of the calls

## Select just takes the requested columns
head(select(batting,playerID,yearID))  

## Mutate creates new variables based on existing variables
myTemp <- mutate(batting,avg=H/AB,shortID=substr(playerID,1,5))
head(select(myTemp,playerID,shortID,H,AB,avg))
tail(select(myTemp,playerID,shortID,H,AB,avg))

## Filter subsets the data based on criteria with each , being and (use | for or)
filter(batting,yearID==2010,teamID=="NYA" | teamID=="NYN",AB>600)[,1:5]

## Arrange runs the sorting for you - no need to use the x[order(x)] concept
head(arrange(batting,desc(yearID),teamID,desc(AB)))[,1:5]

```
  
  
####_Expanding dplyr with group_by()_  
The dplyr functionality can then be expanded with the group_by() call, which creates an internal grouping without actually modifying the data.  See below for example usages:  
```{r}

library(dplyr)
set.seed(0218160926)

## By-group processing (keep n results from n items)
x <- filter(batting, yearID==2013)  ## take only 2013
x <- group_by(x, teamID)  ## create an internal grouping (no real data change)
x <- arrange(x, teamID, desc(HR))  ## sort by teamID, then descending HR

## Now, the mutate below will be running everything by teamID -- rank, cumulative, cumulative %
x <- mutate(x, rank=rank(desc(HR), ties.method="min"), cum_HR=cumsum(HR), 
            cum_HR_pct = round(cumsum(HR)/sum(HR),2))

x[1:10,c("teamID","playerID","HR","rank","cum_HR","cum_HR_pct")]
x[sample(1:nrow(x),10,replace=FALSE),c("teamID","playerID","HR","rank","cum_HR","cum_HR_pct")]

x <- filter(x, rank <= 5)
x[1:15,c("teamID","playerID","HR","rank","cum_HR","cum_HR_pct")]  ## Top 5 players on first 3 teams

myTest <- filter(x, rank <= 3)
myTest[1:10,c("teamID","playerID","HR","rank","cum_HR","cum_HR_pct")]  ## keeps tie
```
  
  
####_Expanding dplyr by skipping new column creation_  
The dplyr code above can be consolidated, avoiding the need to create new variables (maybe harder to read and debug, but with the reward of greater efficiency):  
```{r}

library(dplyr)

## Sam as previous
x <- filter(batting, yearID==2013)  ## take only 2013
x <- group_by(x, teamID)  ## create an internal grouping (no real data change)
x <- arrange(x, teamID, desc(HR))  ## sort by teamID, then descending HR

## Skip creating columns and updating databases
x <- filter(x, rank(desc(HR), ties.method="min") <= 5)
x[1:15,c("teamID","playerID","yearID","HR")]  ## Top 5 players on first 3 teams
```
  
  
####_Expanding dplyr by chaining_  
The %>% operator in dplyr lets many of these operations run in order.  For example:  
```{r}

library(dplyr)

## Old code for reference
x <- filter(batting, yearID==2013)  ## take only 2013
x <- group_by(x, teamID)  ## create an internal grouping (no real data change)
x <- arrange(x, teamID, desc(HR))  ## sort by teamID, then descending HR
x <- mutate(x, rank=rank(desc(HR), ties.method="min"), cum_HR=cumsum(HR), 
            cum_HR_pct = round(cumsum(HR)/sum(HR),2))
x <- filter(x, rank <= 5)
x[1:15,c("teamID","playerID","HR","rank","cum_HR","cum_HR_pct")]  ## Top 5 players on first 3 teams

## Use chaining to filter, then group_by, then arrange, then mutate, then filter again
y <- filter(batting, yearID==2013) %>%
     group_by(teamID) %>%
     arrange(teamID, desc(HR)) %>%
     mutate(rank=rank(desc(HR),ties.method="min"),cum_HR=cumsum(HR),
            cum_HR_pct=round(cum_HR/sum(HR),2)
            ) %>%
     filter(rank <= 5)
y[1:15,c("teamID","playerID","HR","rank","cum_HR","cum_HR_pct")]  ## Top 5 players on first 3 teams

identical(x,y)  ## The results are exactly, 100% the same
```
  
  
### Chapter 11: merge()  
Per Taveras, merge() is more or less the equivalent of VLOOKUP in R.  The advantages seem to be that you can do a multi-column lookup and/or value-gathering.  The downside is that it is always doing a ,FALSE where the lookup needs to exactly match.  My Exercise001 code is designed to allow for ,1 and ,-1 lookup also.  
  
```{r}

players <- read.csv("Lahman/Master.csv",stringsAsFactors=FALSE) ## The master players data

## merge(x, y, 
##       by=intersect(names(x),names(y)), by.x=by, by.y=by, 
##       all=FALSE, all.x=all, all.y=all
##       sort=TRUE, suffixes=c(".x",".y"), incomparables=NULL)
##
## can declare both dataset columns using by= or single dataset columns using by.x= and by.y=
## notably, the by variables need not match names; by.x=Player_ID, by.y=IDPLAYER
## default is inner join; can override with all.x=TRUE (left) or all.y=TRUE (right) or all=TRUE (outer)
## sort=TRUE sorts the result by the by columns

battingCountry <- merge(batting, players[ ,c("playerID","birthCountry","birthState")])

## Note that dplyr has merge functions also, which may be handy when more advanced programming is needed

```
  
  
### Chapter 12: summarize()  
The summarize() call in dplyr can give you totals by the group_by variables (this no longer has the property that n-inputs keeps n-outputs):  
```{r}
library(dplyr)

mySummary <- filter(batting, yearID>=2008, !is.na(AB)) %>%
             group_by(teamID, yearID) %>%
             summarize(RBI_sum=sum(RBI),sd_RBI=round(sd(RBI),1),
                       avg=round(sum(H)/sum(AB),3),size=n_distinct(playerID)
                       )

mySummary[1:15,]

## Can always use aggregate from base for simpler versions
altApproach <- aggregate(RBI ~ teamID, data=batting[batting$yearID==2008,], FUN=sum)
altApproach[1:15,]
```
  
  
### Chapter 13: Reshaping the data  
The data can be reshaped using Wickham's package reshape.  I am not yet sure whether-how this relates to Wickham's tidyr package but it has two examples that are very commonly useful.  
* melt coverts wide data to long  
* dcast converts long data to wide  
  
####_Basic philosophy of melting_  
Melting consists of making two decisions:  
1.  What represents a single object?  These become id.vars  
2.  What columns represent the measures per object?  These become measure.vars  


```{r}

library(reshape2)

wide_data <- data.frame(player=c(1,2,3),points_Age25=c(263, 279, 172),points_Age28=c(111,117,221),
                        fake=c("Who","needs","these")
                        )

wide_data
melt(wide_data,id.vars=c("player"),measure.vars=c("points_Age25","points_Age28"),
     value.name="Points",variable.name="Age")
## Could gsub away the Points_Age in Age and convert to numeric

```
  
  
####_Basic philosophy of dcast_  
To dcast requires making three decisions:  
1.  Which column(s) represent the object?  
2.  Which column(s) do you want to transpose over?  
3.  Which column contains the measure?  
  
```{r}

library(reshape2)

long_data <- data.frame(player=c(1,1,2,2,3,3),age=c(25,28,25,28,25,28),
                        points=c(263,111,279,117,172,221),fake=c("do","not","want","these","to","stay")
                        )

long_data
dcast(long_data, player ~ age, value.var="points")

long_data_2 <- data.frame(player=c(1,1,2,2,3,3,1,1,2,2,3,3),
                          age=c(25,28,25,28,25,28,25,28,25,28,25,28),
                          points=c(263,111,279,117,172,221,269,113,285,119,178,223),
                          day_night=c(rep("D",6),rep("N",6)),
                          fake = LETTERS[1:12]
                          )

long_data_2
dcast(long_data_2,player ~ day_night + age, value.var="points")
```
  
  