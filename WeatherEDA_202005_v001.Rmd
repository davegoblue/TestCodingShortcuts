---
title: "Weather Exploratory Data Analysis"
author: "davegoblue"
date: "5/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background
The file 'WeatherDownloads_202005_v002.Rmd' contains code for dowloading and processing historical weather data as contained in METAR archives hosted by Iowa State University.

Data have been dowloaded and processed for several stations (airports) and years, with .rds files saved in "./RInputFiles/ProcessedMETAR".

This module will perform exploratory data analysis on the processed weather files.
  
#### _Data Availability_  
Each processed data file contains one year of hourly weather data for one station.  Files are saved as './RInputFiles/ProcessedMETAR/metar_kxxx_yyyy.rds' where xxx is the three-digit airport code and yyyy is the four-digit year.

Each file contains the following variables:  
  
* METAR (chr) - the extracted portion of the METAR based on a regex string  
* WindDir (chr) - the previaling wind direction in degrees, stored as a character since 'VRB' means variable  
* WindSpeed (int) - the prevailing wind speed in knots  
* WindGust (dbl) - the wind gust speed in knots (NA if there is no recorded wind gust at that hour)  
* Dummy (chr) - artifact, always a blank space  
* Visibility (dbl) - surface visibility in statute miles  
* TempC (int) - temperature in degrees Celsius  
* DewC (int) - dew point in degrees Celsius  
* Altimeter (int) - altimeter in inches of mercury  
* SLP (int) - the raw sea-level-pressure reading from the METAR  
* FahrC (chr) - the raw temperature string pulled from the METAR (Tttttdddd) where tttt is the Fahrenheit temperature recorded in Celsius and dddd is the Fahrenheit dew point recorded in Celsius  
* dtime (dttm) - the date-time associated with the observation  
* origMETAR (chr) - the full METAR associated with the observation  
* TempF (dbl) - the Fahrenheit temperature associated with converting FahrC to Fahrenheit  
* DewF (dbl) - the Fahrenheit dew point associated with converting FahrC to Fahrenheit  
* modSLP (dbl) - Sea-Level Pressure (SLP), adjusted to reflect that SLP is recorded as 0-1000 but reflects data that are 950-1050  
* nSKC (int) - number of times 'SKC' (human-confirmed cloud-free) is recorded in the observation (should be 0 or 1)  
* nCLR (int) - number of times 'CLR' (austomated-sensor cloud-free) is recorded in the observation (should be 0 or 1, and should never have both nSKC>0 and nCLR>0)  
* cloudn (chr) - the nth cloud layer recorded in the METAR (layers begin with FEW, SCT, BKN, OVC or VV)  
* cTypen (chr) - the cloud type of the nth cloud layer (FEW, BKN, SCT, OVC, or VV)  
* cLeveln (dbl) - the cloud height in feet of the nth cloud layer  
* wType (fct) - highest level of obscuration recorded in the METAR (VV > OVC > BKN > SCT > FEW > CLR/SKC)  
* year (dbl) - year of the observation  
* monthint (dbl) - month of the observation as a number (e.g., 6=June)  
* month (fct) - month of the observation as three-character abbreviation, saved as a factor (e.g., Jun=June)  
* day (int) - day of the month of the observation  
  
#### _Base Functions Available_  
There are several functions available for analysis:  
  
* plotCountsByMetric() - bar plots for counts by variable  
* plotNumCor() - plot two numeric variables against each other  
* plotFactorNumeric() - boxplot a numeric variable against a factor variable  

* corMETAR() - correlations between METAR variables  
* lmMETAR() - linear regression modeling for METAR variables  

* basicWindPlots() - plot wind speed and direction  
* getWindDirGroup() - convert wind direction to a grouping (e.g., N for 320-360-40)  
* consolidatePlotWind() - show frequency plots of wind direction, city, and month  
  
The tidyverse library is loaded and the 2016 Detroit data is read in to show examples of the functions:  
```{r}

library(tidyverse)

kdtw_2016 <- readRDS("./RInputFiles/ProcessedMETAR/metar_kdtw_2016.rds")

```
  
A variable mapping is created to allow for better readable variable names:  
```{r}

varMapper <- c(WindDir="Wind Direction (degrees)", 
               WindSpeed="Wind Speed (kts)",
               WindSpeed5="Wind Speed (kts), rounded to nearest 5 knots", 
               Visibility="Visibility (SM)", 
               TempC="Temperature (C)", 
               DewC="Dew Point (C)", 
               Altimeter="Altimeter (inches Hg)",
               Altimeter10="Altimeter (inches Hg), rounded to nearest 0.1 inHg", 
               modSLP="Sea-Level Pressure (hPa)", 
               TempF="Temperature (F)",
               DewF="Dew Point (F)", 
               TempF5="Temperature (F), rounded to nearest 5 degrees",
               DewF5="Dew Point (F), rounded to nearest 5 degrees", 
               cType1="First Cloud Layer Type", 
               cLevel1="First Cloud Layer Height (ft)",
               month="Month", 
               year="Year",
               wType="Greatest Sky Obscuration", 
               day="Day of Month"
               )

```

  
The function plotCountsByMetric() produces bar plots for counts by variable:  
```{r}

# Helper function for generating plots by key variables
plotcountsByMetric <- function(df, 
                               mets, 
                               title="", 
                               rotateOn=20, 
                               dropNA=TRUE, 
                               diagnose=FALSE,
                               mapper=varMapper,
                               facetOn=NULL, 
                               showCentral=FALSE
                               ) {
    
    # Function arguments
    # df: dataframe or tibble containing raw data
    # mets: character vector of variables for plotting counts
    # title: character vector for plot title
    # rotateOn: integer, x-axis labels will be rotated by 90 degrees if # categories >= rotateOn
    # dropNA: boolean for whether to drop all NA prior to plotting (recommended for avoiding warnings)
    # diagnose: boolean for whether to note in the log the number of NA observations dropped
    # mapper: named list containing mapping from variable name to well-formatted name for titles and axes
    # facetOn: a facetting variable for the supplied df (NULL for no faceting)
    # showCentral: boolean for whether to show the central tendency over-plotted on the main data
    
    # Function usage
    # 1.  By default, the function plots overall counts by metric for a given input
    # 2.  If facetOn is passed as a non-NULL, then the data in #1 will be facetted by facetOn
    # 3.  If showCentral=TRUE, then the overall mean will be plotted as a point on the main plot (only makes sense if facetOn has been selected)
    
    
    # Plot of counts by key metric
    for (x in mets) {
        # If a facetting variable is provided, need to include this in the group_by
        useVars <- x
        if (!is.null(facetOn)) { useVars <- c(facetOn, useVars) }
        dat <- df %>%
            group_by_at(vars(all_of(useVars))) %>%
            summarize(n=n())
        
        if (dropNA) {
            nOrig <- nrow(dat)
            sumOrig <- sum(dat$n)
            dat <- dat %>%
                filter_all(all_vars(!is.na(.)))
            if (diagnose & (nOrig > nrow(dat))) { 
                cat("\nDropping", 
                    nOrig-nrow(dat), 
                    "rows with", 
                    sumOrig-sum(dat$n), 
                    "observations due to NA\n"
                    )
            }
        }
        
        # Create the main plot
        p <- dat %>%
            ggplot(aes_string(x=x, y="n")) + 
            geom_col() + 
            labs(title=title,
                 subtitle=paste0("Counts By: ", mapper[x]), 
                 x=paste0(x, " - ", mapper[x]),
                 y="Count"
                 )
        # If the rotateOn criteria is exceeded, rotate the x-axis by 90 degrees
        if (nrow(dat) >= rotateOn) {
            p <- p + theme(axis.text.x=element_text(angle=90))
        }
        # If facetting has been requested, facet by the desired variable
        if (!is.null(facetOn)) {
            p <- p + facet_wrap(as.formula(paste("~", facetOn)))
        }
        # If showCentral=TRUE, add a dot plot for the overall average
        if (showCentral) {
            # Get the median number of observations by facet, or the total if facetOn=NULL
            if (is.null(facetOn)) {
                useN <- sum(dat$n)
            } else {
                useN <- dat %>%
                    group_by_at(vars(all_of(facetOn))) %>%
                    summarize(n=sum(n)) %>%
                    pull(n) %>%
                    median()
            }
            # Get the overall percentages by x
            centralData <- helperCountsByMetric(tbl=dat, ctVar=x, sumOn="n") %>%
                mutate(centralValue=nPct*useN)
            # Apply the median
            p <- p + geom_point(data=centralData, aes(y=centralValue), color="red", size=2)
        }
        # Print the plot
        print(p)
    }
}

# Example for Detroit 2016 - using WindDir, cType1, month, wType
plotcountsByMetric(kdtw_2016, 
                   mets=c("WindDir", "cType1", "month", "wType"), 
                   title="Detroit, MI (2016)"
                   )

```
  
The function plotNumCor() plots two numeric variables against one another:  
```{r}

# Create a function for plotting two variables against each other
plotNumCor <- function(met, 
                       var1, 
                       var2, 
                       title=NULL, 
                       subT="", 
                       dropNA=TRUE, 
                       diagnose=FALSE,
                       mapper=varMapper, 
                       facetOn=NULL, 
                       showCentral=FALSE
                       ) {
    
    # Function arguments
    # met: dataframe or tibble containing raw data
    # var1: character vector of variable to be used for the x-axis
    # var2: character vector of variable to be used for the y-axis
    # title: character vector for plot title
    # subT: character vector for plot subtitle
    # dropNA: boolean for whether to drop all NA prior to plotting (recommended for avoiding warnings)
    # diagnose: boolean for whether to note in the log the number of NA observations dropped
    # mapper: named list containing mapping from variable name to well-formatted name for titles and axes
    # facetOn: a facetting variable for the supplied met (NULL for no faceting)
    # showCentral: boolean for whether to show the central tendency over-plotted on the main data
    
    # Function usage
    # 1.  By default, the function plots overall counts by the provided x/y metrics, with each point sized based on the number of observations, and with an lm smooth overlaid
    # 2.  If facetOn is passed as a non-NULL, then the data in #1 will be facetted by facetOn
    # 3.  If showCentral=TRUE, then the lm smooth that best first to the overall data will be plotted (only makes sense if facetOn has been selected)
    
    # Create the title if not passed
    if (is.null(title)) { 
        title <- paste0("Hourly Observations of ", mapper[var1], " and ", mapper[var2]) 
    }

    # If a facetting variable is provided, need to include this in the group_by
    useVars <- c(var1, var2)
    if (!is.null(facetOn)) { useVars <- c(facetOn, useVars) }
        
    # Pull the counts by useVars
    dat <- met %>%
        group_by_at(vars(all_of(useVars))) %>%
        summarize(n=n()) 
    
    # If NA requested to be excluded, remove anything with NA
    if (dropNA) {
        nOrig <- nrow(dat)
        sumOrig <- sum(dat$n)
        dat <- dat %>%
            filter_all(all_vars(!is.na(.)))
        if (diagnose) { 
            cat("\nDropping", 
                nOrig-nrow(dat), 
                "rows with", 
                sumOrig-sum(dat$n), 
                "observations due to NA\n"
                )
        }
    }
    
    p <- dat %>%
        ggplot(aes_string(x=var1, y=var2)) + 
        geom_point(alpha=0.5, aes_string(size="n")) + 
        geom_smooth(method="lm", aes_string(weight="n")) + 
        labs(x=paste0(mapper[var1], " - ", var1), 
             y=paste0(mapper[var2], " - ", var2), 
             title=title, 
             subtitle=subT
             )
    
    # If facetting has been requested, facet by the desired variable
    if (!is.null(facetOn)) {
        p <- p + facet_wrap(as.formula(paste("~", facetOn)))
    }
    # If showCentral=TRUE, add a dashed line for the overall data
    if (showCentral) {
        p <- p + helperNumCor(dat, xVar=var1, yVar=var2, sumOn="n")
    }
    
    print(p)
}

# Example for Detroit 2016 - using TempC and TempF
plotNumCor(kdtw_2016, var1="TempC", var2="TempF", subT="Detroit, MI (2016)", diagnose=TRUE)

# Example for Detroit 2016 - using TempC and DewC
plotNumCor(kdtw_2016, var1="TempC", var2="DewC", subT="Detroit, MI (2016)", diagnose=TRUE)

# Example for Detroit 2016 - using Altimeter and modSLP
plotNumCor(kdtw_2016, var1="Altimeter", var2="modSLP", subT="Detroit, MI (2016)", diagnose=TRUE)

```
  
The function plotFactorNumeric() creates box plots for a numeric variable against a factor variable:  
```{r}

# Updated function for plotting numeric by factor
plotFactorNumeric <- function(met, 
                              fctVar, 
                              numVar, 
                              title=NULL, 
                              subT="", 
                              diagnose=TRUE,
                              showXLabel=TRUE,
                              mapper=varMapper,
                              facetOn=NULL, 
                              showCentral=FALSE
                              ) {
    
    # Function arguments
    # met: dataframe or tibble containing raw data
    # fctVar: character vector of variable to be used for the x-axis (factor in the boxplot)
    # numVar: character vector of variable to be used for the y-axis (numeric in the boxplot)
    # title: character vector for plot title
    # subT: character vector for plot subtitle
    # diagnose: boolean for whether to note in the log the number of NA observations dropped
    # showXLabel: boolean for whether to include the x-label (e.g., set to FALSE if using 'month')
    # mapper: named list containing mapping from variable name to well-formatted name for titles and axes
    # facetOn: a facetting variable for the supplied met (NULL for no faceting)
    # showCentral: boolean for whether to show the central tendency over-plotted on the main data
    
    # Function usage
    # 1.  By default, the function creates the boxplot of numVar by fctVar
    # 2.  If facetOn is passed as a non-NULL, then the data in #1 will be facetted by facetOn
    # 3.  If showCentral=TRUE, then the overall median of numVar by fctVar will be plotted as a red dot

    
    # Create the title if not passed
    if (is.null(title)) { 
        title <- paste0("Hourly Observations of ", mapper[numVar], " by ", mapper[fctVar])
    }
    
    # Remove the NA variables
    nOrig <- nrow(met)
    dat <- met %>%
        filter(!is.na(get(fctVar)), !is.na(get(numVar)))
    if (diagnose) { cat("\nRemoving", nOrig-nrow(dat), "records due to NA\n") }
    
    # Create the base plot
    p <- dat %>%
        ggplot(aes_string(x=fctVar, y=numVar)) + 
        geom_boxplot(fill="lightblue") + 
        labs(title=title, 
             subtitle=subT, 
             x=ifelse(showXLabel, paste0(mapper[fctVar], " - ", fctVar), ""), 
             y=paste0(mapper[numVar], " - ", numVar)
             )
    
    # If facetting has been requested, facet by the desired variable
    if (!is.null(facetOn)) {
        p <- p + facet_wrap(as.formula(paste("~", facetOn)))
    }
    
    # If showCentral=TRUE, add a dot plot for the overall average
    if (showCentral) {
        centData <- helperFactorNumeric(dat, .f=median, byVar=fctVar, numVar=numVar)
        p <- p + geom_point(data=centData, aes(y=helpFN), size=2, color="red")
    }

    # Render the final plot
    print(p)
    
}

# Example for Detroit 2016 - using TempF and month
plotFactorNumeric(kdtw_2016, 
                  fctVar="month", 
                  numVar="TempF", 
                  subT="Detroit, MI (2016)", 
                  showXLabel=FALSE,
                  diagnose=TRUE
                  )

# Example for Detroit 2016 - using WindSpeed and wType
plotFactorNumeric(kdtw_2016, 
                  fctVar="wType", 
                  numVar="WindSpeed", 
                  subT="Detroit, MI (2016)", 
                  showXLabel=TRUE,
                  diagnose=TRUE
                  )

# Example for Detroit 2016 - using Visibility and wType
plotFactorNumeric(kdtw_2016, 
                  fctVar="wType", 
                  numVar="Visibility", 
                  subT="Detroit, MI (2016)", 
                  showXLabel=TRUE,
                  diagnose=TRUE
                  )

```
  
An issue previous observed where visibility 1/16SM was interpreted as 16 statutory miles has been corrected in the 'WeatherDownloads_202005_v002' file.
  
The function corMETAR() calculates correlations among numeric variables in the METAR data:  
```{r}

# Function to calculate, display, and plot variable correlations
corMETAR <- function(met, numVars, subT="") {

    # Keep only complete cases and report on data kept
    dfUse <- met %>%
        select_at(vars(all_of(numVars))) %>%
        filter(complete.cases(.))
    
    nU <- nrow(dfUse)
    nM <- nrow(met)
    myPct <- round(100*nU/nM, 1)
    cat("\n *** Correlations use ", nU, " complete cases (", myPct, "% of ", nM, " total) ***\n", sep="")
    
    # Create the correlation matrix
    mtxCorr <- dfUse %>%
        cor()

    # Print the correlations
    mtxCorr %>%
        round(2) %>%
        print()

    # Display a heat map
    corrplot::corrplot(mtxCorr, 
                       method="color", 
                       title=paste0("Hourly Weather Correlations\n", subT), 
                       mar=c(0, 0, 2, 0)
                       )
}

# Example for Detroit, MI 2016
coreNum <- c("TempC", "TempF", "DewC", "DewF", 
             "Altimeter", "modSLP", "WindSpeed", "Visibility"
             )
corMETAR(kdtw_2016, numVars=coreNum, subT="Detroit, MI (2016) METAR")

```
  
The function lmMETAR() runs simple linear regression models on the METAR data:  
```{r}

# Function for linear regressions on METAR data
lmMETAR <- function(met, 
                    y, 
                    x, 
                    yName, 
                    subT=""
                    ) {
    
    # Convert to formula
    myChar <- paste0(y, " ~ ", x)
    cat("\n *** Regression call is:", myChar, "***\n")
    
    # Run regression
    regr <- lm(formula(myChar), data=met)
    
    # Summarize regression
    print(summary(regr))
    
    # Predict the new values
    pred <- predict(regr, newdata=met)
    
    # Plot the predictions
    p <- met %>%
        select_at(vars(all_of(y))) %>%
        mutate(pred=pred) %>%
        filter_all(all_vars(!is.na(.))) %>%
        group_by_at(vars(all_of(c(y, "pred")))) %>%
        summarize(n=n()) %>%
        ggplot(aes_string(x=y, y="pred")) + 
        geom_point(aes(size=n), alpha=0.25) + 
        geom_smooth(aes(weight=n), method="lm") + 
        labs(title=paste0("Predicted vs. Actual ", yName, " - ", x, " as Predictor"), 
             subtitle=subT, 
             x=paste0("Actual ", yName), 
             y=paste0("Predicted ", yName)
             )
    print(p)
    
}

# Examples for Detroit, MI 2016
lmMETAR(kdtw_2016, "modSLP", "Altimeter", yName="Sea Level Pressure", subT="Detroit, MI (2016)")
lmMETAR(kdtw_2016, "modSLP", "Altimeter + TempF", yName="Sea Level Pressure", subT="Detroit, MI (2016)")
lmMETAR(kdtw_2016, "TempC", "DewC", yName="Temperature (C)", subT="Detroit, MI (2016)")

```
  
The basicWindPlots() function creates plots for wind speed and direction:  
```{r}

# Generate basic wind plots
basicWindPlots <- function(met, 
                           dirVar="WindDir", 
                           spdVar="WindSpeed",
                           desc="", 
                           gran="", 
                           mapper=varMapper
                           ) {

    # Plot for the wind direction
    wDir <- met %>%
        ggplot(aes_string(x=dirVar)) + 
        geom_bar() + 
        labs(title=paste0(desc, " Wind Direction"), subtitle=gran, 
             y="# Hourly Observations", x=mapper[dirVar]
             ) + 
        theme(axis.text.x=element_text(angle=90))
    print(wDir)

    # Plot for the minimum, average, and maximum wind speed by wind direction
    # Wind direction 000 is reserved for 0 KT wind, while VRB is reserved for 3-6 KT variable winds
    wSpeedByDir <- met %>%
        filter(!is.na(get(dirVar))) %>%
        group_by_at(vars(all_of(dirVar))) %>%
        summarize(minWind=min(get(spdVar)), meanWind=mean(get(spdVar)), maxWind=max(get(spdVar))) %>%
        ggplot(aes_string(x=dirVar)) +
        geom_point(aes(y=meanWind), color="red", size=2) +
        geom_errorbar(aes(ymin=minWind, ymax=maxWind)) +
        labs(title=paste0(desc, " Wind Speed (Max, Mean, Min) By Wind Direction"), 
             subtitle=gran,
             y=mapper[spdVar], 
             x=mapper[dirVar]
             ) + 
        theme(axis.text.x=element_text(angle=90))
    print(wSpeedByDir)

    # Plot for the wind speed
    pctZero <- sum(pull(met, spdVar)==0, na.rm=TRUE) / nrow(met)
    wSpeed <- met %>%
        filter_at(vars(all_of(spdVar)), all_vars(!is.na(.))) %>%
        ggplot(aes_string(x=spdVar)) +
        geom_bar(aes(y=..count../sum(..count..))) +
        labs(title=paste0(round(100*pctZero), "% of wind speeds in ", desc, " measure 0 Knots"),
             subtitle=gran,
             y="% Hourly Observations", 
             x=mapper[spdVar]
             )
    print(wSpeed)
    
    # Polar plot for wind speed and wind direction
    wData <- met %>%
        filter_at(vars(all_of(dirVar)), all_vars(!is.na(.) & !(. %in% c("000", "VRB")))) %>%
        filter_at(vars(all_of(spdVar)), all_vars(!is.na(.))) %>%
        mutate_at(vars(all_of(dirVar)), as.numeric) %>%
        group_by_at(vars(all_of(c(dirVar, spdVar)))) %>%
        summarize(n=n())
        
    wPolarDirSpeed <- wData %>%
        ggplot(aes_string(x=spdVar, y=dirVar)) +
        geom_point(alpha=0.1, aes(size=n)) +
        coord_polar(theta="y") +
        labs(title=paste0(desc, " Direction vs. Wind Speed"), 
             subtitle=gran, 
             x=mapper[spdVar], 
             y=mapper[dirVar]
             ) +
        scale_y_continuous(limits=c(0, 360), breaks=c(0, 90, 180, 270, 360)) +
        scale_x_continuous(limits=c(0, 40), breaks=c(0, 5, 10, 15, 20, 25, 30, 35, 40)) +
        geom_point(aes(x=0, y=0), color="red", size=2)
    print(wPolarDirSpeed)

}

# Example for Detroit, MI 2016
basicWindPlots(kdtw_2016, desc="Detroit, MI (2016)", gran="KDTW METAR")

```
  
The getWindDirGroup() function maps wind direction to a category such as NNE.  Because the METAR data are recorded in units of 10 degrees, either 4 groupings (90 degrees each) or 12 groupings (30 degrees each) are preferred, so that each category has the same underlying number of buckets:  
```{r}

# Extract the wind direction data from a processed METAR file
getWindDirGroup <- function(met, src) {
    
    # Use the fullMETAR data and extract WindDir, WindSpeed, month
    windPlotData <- met %>%
        select(WindDir, WindSpeed, month) %>%
        mutate(windDirGroup=factor(case_when(WindSpeed==0 ~ "No Wind", 
                                             WindDir=="VRB" ~ "Variable", 
                                             WindDir %in% c("350", "360", "010") ~ "N", 
                                             WindDir %in% c("020", "030", "040") ~ "NNE", 
                                             WindDir %in% c("050", "060", "070") ~ "ENE", 
                                             WindDir %in% c("080", "090", "100") ~ "E", 
                                             WindDir %in% c("110", "120", "130") ~ "ESE",
                                             WindDir %in% c("140", "150", "160") ~ "SSE", 
                                             WindDir %in% c("170", "180", "190") ~ "S", 
                                             WindDir %in% c("200", "210", "220") ~ "SSW",
                                             WindDir %in% c("230", "240", "250") ~ "WSW", 
                                             WindDir %in% c("260", "270", "280") ~ "W", 
                                             WindDir %in% c("290", "300", "310") ~ "WNW", 
                                             WindDir %in% c("320", "330", "340") ~ "NNW", 
                                             TRUE ~ "Error"
                                             ), 
                                   levels=c("No Wind", "Variable", "Error", 
                                            "N", "NNE", "ENE", 
                                            "E", "ESE", "SSE", 
                                            "S", "SSW", "WSW", 
                                            "W", "WNW", "NNW"
                                            )
                                   )
               )
    
    # Rempve the errors and calculate percentages by month for the remainder
    processedWindData <- windPlotData %>%
        filter(windDirGroup != "Error") %>%
        group_by(month, windDirGroup) %>%
        summarize(n=n()) %>%
        ungroup() %>%
        group_by(month) %>%
        mutate(pct=n/sum(n)) %>%
        ungroup() %>%
        mutate(src=src)
    
    processedWindData

}

```
  
The function conslidatePlotWind() then calls getWindDirGroup() for any number of files:  
```{r}

# Consolidate and plot wind data
consolidatePlotWind <- function(files, names) {

    consFun <- function(x, y) { getWindDirGroup(met=x, src=y) }
    boundByRows <- map2_dfr(.x=files, .y=names, .f=consFun)

    # Show frequency by month for each city, faceted by wind direction
    p1 <- boundByRows %>%
        ggplot(aes(x=month, y=pct, color=src)) + 
        geom_line(aes(group=src)) + 
        facet_wrap(~windDirGroup) + 
        labs(title="Wind Frequency by Month", 
             x="Month", 
             y="Frequency of Wind Observations"
             ) +
        theme(axis.text.x=element_text(angle=90))
    print(p1)
    
    # Show frequency by wind direction for each city, faceted by month
    p2 <- boundByRows %>%
        ggplot(aes(x=windDirGroup, y=pct, color=src)) + 
        geom_line(aes(group=src)) + 
        facet_wrap(~month) + 
        labs(title="Wind Frequency by Wind Direction", 
             x="Wind Direction", 
             y="Frequency of Wind Observations"
             ) +
        theme(axis.text.x=element_text(angle=90))
    print(p2)
    
    boundByRows
    
}

# Load the Las Vegas data and New Orleans data for comparison
kmsy_2016 <- readRDS("./RInputFiles/ProcessedMETAR/metar_kmsy_2016.rds")
klas_2016 <- readRDS("./RInputFiles/ProcessedMETAR/metar_klas_2016.rds")

# Run wind by month comparisons for Detroit, Las Vegas, New Orleans
consolidatePlotWind(files=list(kdtw_2016, klas_2016, kmsy_2016), 
                    names=c("Detroit, MI (2016)", "Las Vegas, NV (2016)", "New Orleans, LA (2016)")
                    )

```
  
#### _Combining Functions_  
The functions can be combined so that a full process can be run for a given file:  
```{r}

# File name to city name mapper
cityNameMapper <- c(kdtw_2016="Detroit, MI (2016)", 
                    kewr_2016="Newark, NJ (2016)",
                    kgrb_2016="Green Bay, WI (2016)",
                    kgrr_2016="Grand Rapids, MI (2016)",
                    kiah_2016="Houston, TX (2016)",
                    kind_2016="Indianapolis, IN (2016)",
                    klas_2015="Las Vegas, NV (2015)",
                    klas_2016="Las Vegas, NV (2016)", 
                    klas_2017="Las Vegas, NV (2017)", 
                    klnk_2016="Lincoln, NE (2016)",
                    kmke_2016="Milwaukee, WI (2016)",
                    kmsn_2016="Madison, WI (2016)",
                    kmsp_2016="Minneapolis, MN (2016)",
                    kmsy_2015="New Orleans, LA (2015)",
                    kmsy_2016="New Orleans, LA (2016)", 
                    kmsy_2017="New Orleans, LA (2017)", 
                    kord_2015="Chicago, IL (2015)",
                    kord_2016="Chicago, IL (2016)", 
                    kord_2017="Chicago, IL (2017)", 
                    ksan_2015="San Diego, CA (2015)",
                    ksan_2016="San Diego, CA (2016)",
                    ksan_2017="San Diego, CA (2017)",
                    ktvc_2016="Traverse City, MI (2016)"
                    )

# This is a helper function to create a locale description
getLocaleDescription <- function(x, mapper=cityNameMapper) {
    
    # Initialize the description as NULL
    desc <- NULL
    
    for (potMatch in names(mapper)) {
        if (str_detect(string=x, pattern=potMatch)) {
            desc <- mapper[potMatch]
            break
        }
    }
    
    # If the mapping failed, use UNMAPPED_x as the description
    if (is.null(desc)) {
        desc <- paste0("UNMAPPED_", x)
        cat("\nUnable to find a description, will use ", desc, "\n\n", sep="")
    } else {
        cat("\nWill use ", desc, " as the description for ", x, "\n\n", sep="")
    }
    
    # Return the descriptive name
    desc
    
}

# The following function runs the functions that work on a single data source
combinedEDA <- function(filename=NULL, 
                        tbl=NULL,
                        desc=NULL,
                        mets=c("WindDir", "WindSpeed", "TempC", "DewC", "Altimeter", 
                               "modSLP", "cType1", "cLevel1", "month", "day"
                               ),
                        corPairs=list(c("TempC", "TempF"), 
                                      c("TempC", "DewC"), 
                                      c("Altimeter", "modSLP"), 
                                      c("Altimeter", "WindSpeed")
                                      ),
                        fctPairs=list(c("month", "TempF"), 
                                      c("month", "DewF"), 
                                      c("month", "WindSpeed"), 
                                      c("month", "Altimeter"), 
                                      c("wType", "Visibility"), 
                                      c("wType", "WindSpeed"), 
                                      c("WindDir", "WindSpeed"), 
                                      c("WindDir", "TempF")
                                      ),
                        heatVars=c("TempC", "TempF", 
                                   "DewC", "DewF", 
                                   "Altimeter", "modSLP", 
                                   "WindSpeed", "Visibility", 
                                   "monthint", "day"
                                   ),
                        lmVars=list(c("modSLP", "Altimeter"), 
                                    c("modSLP", "Altimeter + TempF"), 
                                    c("TempF", "DewF"), 
                                    c("WindSpeed", "Altimeter + TempF + DewF + month")
                                    ),
                        mapVariables=varMapper,
                        mapFileNames=cityNameMapper,
                        path="./RInputFiles/ProcessedMETAR/"
                        ) {
    
    # Require that either filename OR tbl be passed
    if (is.null(filename) & is.null(tbl)) {
        cat("\nMust provide either a filename or an already-loaded tibble\n")
        stop("\nfilename=NULL and tbl=NULL may not both be passed to combinedEDA()\n")
    }
    
    # Require that either 1) filename and mapFileNames, OR 2) desc be passed
    if ((is.null(filename) | is.null(mapFileNames)) & is.null(desc)) {
        cat("\nMust provide either a filename with mapFileNames or a file description\n")
        stop("\nWhen desc=NULL must have non-null entries for both filename= and mapFileNames=\n")
    }
    
    # Find the description if it is NULL (default)
    if (is.null(desc)) {
        desc <- getLocaleDescription(filename, mapper=mapFileNames)
    }
    
    # Warn if both filename and tbl are passed, since tbl will be used
    if (!is.null(filename) & !is.null(tbl)) {
        cat("\nA tibble has been passed and will be used as the dataset for this function\n")
        warning("\nArgument filename=", filename, " is NOT loaded since a tibble was passed\n")
    }
    
    # Read in the file unless tbl has already been passed to the routine
    if (is.null(tbl)) {
        tbl <- readRDS(paste0(path, filename))
    }
    
    # Plot counts by metric
    plotcountsByMetric(tbl, mets=mets, title=desc, diagnose=TRUE)
    
    # Plot relationships between two variables
    for (ys in corPairs) {
        plotNumCor(tbl, var1=ys[1], var2=ys[2], subT=desc, diagnose=TRUE)
    }
    
    # plot numeric vs. factor
    for (ys in fctPairs) {
        plotFactorNumeric(tbl, fctVar=ys[1], numVar=ys[2], subT=desc, showXLabel=FALSE, diagnose=TRUE)
    }
    
    # Heatmap for variable correlations
    corMETAR(tbl, numVars=heatVars, subT=paste0(desc, " METAR"))

    # Run linear rergression
    for (ys in lmVars) {
        lmMETAR(tbl, y=ys[1], x=ys[2], yName=varMapper[ys[1]], subT=desc)
    }
    
    # Run the basic wind plots
    basicWindPlots(tbl, desc=desc, gran="")
    
    # Return the tibble
    tbl
    
}

```
  
The process can then be run for each of Detroit (2016), Las Vegas (2016), and New Orleans (2016):  
```{r cache=TRUE}

# Retrieve the Detroit, MI (2016) data
kdtw_2016 <- combinedEDA("metar_kdtw_2016.rds")

```

```{r cache=TRUE}

# Retrieve the Las Vegas, NV (2016) data
klas_2016 <- combinedEDA("metar_klas_2016.rds")

```

```{r cache=TRUE}

# Retrieve the New Orleans, LA (2016) data
kmsy_2016 <- combinedEDA("metar_kmsy_2016.rds")

```
  
#### _Directing Output to a Separate File_  
There is a lot of good information in the EDA, but it can be overwhelming to have everything in one place.  Perhaps a wrapper function can be built allowing for outputs to be piped to a given file:  
```{r}

wrapCombinedEDA <- function(readFile, 
                            readPath="./RInputFiles/ProcessedMETAR/", 
                            mapFileNames=cityNameMapper,
                            desc=NULL,
                            writeLogFile=NULL,
                            writeLogPDF=NULL,
                            writeLogPath=NULL,
                            appendWriteFile=FALSE,
                            ...
                            ) {
    
    # Read in the requested file
    tbl <- readRDS(paste0(readPath, readFile))

    # Find the description if it has not been passed
    if (is.null(desc)) {
        desc <- getLocaleDescription(readFile, mapper=mapFileNames)
    }
    
    # Helper function that only runs the combinedEDA() routine
    coreFunc <- function() { combinedEDA(tbl=tbl, desc=desc, mapFileNames=mapFileNames, ...) }
    
    # If writeLogPDF is not NULL, direct the graphs to a suitable PDF
    if (!is.null(writeLogPDF)) {
        
        # Prepend the provided log path if it has not been made available
        if (!is.null(writeLogPath)) {
            writeLogPDF <- paste0(writeLogPath, writeLogPDF)
        }
        
        # Provide the location of the EDA pdf file
        cat("\nEDA PDF file is available at:", writeLogPDF, "\n")

        # Redirect the writing to writeLogPDF
        pdf(writeLogPDF)
    }
    
    # Run EDA on the tbl using capture.output to redirect to a log file if specified
    if (!is.null(writeLogFile)) {
        
        # Prepend the provided log path if it has not been made available
        if (!is.null(writeLogPath)) {
            writeLogFile <- paste0(writeLogPath, writeLogFile)
        }
        
        # Provide the location of the EDA log file
        cat("\nEDA log file is available at:", writeLogFile, "\n")
        
        # Run EDA such that the output goes to the log file
        capture.output(coreFunc(), 
                       file=writeLogFile, 
                       append=appendWriteFile
                       )
        
    } else {
        # Run EDA such that output stays in stdout
        coreFunc()
    }
    
    # If writeLogPDF is not NULL, redirect to stdout
    if (!is.null(writeLogPDF)) {
        dev.off()
    }
    
    # Return the tbl
    tbl
    
}

```
  
```{r cache=TRUE}

filePath <- "./RInputFiles/ProcessedMETAR/"

# Example for the basic function for Chicago, IL (2016) written to stdout
kord_2016 <- wrapCombinedEDA("metar_kord_2016.rds", readPath=filePath)

```
  
```{r cache=TRUE}

# Example for the basic function for San Diego, CA (2016) written to 'metar_ksan_2016_EDA.log'
ksan_2016 <- wrapCombinedEDA("metar_ksan_2016.rds", 
                             readPath=filePath, 
                             writeLogFile='metar_ksan_2016_EDA.log',
                             writeLogPDF='metar_ksan_2016_EDA.pdf', 
                             writeLogPath=filePath
                             )

```
  
Finally, a function can be called to create the inputs to wrapCombinedEDA() for lower typing:  
```{r}

logAndPDFCombinedEDA <- function(tblName, filePath="./RInputFiles/ProcessedMETAR/") {
    
    # Create the RDS file name
    rdsName <- paste0("metar_", tblName, ".rds")
    cat("\nRDS Name:", rdsName)
    
    # Create the log file name
    logName <- paste0("metar_", tblName, "_EDA.log")
    cat("\nLog Name:", logName)
    
    # Create the PDF file name
    pdfName <- paste0("metar_", tblName, "_EDA.pdf")
    cat("\nPDF Name:", pdfName)
    
    # Call wrapCombinedEDA()
    tbl <- wrapCombinedEDA(rdsName, 
                           readPath=filePath, 
                           writeLogFile=logName, 
                           writeLogPDF=pdfName,
                           writeLogPath=filePath
                           )
    
    # Return the tbl
    tbl
    
}

```
  
This function can then be run for all of the relevant files (cached to avoid multiple runs):  
```{r cache=TRUE}

# Run for 2016 only for kdtw, kewr, kgrb, kgrr, kiah, kind, klnk, kmke, kmsn, kmsp, ktvc
kdtw_2016 <- logAndPDFCombinedEDA("kdtw_2016")
kewr_2016 <- logAndPDFCombinedEDA("kewr_2016")
kgrb_2016 <- logAndPDFCombinedEDA("kgrb_2016")
kgrr_2016 <- logAndPDFCombinedEDA("kgrr_2016")
kiah_2016 <- logAndPDFCombinedEDA("kiah_2016")
kind_2016 <- logAndPDFCombinedEDA("kind_2016")
klnk_2016 <- logAndPDFCombinedEDA("klnk_2016")
kmke_2016 <- logAndPDFCombinedEDA("kmke_2016")
kmsn_2016 <- logAndPDFCombinedEDA("kmsn_2016")
kmsp_2016 <- logAndPDFCombinedEDA("kmsp_2016")
ktvc_2016 <- logAndPDFCombinedEDA("ktvc_2016")

```
  
```{r cache=TRUE}

# Run for 2015-2016-2017 for klas, kmsy, kord, ksan
klas_2015 <- logAndPDFCombinedEDA("klas_2015")
klas_2016 <- logAndPDFCombinedEDA("klas_2016")
klas_2017 <- logAndPDFCombinedEDA("klas_2017")
kmsy_2015 <- logAndPDFCombinedEDA("kmsy_2015")
kmsy_2016 <- logAndPDFCombinedEDA("kmsy_2016")
kmsy_2017 <- logAndPDFCombinedEDA("kmsy_2017")
kord_2015 <- logAndPDFCombinedEDA("kord_2015")
kord_2016 <- logAndPDFCombinedEDA("kord_2016")
kord_2017 <- logAndPDFCombinedEDA("kord_2017")
ksan_2015 <- logAndPDFCombinedEDA("ksan_2015")
ksan_2016 <- logAndPDFCombinedEDA("ksan_2016")
ksan_2017 <- logAndPDFCombinedEDA("ksan_2017")

```
  
Reload Traverse City, MI (2016) due to a previous error (short-term fix to avoid re-running a full cache):  
```{r cache=TRUE}
ktvc_2016 <- logAndPDFCombinedEDA("ktvc_2016")
```

The files are now available for further analysis, with individual PDF files for plots associated with each locale.
  
#### _Comparing Multiple Locales_  
With EDA about each locale saved to .pdf and .log files, it is interesting to investigate comparisons among the various locales.  For example, how do the temperature patterns by month for a given locale compare to the overall global median temperature patterns by month?
  
The existing functions contain most of the code needed to perform this.  The main steps to add are:  
  
1.  Combine processed data files  
2.  Adapt the base functions to create the overall mean or median, when requested by parameter  
3.  Adapt the base functions to add the overall mean or median to the plot, when requested by parameter  
4.  Facet the plot by locale, when requested by parameter  
  
The first step is to combine one or more processed files, with a column added for locale:  
```{r}

# Combine files from a character list
combineProcessedFiles <- function(charList, mapper=cityNameMapper) {
    
    # Combine the objects represented by charList, and name the list items using charList
    listFiles <- lapply(charList, FUN=function(x) { get(x) })
    names(listFiles) <- charList
    
    # Bind rows, and add the descriptive locale name as sourceName
    tblFiles <- bind_rows(listFiles, .id="source") %>%
        mutate(sourceName=mapper[source])
    
    tblFiles
    
}

```
  
The 2016 data will be used to run the combined process:  
```{r}

# Grab all the data that ends in _2016
locales2016 <- ls() %>%
    grep(pattern="_2016", value=TRUE)
cat("\nLocales used will be:\n\n", paste0(locales2016, collapse="\n"), "\n\n", sep="")

# Combine the 2016 data
all2016Data <- combineProcessedFiles(locales2016)

# Show counts by sourceName
all2016Data %>%
    count(source, sourceName)

```
  
The following global summaries will be useful:  
  
* plotCountsByMetric() - overall percentage by metric, applied to total counts for locale  
* plotNumCor() - overall geom_smooth()  
* plotFactorNumeric() - overall mean/median of numeric by factor  
* corMETAR() and lmMETAR() - not applicable, though could be run on full dataset  
* basicWindPlots() - tbd, perhaps adapt along with consolidatePlotWind  
* consolidatePlotWind() - tbd, perhaps adapt along with basicWindPlots  
  
Helper functions can be created for:  
  
* helperCountsByMetric() - get the overall percentage by metric for variable x  
* helperNumCor() - get an overall geom_smooth for variable y vs. variable x  
* helperFactorNumeric() - get the overall mean or median for numeric variable y by factor variable x  
  
The function helperFactorNumeric is created to apply function f to numeric variable y by factor variable x:  
```{r}

# Helper function to get overall percentage by metric for variable x
helperCountsByMetric <- function(tbl, ctVar, sumOn="dummyVar") {

    tbl %>%
        mutate(dummyVar=1) %>%
        select_at(vars(all_of(c(ctVar, sumOn)))) %>%
        filter_all(all_vars(!is.na(.))) %>%
        group_by_at(ctVar) %>%
        summarize(n=sum(get(sumOn))) %>%
        mutate(nPct=n/sum(n))
        
}

# Example run to get counts by greatest sky obscuration
helperCountsByMetric(all2016Data, ctVar="wType")


# Helper function to get a geom_smooth for variable y vs variable x
helperNumCor <- function(tbl, 
                         xVar, 
                         yVar, 
                         sumOn="dummyVar",
                         se=TRUE, 
                         color="red", 
                         method="lm", 
                         lty=2
                         ) {
    
    # Generate the overall totals for sumOn by xVar and yVar
    plotData <- tbl %>%
        mutate(dummyVar=1) %>%
        select_at(vars(all_of(c(xVar, yVar, sumOn)))) %>%
        filter_all(all_vars(!is.na(.))) %>%
        group_by_at(vars(all_of(c(xVar, yVar)))) %>%
        summarize(nTotal=sum(get(sumOn)))
    
    geom_smooth(data=plotData, 
                aes_string(x=xVar, y=yVar, weight="nTotal"), 
                se=se, 
                color=color, 
                method=method, 
                lty=lty
                )
    
}

# Example run to get TempC vs DewC
helperNumCor(all2016Data, xVar="TempC", yVar="DewC")

# Example for using the helper function on a plot
plotNumCor(kdtw_2016, var1="TempC", var2="DewC") + 
    helperNumCor(all2016Data, xVar="TempC", yVar="DewC")


# Helper function to calculate .f(numVar) by byVar
helperFactorNumeric <- function(tbl, .f, byVar, numVar) {
    
    tbl %>%
        select_at(vars(all_of(c(byVar, numVar)))) %>%
        filter_all(all_vars(!is.na(.))) %>%
        group_by_at(byVar) %>%
        summarize(helpFN=.f(get(numVar)))
    
}

# Example for getting median TempF by month
helperFactorNumeric(all2016Data, .f=median, byVar="month", numVar="TempF")

```
  
The function plotCountsByMetric() has been updated above to allow for facetting and plotting of the overall central tendency.  Two examples are shown - the base from previous, and a facetted example:  
```{r}

# Previous Example for Detroit 2016 - using WindDir, cType1, month, wType
plotcountsByMetric(kdtw_2016, 
                   mets=c("WindDir", "cType1", "month", "wType"), 
                   title="Detroit, MI (2016)", 
                   dropNA=TRUE, 
                   diagnose=TRUE
                   )


# Facetted example for kdtw_2016, kord_2016, klas_2016, ksan_2016
useData <- all2016Data %>%
    filter(source %in% c("kdtw_2016", "klas_2016", "kord_2016", "ksan_2016"))

plotcountsByMetric(useData, 
                   mets=c("WindDir", "cType1", "month", "wType"), 
                   title="Comparison Across Locales (red dots are the median)", 
                   dropNA=TRUE, 
                   diagnose=TRUE, 
                   facetOn="sourceName", 
                   showCentral=TRUE
                   )

```
  
As observed previously, Las Vegas tends towards southerly winds while San Diego tends towards northwesterly winds and calm (direction 000) winds.  Detroit is most likely to be overcast, while Las Vegas is most likely to be clear.
  
The function plotNumCor() has been updated above to allow for facetting and plotting of the overall central tendency.  Two examples are shown - the base from previous, and a facetted example:  
```{r}

# Example for Detroit 2016 - using TempC and DewC
plotNumCor(kdtw_2016, var1="TempC", var2="DewC", subT="Detroit, MI (2016)", diagnose=TRUE)


# Facetted example for kdtw_2016, kord_2016, klas_2016, ksan_2016
useData <- all2016Data %>%
    filter(source %in% c("kdtw_2016", "klas_2016", "kord_2016", "ksan_2016"))

# Facetted plot for very highly correlated variables TempC and TempF
plotNumCor(useData, 
           var1="TempC", 
           var2="TempF", 
           subT="Comparison Across Locales (red dashed lines are the overall)", 
           dropNA=TRUE, 
           diagnose=TRUE, 
           facetOn="sourceName", 
           showCentral=TRUE
           )

# Facetted plot for highly correlated variables TempF and DewF
plotNumCor(useData, 
           var1="TempF", 
           var2="DewF", 
           subT="Comparison Across Locales (red dashed lines are the overall)", 
           dropNA=TRUE, 
           diagnose=TRUE, 
           facetOn="sourceName", 
           showCentral=TRUE
           )

```
  
The differences in the relationships between temperature and dew point stand out:  
  
* Chicago and Detroit have a wide spread of both temperature and dew point, and they tend to rise and fall together  
* San Diego has a narrow spread of both temperature and dew point, and they have a lesser tendency to rise and fall together  
* Las Vegas has very little change in average dew point wven as temperatures range from 30-100 degrees F  
  
In contrast, of course, temperatures measured in C and F all follow the same pattern regardless of city  
  
The function plotFactorNumeric() has been updated above to allow for facetting and plotting of the overall central tendency.  Two examples are shown - the base from previous, and a facetted example:  
```{r}

# Example for Detroit 2016 - using TempF and month
plotFactorNumeric(kdtw_2016, 
                  fctVar="month", 
                  numVar="TempF", 
                  subT="Detroit, MI (2016)", 
                  showXLabel=FALSE,
                  diagnose=TRUE
                  )


# Facetted example for kdtw_2016, kord_2016, klas_2016, ksan_2016
useData <- all2016Data %>%
    filter(source %in% c("kdtw_2016", "klas_2016", "kord_2016", "ksan_2016"))

plotFactorNumeric(useData, 
                  fctVar="month", 
                  numVar="TempF", 
                  subT="Overall median shown as red dot", 
                  showXLabel=FALSE,
                  diagnose=TRUE,
                  facetOn="sourceName", 
                  showCentral=TRUE
                  )

```
  
Las Vegas consistently runs above the overall median temperature, while Chicago and Detroit run below the overall median temperature, particularly during the cold season.  San Diego has little temperature variation by month and is thus below the median in the warm season and above the median in the cold season.
  
It is now possible to re-run the EDA plotting routines, focused on the 2016 data:  
```{r}

# Create rounded TempF and DewF in all2016Data
all2016Data <- all2016Data %>%
    mutate(TempF5=5*round(round(TempF)/5), 
           DewF5=5*round(round(DewF)/5), 
           WindSpeed5=5*round(WindSpeed/5),
           Altimeter10=round(Altimeter, 1)
           )

# Counts by Metric for all 2016 data
plotcountsByMetric(all2016Data, 
                   mets=c("month", "year",
                          "WindDir", "WindSpeed5", 
                          "Visibility", "Altimeter10",
                          "TempF5", "DewF5", 
                          "wType"
                          ), 
                   title="Comparisons Across Locales (red dots are the median)", 
                   facetOn="sourceName",
                   showCentral=TRUE
                   )

```
  
The cross-locale comparisons bring out a few salient features:  
  
DATA VOLUMES:  
* All locales have roughly the same amount of data by year and month, focused on 2016 and with 1-2 days on either side  
  
WIND DIRECTION and WIND SPEED:  
* Las Vegas has an excess of no/variable wind and of southerly winds, both appropriate for a desert  
* Houston has an excess of no wind and southerly winds, both appropriate for the Gulf Coast  
* San Diego has an excess of no wind and of northwesterly wind, both appropriate for the Pacific coast  
* Chicago, Grand Rapids, Indianapolis, Minneapolis, and Newark all have lower occurences of no wind, appropriate for relatively cold mid-latitude cities  
* Lincoln looks "about normal", with the exception that it has slightly more southerly winds; Lincoln is the only Great Plains locale in the analysis, and it appears to be a blend of Gulf Coast and Wintry  
* Detroit, Green Bay, Milwaukee, and New Orleans all look "about average"; this is not surprising in the first three cases given the predominance of cold, mid-latitude locales, but is surprising for New Orleans  
* Madison and Traverse City are surprising in that both show a predominance of no/variable winds; this is uncommon for cold-weather cities in the mid-latitude and merits further examination  
  
VISIBILITY:  
* The overwhelming majority of visibilities are 10SM (the highest that is recorded; more or less means unlimited in the METAR)  
* There is a data issue with a Visibility > 10 that should be addressed  
* Las Vegas is slightly more likely than most to have unlimited Visibility and Detroit is slightly less likely than most to have unlimited visibility  
  
ALTIMETER:  
* Las Vegas skews low as appropriate for a high-altitude desert locale  
* New Orleans and Houston show less variance, perhaps driven by being roughly at sea level and in close proximity to the Gulf of Mexico  
* San Diego shows very low variance, perhaps driven by being roughly at sea level and in close proximity to the Pacific Ocean  
  
TEMPERATURE:  
* Houston, Las Vegas, and New Orleans skew warm as expected  
* San Diego has ver low variance as expected  
* At a gross level, the other cities look similar to the median, likely driven by the predominance of cold, mid-latitude locales in the data file  
  
DEW POINT:  
* Houston and New Orleans skew very high as expected  
* Las Vegas skews very low as expected  
* San Diego has very low variance as expected  
  
SKY OBSCURATION:  
* Lincoln and Green Bay are the most likely to be CLR (clear, no clouds on the automated sensor).  This may be driven by a difference in maximum sensor heights, and is unexpected in Green Bay which should be frequently cloudy due to its latitude and proximity to a large body of water  
* Detroit, Traverse City, Grand Rapids, and Minneapolis are especially likely to be overcast  
* Las Vegas is especially likely to have few clouds or to be clear  
  
Next steps are to run the facetted comparisons for the numeric variables and the numeric vs. factor variables.  As well, there are some items above that merit further exploration.
  
