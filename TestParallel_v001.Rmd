---
title: "Test Parallel"
author: "davegoblue"
date: "May 3, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview and Background  
The parallel package in R allows for some very nice improvements in run time.  So far, I have been using 3 workers with Windows (number of threads minus 1), but I am curious more generally about the gains driven by parallel.  This program is a first effort to test speed vs. number of clusters.  
  
## Analysis  
First, the parallel and doParalel libraries are called, and information about the specific setup is printed:  
```{r}
library(parallel)
library(doParallel)

nLogical <- detectCores() ## defaults to logical=TRUE
nCore <- detectCores(logical=FALSE) ## will only find physical cores

print(paste0("This set-up has ",nLogical," cores, with ",nCore," being physical cores."))
```
  
Next, a time-waster function is set-up.  This function is designed to repeatedly do the maths on a vector, then to return the final vector.  It is purely to get the CPU cranking; there is no other purpose to the function:  
  
```{r}
timeWaster <- function(vecLen=factorial(8), nRuns=factorial(8)) {
    vecTemp <- rep(0, vecLen) ## Create numeric vector
    vecMeans <- rep(0, nRuns) ## Create the storage vector
    
    for (intCtr in 1:nRuns) {
        vecTemp <- vecTemp * rnorm(vecLen)
        vecTemp <- vecTemp + rnorm(vecLen)
        vecMeans[intCtr] <- mean(vecTemp)
    }
    
    return(vecMeans)
}
```
  
First, the time waster function is called sequentially (normally) for a timing benchmark:  
```{r}
baseTime <- proc.time()

temp <- timeWaster()
str(temp)
summary(temp)

seqTime <- proc.time() - baseTime

print("Ran sequentially: Time taken")
print(seqTime)
```
  
Next, the parallel processing routine is called with the following parameters:  
  
* The number of clusters will be the number of logical clusters minus 1 (3 total on my machine)  
* Each cluster will run the same timeWaster() function; importantly, there is no splitting up of the workload, so the 3 parallel clusters will do (in aggregate) 3 times as much work  
* Processing will run by way of foreach() %dopar% with .combine=c (concatenate it all in to one jumbo vector)  
  
The intent of the above is to establish a baseline for the inefficiencies introduced by running in parallel.  The machine needs to create its clusters, parse out work to them, and integrate their results.  This is sort of a fixed cost that will (likely) never be overcome.  
```{r}
baseTime <- proc.time()

nPars <- nLogical - 1 ## Default is to save 1 logical core for other processing
clCores <- makeCluster(nPars)
registerDoParallel(clCores)

temp <- foreach(parCtr=1:nPars, .combine=c) %dopar% {
    timeWaster()
}

stopCluster(clCores)
registerDoSEQ()

str(temp)
summary(temp)

parTime <- proc.time() - baseTime

print("Ran in parallel: Time taken")
print(parTime)
```

