---
title: "Coronavirus US - Data Updates"
author: "davegoblue"
date: "11/8/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background
This file is designed to analyze coronavirus data from a single state using three data sources:  
  
* [The COVID Tracking Project](https://covidtracking.com/) contains state-level data for cases, deaths, tests, and hospitalizations  
* [USA Facts](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/) contains county-level data for cases, deaths, and population  
* [CDC Weekly Deaths by Jurisdiction](https://catalog.data.gov/dataset/weekly-counts-of-deaths-by-jurisdiction-and-age-group) contains state-level data for total deaths by age cohort  
  
Code for processing data from each of these sources is available in:  
  
* Coronavirus_Statistics_CTP_v003  
* Coronavirus_Statistics_USAF_v003  
* Coronavirus_Statistics_CDC_v003  
  
The goal of this file is to download updated data for the three main data sources, and to explore the performance of the segments as measured against the new data.

Functions are sourced and a variable mapping file is created:  
```{r}

# All functions assume that tidyverse and its components are loaded and available
# Other functions are declared in the sourcing files or use library::function()
library(tidyverse)

# If the same function is in both files, use the version from the more specific source
source("./Coronavirus_Statistics_Functions_Shared_v003.R")
source("./Coronavirus_Statistics_Functions_CTP_v003.R")
source("./Coronavirus_Statistics_Functions_USAF_v003.R")
source("./Coronavirus_Statistics_Functions_CDC_v003.R")

# Create a variable mapping file
varMapper <- c("cases"="Cases", 
               "newCases"="Increase in cases, most recent 30 days",
               "casesroll7"="Rolling 7-day mean cases", 
               "deaths"="Deaths", 
               "newDeaths"="Increase in deaths, most recent 30 days",
               "deathsroll7"="Rolling 7-day mean deaths", 
               "cpm"="Cases per million",
               "cpm7"="Cases per day (7-day rolling mean) per million", 
               "newcpm"="Increase in cases, most recent 30 days, per million",
               "dpm"="Deaths per million", 
               "dpm7"="Deaths per day (7-day rolling mean) per million", 
               "newdpm"="Increase in deaths, most recent 30 days, per million", 
               "hpm7"="Currently Hospitalized per million (7-day rolling mean)", 
               "tpm"="Tests per million", 
               "tpm7"="Tests per million per day (7-day rolling mean)", 
               "cdcExcess"="Excess all-cause (CDC)", 
               "ctp_death7"="COVID Tracking Project", 
               "usaf_death7"="USA Facts",
               "CDC_deaths"="CDC total deaths",
               "CDC_excess"="CDC excess deaths",
               "CTP_cases"="COVID Tracking Project cases",
               "CTP_deaths"="COVID Tracking Project deaths",
               "CTP_hosp"="COVID Tracking Project hospitalized",
               "CTP_tests"="COVID Tracking Project tests",
               "USAF_cases"="USA Facts cases", 
               "USAF_deaths"="USA Facts deaths",
               "vpm7"="Per million people (7-day rolling daily average)",
               "vpm"="Per million people"
               )

```
  
#### _Data Updates (early November)_  
New data from COVID Tracking Project are downloaded and assessed against the existing state-level segments:  
```{r cache=TRUE}

# Use existing segments with updated data
locDownload <- "./RInputFiles/Coronavirus/CV_downloaded_201108.csv"
test_old_201108 <- readRunCOVIDTrackingProject(thruLabel="Nov 7, 2020", 
                                               downloadTo=if (file.exists(locDownload)) NULL else locDownload,
                                               readFrom=locDownload, 
                                               compareFile=readFromRDS("test_hier5_201025")$dfRaw,
                                               useClusters=readFromRDS("test_hier5_201025")$useClusters
                                               )
saveToRDS(test_old_201108, ovrWriteError=FALSE)

```
  
Cases appear to be spiking in some of the states in the segment that had previously been less impacted.  Hospitalizations in aggregate in this segment are starting to slope upwards, though not yet at the same rate as the increase in cases.

New data from USA Facts are downloaded and assessed against the existing county-level segments:  
```{r cache=TRUE}

# Locations for the population, case, and death file
popLoc <- "./RInputFiles/Coronavirus/covid_county_population_usafacts.csv"
caseLoc <- "./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20201109.csv"
deathLoc <- "./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20201109.csv"

# Run old segments against new data
cty_old_20201109 <- readRunUSAFacts(maxDate="2020-11-07", 
                                    popLoc=popLoc, 
                                    caseLoc=caseLoc, 
                                    deathLoc=deathLoc, 
                                    dlCaseDeath=!(file.exists(caseLoc) & file.exists(deathLoc)),
                                    oldFile=readFromRDS("cty_20201026")$dfBurden, 
                                    existingCountyClusters=readFromRDS("cty_20201026")$clustVec
                                    )
saveToRDS(cty_old_20201109, ovrWriteError=FALSE)

```

Cases appear to be growing in many of the county clusters, though deaths per million per day remain well below the peaks observed in April in the earlier-hit counties.

Next, all-cause death data from the CDC are downloaded and assessed:  
```{r cache=TRUE}

# Use data that have previously been downloaded
cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20201110.csv"
cdcList_20201110 <- readRunCDCAllCause(loc=cdcLoc, 
                                       startYear=2015, 
                                       curYear=2020,
                                       weekThru=36, 
                                       startWeek=9, 
                                       lst=readFromRDS("test_old_201108"), 
                                       epiMap=readFromRDS("epiMonth"), 
                                       agePopData=readFromRDS("usPopBucket2020"), 
                                       cvDeathThru="2020-09-05", 
                                       cdcPlotStartWeek=10, 
                                       dlData=!file.exists(paste0("./RInputFiles/Coronavirus/", cdcLoc))
                                       )

saveToRDS(cdcList_20201110, ovrWriteError=FALSE)

```

The death data can then be combined and analyzed, using the function from Coronavirus_Statistics_States_v003:  
```{r}

combineDeathData <- function(ctp, 
                             usaf, 
                             cdc, 
                             keyState, 
                             curYear=2020,
                             minDate=as.Date(paste0(curYear, "-01-01")), 
                             perMillion=FALSE,
                             glimpseIntermediate=FALSE, 
                             facetFreeY=!perMillion, 
                             returnData=TRUE
                             ) {
    
    # FUNCTION ARGUMENTS:
    # ctp: the list with COVID Tracking Project data
    # usaf: the data frame with USA Facts data
    # cdc: the list with CDC data
    # keyState: the state(s) to be explored
    # curYear: current year
    # minDate: the minimum date to use in the CDC data
    # perMillion: boolean, should data be show on a per-million-people basis?
    # glimpseIntermediate: boolean, should glimpses of frames be provided as they are built?
    # facetFreeY: boolean, should facets be created with free_y scales (only relevant if 2+ keyStates)
    # returnData: boolean, should the data frame be returned?
    
    # STEP 0a: Extract relevant elements from lists (use frame as-is if directly passed)
    if ("list" %in% class(ctp)) ctp <- ctp[["consolidatedPlotData"]]
    if ("list" %in% class(usaf)) usaf <- usaf[["clusterStateData"]]
    if ("list" %in% class(cdc)) cdc <- cdc[["stateAgg"]]
    
    # STEP 0b: Create a mapping file of date to epiWeek
    epiMap <- tibble::tibble(date=seq.Date(from=minDate, to=as.Date(paste0(curYear, "-12-31")), by="1 day"), 
                             week=lubridate::epiweek(date)
                             )
    
    # STEP 1: Filter to only relevant data
    # STEP 1a: COVID Tracking Project
    ctp <- ctp %>%
        ungroup() %>%
        filter(name=="deaths", state %in% keyState)
    if(glimpseIntermediate) glimpse(ctp)
    # STEP 1b: USA Facts
    usaf <- usaf %>%
        ungroup() %>%
        filter(state %in% keyState)
    if(glimpseIntermediate) glimpse(usaf)
    # STEP 1c: CDC
    cdc <- cdc %>%
        ungroup() %>%
        filter(year==curYear, state %in% keyState)
    if(glimpseIntermediate) glimpse(cdc)
    
    # STEP 2a: Sum the county-level data so that it is state-level data
    usafState <- usaf %>%
        group_by(state, date) %>%
        summarize(deaths=sum(deaths), dpm7=sum(dpm7*pop)/sum(pop), pop=sum(pop), .groups="drop_last") %>%
        ungroup()
    # STEP 2b: Convert the CDC data to an estimated daily total (split the weekly total evenly)
    cdcDaily <- cdc %>%
        left_join(epiMap, by=c("week")) %>%
        select(state, week, date, cdcDeaths=deaths, cdcExcess=delta) %>%
        mutate(cdcDeaths=cdcDeaths/7, cdcExcess=cdcExcess/7)
    
    # STEP 3: Create a state death-level database by date
    dailyDeath <- select(ctp, state, date, ctpDeaths=value, ctp_dpm7=vpm7, ctp_pop=pop) %>%
        full_join(select(usafState, state, date, usafDeaths=deaths, usaf_dpm7=dpm7, usaf_pop=pop), 
                  by=c("state", "date")
                  ) %>%
        full_join(cdcDaily, by=c("state", "date")) %>%
        arrange(state, date) %>%
        mutate(ctp_death7=ctp_dpm7*ctp_pop/1000000, usaf_death7=usaf_dpm7*usaf_pop/1000000)
    if(glimpseIntermediate) glimpse(dailyDeath)

    # STEP 4a: Assign a population by state
    statePop <- dailyDeath %>%
        group_by(state) %>%
        summarize(pop=max(usaf_pop, ctp_pop, na.rm=TRUE), .groups="drop_last")
    
    # STEP 4b: Plot the deaths data
    p1 <- dailyDeath %>%
        select(state, date, ctp_death7, usaf_death7, cdcExcess) %>%
        pivot_longer(-c(state, date), names_to="source", values_to="deaths") %>%
        filter(!is.na(deaths)) %>%
        left_join(statePop, by="state") %>%
        ggplot(aes(x=date, y=deaths*if(perMillion) (1000000/pop) else 1)) + 
        geom_line(aes(group=source, color=varMapper[source])) + 
        labs(x="", 
             y=paste0("Deaths", if(perMillion) " per million" else ""), 
             title=paste0(curYear, " deaths per day in ", paste0(keyState, collapse=", ")),
             subtitle=paste0("Rolling 7-day average", if(perMillion) " per million people" else ""),
             caption="CDC estimated excess all-cause deaths, weekly total divided by 7 to estimate daily total"
             ) + 
        scale_x_date(date_breaks="1 month", date_labels="%b") + 
        scale_color_discrete("Data source") + 
        theme(legend.position="bottom") + 
        geom_hline(yintercept=0, lty=2)
    if (length(keyState) > 1) p1 <- p1 + facet_wrap(~state, scales=if(facetFreeY) "free_y" else "fixed")
    print(p1)
    
    # STEP 5: Return the daily death file
    if(returnData) dailyDeath
    
}


# Example function
combineDeathData(ctp=test_old_201108, 
                 usaf=cty_old_20201109$clusterStateData, 
                 cdc=cdcList_20201110, 
                 keyState=c("NY", "NJ", "MA", "FL", "GA", "TX", "AZ", "MS", "LA", "MI", "IL", "WI"), 
                 perMillion=FALSE, 
                 returnData=FALSE
                 )

combineDeathData(ctp=test_old_201108, 
                 usaf=cty_old_20201109$clusterStateData, 
                 cdc=cdcList_20201110, 
                 keyState=c("NY", "NJ", "MA", "FL", "GA", "TX", "AZ", "MS", "LA", "MI", "IL", "WI"), 
                 perMillion=TRUE, 
                 returnData=FALSE
                 )

```
  
In general, the shapes of the curves are well aligned, though the CDC excess-deaths generally start earlier and peak higher than the coronavirus deaths curves from COVID Tracking Project and USA Facts.  In general, the northeastern states hit early have a classic epidemic peak curve, while the states hit later tend to have lower peaks (per million) but, in some cases, a much extended timeline of non-zero disease impact.

Next, an integrated state data file is created from the latest data:  
```{r}

ctpList <- readFromRDS("test_old_201108")
usafData <- readFromRDS("cty_old_20201109")$clusterStateData
cdcList <- readFromRDS("cdcList_20201110")

# Function to convert a COVID Tracking Project file for further processing
prepCTPData <- function(ctp) {
    
    # FUNCTION AGRUMENTS:
    # ctp: a properly formatted list or data frame containing processed COVID Tracking Project data

    # Pull the relevant data frame if a list has been passed    
    if ("list" %in% class(ctp)) ctp <- ctp[["consolidatedPlotData"]]

    # Ungroup the data, delete the state named 'cluster', and Create a value7 metric
    ctp <- ctp %>%
        ungroup() %>%
        filter(state != "cluster") %>%
        mutate(value7=ifelse(is.na(vpm7), NA, vpm7*pop/1000000))
    
    # Split state-cluster-population as a separate file unique by state
    ctpDemo <- ctp %>%
        group_by(state, cluster) %>%
        summarize(pop=max(pop, na.rm=TRUE), .groups="drop_last") %>%
        ungroup()
    
    # Create a final data file with the key elements
    ctpData <- ctp %>%
        rename(metric=name) %>%
        mutate(source="CTP", name=paste0(source, "_", metric)) %>%
        select(state, date, metric, source, name, value, value7, vpm, vpm7)
    
    # Return the key data frames
    list(ctpDemo=ctpDemo, ctpData=ctpData)
    
}

ctpPrepped <- prepCTPData(ctpList)



# Function to convert a USA Facts file for further processing
prepUSAFData <- function(usaf) {
    
    # FUNCTION AGRUMENTS:
    # usaf: a properly formatted list or data frame containing processed USA Facts data

    # Pull the relevant data frame if a list has been passed    
    if ("list" %in% class(usaf)) usaf <- usaf[["clusterStateData"]]

    # Sum the data to state, keeping only state-date-pop-cases-deaths, then pivot longer
    usaf <- usaf %>%
        group_by(state, date) %>%
        summarize(cases=sum(cases), deaths=sum(deaths), pop=sum(pop), .groups="drop_last") %>%
        ungroup() %>%
        pivot_longer(-c(state, date, pop), names_to="metric", values_to="value")
    
    # Create the rolling-7 for value, having grouped by state-pop-metric and sorted by date
    # Add the per million component
    usaf <- usaf %>%
        group_by(state, pop, metric) %>%
        arrange(date) %>%
        helperRollingAgg(origVar="value", newName="value7") %>%
        ungroup() %>%
        mutate(vpm=value*1000000/pop, vpm7=value7*1000000/pop)
    
    # Split state-pop as a separate file unique by state
    usafDemo <- usaf %>%
        group_by(state) %>%
        summarize(pop=max(pop, na.rm=TRUE), .groups="drop_last") %>%
        ungroup()
    
    # Create a final data file with the key elements
    usafData <- usaf %>%
        mutate(source="USAF", name=paste0(source, "_", metric)) %>%
        select(state, date, metric, source, name, value, value7, vpm, vpm7)
    
    # Return the key data frames
    list(usafDemo=usafDemo, usafData=usafData)
    
}

usafPrepped <- prepUSAFData(usafData)



# Function to convert a CDC file for further processing
prepCDCData <- function(cdc, 
                        popData,
                        startYear=2020, 
                        startDate=as.Date(paste0(startYear, "-01-01")), 
                        endDate=as.Date(paste0(startYear, "-12-31"))
                        ) {
    
    # FUNCTION AGRUMENTS:
    # cdc: a properly formatted list or data frame containing processed CDC data
    # popData: a file containing fields state-pop
    # startYear: starting year (CDC data will be filtered for this year and later)
    # startDate: the starting date for use in the mapping file to create daily estimates
    # endDate: the ending date for use in the mapping file to create daily estimates

    # Pull the relevant data frame if a list has been passed    
    if ("list" %in% class(cdc)) cdc <- cdc[["stateAgg"]]

    # Create a mapping file of dates to epiweek-epiyear
    epiMap <- tibble::tibble(date=seq.Date(from=startDate, to=endDate, by="1 day"), 
                             year=lubridate::epiyear(date),
                             week=lubridate::epiweek(date)
                             )
    
    # Filter the data to the relevant year and keep state-year-week-deaths-excess
    cdc <- cdc %>%
        filter(yearint >= startYear) %>%
        select(state, yearint, week, deaths, excess=delta)

    # Merge in the daily mapping file, divide all totals by 7 to reflect weekly to daily, and pivot longer
    cdc <- cdc %>%
        left_join(epiMap, by=c("yearint"="year", "week"="week")) %>%
        mutate(deaths=deaths/7, excess=excess/7) %>%
        select(state, date, deaths, excess) %>%
        pivot_longer(-c(state, date), names_to="metric", values_to="value")
    
    # Create the rolling-7 for value, having grouped by state-metric and sorted by date
    # Add the per million component
    cdc <- cdc %>%
        group_by(state, metric) %>%
        arrange(date) %>%
        helperRollingAgg(origVar="value", newName="value7") %>%
        ungroup() %>%
        left_join(select(popData, state, pop), by="state") %>%
        mutate(vpm=value*1000000/pop, 
               vpm7=value7*1000000/pop, 
               source="CDC", 
               name=paste0(source, "_", metric)
               ) %>%
        select(state, date, pop, metric, source, name, value, value7, vpm, vpm7)
    
    # Return the key data frame as a list
    list(cdcDemo=select(cdc, state, pop), cdcData=select(cdc, -pop))
    
}

# Create an integrated state demographics file
demoData <- ctpPrepped$ctpDemo %>%
    rename(popCTP=pop) %>%
    full_join(rename(usafPrepped$usafDemo, popUSAF=pop), by="state") %>%
    mutate(pop=pmax(popCTP, popUSAF))

cdcPrepped <- prepCDCData(cdcList, popData=demoData)



# Integrated state data
stateData <- ctpPrepped$ctpData %>%
    bind_rows(usafPrepped$usafData) %>%
    bind_rows(cdcPrepped$cdcData)
glimpse(stateData)

# Control totals
stateData %>%
    group_by(name) %>%
    summarize(value=sum(value, na.rm=TRUE), value7=sum(value7, na.rm=TRUE), .groups="drop_last")

```
  
The alignment of cases and deaths data can then be plotted:  
```{r}

plotStateMetric <- function(df, 
                            yVal, 
                            namesPlot, 
                            keyStates, 
                            namesSec=NULL,
                            scaleSec=NULL,
                            plotTitle=NULL,
                            plotSub=NULL,
                            plotCaption=NULL,
                            primYLab=NULL,
                            secYLab="Caution, different metric and scale",
                            facetFixed=TRUE,
                            mapper=varMapper, 
                            combStates=vector("character", 0), 
                            popData=NULL, 
                            yValPerCap=(yVal %in% c("vpm", "vpm7")), 
                            printPlot=TRUE, 
                            returnData=FALSE
                            ) {
    
    # FUNCTION ARGUMENTS:
    # df: data frame with integrated state data
    # yVal: column to use for the yValues
    # namesPlot: the values of column 'name' to be kept and plotted
    # keyStates: states to be included
    #            if more than one state is passed, facets will be created
    # namesSec: names to be plotted on a secondary y-axes
    # scaleSec: scale to be used for the secondary axis 
    #           namesSec/scaleSec should be similar in magnitude to namesPlot
    # plotTitle: plot title to be used (NULL means none)
    # plotSub: plot subtitle to be used (NULL means none)
    # plotCaption: plot caption to be used (NULL means none)
    # primYLab: primary y label (NULL means use mapper)
    # secYLab: secondary y label (default is "Caution, different metric and scale")
    # facetFixed: boolean, if TRUE scales="fixed", if FALSE scales="free_y"
    #             only relevant if length(keyStates) > 1
    # mapper: mapping file for variable names to descriptive names
    # combStates: states that should be combined together for plotting (named vector, c("state"="newName"))
    # popData: a population file for combining states
    # yValPerCap: boolean, is the y-value of type per-capita?
    # printPlot: boolean, whether to print the plots
    # returnData: boolean, whether to return the data
    
    # Routine is only set up for a secondary axis with facetFixed=TRUE
    if (!is.null(namesSec) & !facetFixed) stop("\nSecondary axis only programmed for scales='fixed'\n")
    
    # Include variables in namesSec as part of namesPlot so they are kept by filter
    if (!is.null(namesSec)) namesPlot <- unique(c(namesPlot, namesSec))
    
    # Filter the data for only the key elements
    df <- df %>%
        select_at(vars(all_of(c("state", "date", "name", yVal)))) %>%
        filter(state %in% keyStates, name %in% namesPlot)
    
    # If there is a list of states to combine, process them
    if (length(combStates) > 0) {
        if (is.null(popData)) { stop("\nCombining states requires population data\n") }
        # Create a data frame with population and new state names
        df <- df %>%
            left_join(select(popData, state, pop), by="state") %>%
            mutate(state=ifelse(state %in% names(combStates), combStates[state], state))
        # Aggregate to the new 'state' level data
        if (yValPerCap) {
            df <- df %>%
                group_by(state, date, name) %>%
                filter(!is.na(get(yVal))) %>%  # only sum population where yVal exists
                summarize(!!yVal:=sum(get(yVal)*pop)/sum(pop), pop=sum(pop), .groups="drop_last")
        } else {
            df <- df %>%
                group_by(state, date, name) %>%
                filter(!is.na(get(yVal))) %>% # only sum population where yVal exists
                summarize(!!yVal:=sum(get(yVal)), pop=sum(pop), .groups="drop_last")
        }
        # Ungroup data frame
        df <- df %>%
            ungroup()
    }
    
    # If there is a secondary scale but no scaleSec has been passed, create one
    if (!is.null(namesSec) & is.null(scaleSec)) {
        maxPrimary <- df %>%
            filter(name %in% setdiff(namesPlot, namesSec)) %>%
            summarize(max(get(yVal), na.rm=TRUE), .groups="drop_last") %>%
            max()
        maxSecondary <- df %>%
            filter(name %in% namesSec) %>%
            summarize(max(get(yVal), na.rm=TRUE), .groups="drop_last") %>%
            max()
        scaleSec <- maxSecondary/maxPrimary
        cat("\nWill scale by:", scaleSec, "\n")
    }
    
    # Create the primary y-axis label from mapper if it has not been passed
    if (is.null(primYLab)) primYLab <- mapper[yVal]
    
    # Create the relevant line plot
    if (printPlot) {
        p1 <- df %>%
            filter(!is.na(get(yVal))) %>%
            ggplot(aes_string(x="date")) + 
            geom_line(data=~filter(., name %in% setdiff(namesPlot, namesSec)), 
                      aes(y=get(yVal), group=name, color=mapper[name])
                      ) + 
            scale_x_date(date_breaks="1 month", date_labels="%b") + 
            geom_hline(aes(yintercept=0), lty=2) + 
            labs(x="") + 
            theme(axis.text.x = element_text(angle = 90))
        if (!is.null(namesSec)) {
            p1 <- p1 + 
                geom_line(data=~filter(., name %in% namesSec), 
                          aes(y=get(yVal)/scaleSec, color=mapper[name], group=name)
                          ) + 
                scale_y_continuous(name=primYLab, 
                                   sec.axis=sec_axis(~.*scaleSec, name=secYLab)
                                   )
        } else {
            p1 <- p1 + scale_y_continuous(name=primYLab)
        }
        if (length(keyStates) > 1) p1 <- p1 + facet_wrap(~state, scales=if(facetFixed) "fixed" else "free_y")
        if (!is.null(plotTitle)) p1 <- p1 + labs(title=plotTitle)
        if (!is.null(plotSub)) p1 <- p1 + labs(subtitle=plotSub)
        if (!is.null(plotCaption)) p1 <- p1 + labs(caption=plotCaption)
        p1 <- p1 + scale_color_discrete("Source and metric")
        print(p1)
    }
    
    if (returnData) return(df)
    
}

# Example of combining states
ne_casedeath <- plotStateMetric(stateData, 
                                yVal="vpm7", 
                                namesPlot=c("CTP_cases"),
                                namesSec=c("CTP_deaths"), 
                                keyStates=c("NY", "NJ", "MA", "CT", "RI", "NH", "VT", "ME"),
                                combStates=c("MA"="S NE", "CT"="S NE", "RI"="S NE", 
                                             "NH"="N NE", "VT"="N NE", "ME"="N NE"
                                             ),
                                plotTitle="2020 coronavirus burden per million per day (select states)", 
                                plotSub="Cases on main y-axis, deaths on secondary y-axis", 
                                primYLab="Cases per million (7-day rolling mean)",
                                secYLab="Deaths per million (7-day rolling mean)",
                                facetFixed=TRUE, 
                                popData=usafPrepped$usafDemo,
                                returnData=TRUE
                                )
ne_casedeath

```
  
An attempt is made to align the curves for two different metrics in a single locale:  
```{r}

alignCurves <- function(df, 
                        valueMetric, 
                        depName,
                        indepName=setdiff(unique(df$name), depName),
                        lagsTry=0:30, 
                        yLabel="Deaths per million", 
                        depLabel="cases",
                        textMetric=stringr::str_split(yLabel, pattern=" ")[[1]][1] %>% stringr::str_to_lower()
                        ) {
    
    # FUNCTION ARGUMENTS
    # df: a data frame containing state-date-name-valueMetric, with only 2 value types in 'name'
    # valueMetric: the name of the value metric
    # depName: the name of the dependent variable (the other will be the predictor)
    # indepName: the name of the predictor variable
    # lagsTry: the lagged values to attempt
    # yLabel: label for the y-axis
    # depLabel: label for the title (regression x-variable name)
    # textMetric: label for the title (regression y-variable name)
    
    # Check that there are only two values in column 'name'
    if (length(unique(df$name))!=2) { stop("\nFunction depends on 'name' having only two possible values\n") }
    
    # Arrange the data by state and date
    df <- df %>%
        arrange(state, date)
    
    # Function to make a data frame with a specific lag
    helperMakeLagData <- function(df, depName, indepName, valueMetric, lagValue) {
        depData <- df %>%
            filter(name==depName) %>%
            select_at(vars(all_of(c("state", "date", valueMetric)))) %>%
            purrr::set_names(c("state", "date", "depVar"))
        indepData <- df %>%
            filter(name==indepName) %>%
            group_by(state) %>%
            mutate(indepVar=lag(get(valueMetric), lagValue)) %>%
            ungroup() %>%
            select(state, date, indepVar)
        fullData <- depData %>%
            full_join(indepData, by=c("state", "date"))
        fullData
    }
    
    # Run a simple linear model for depName ~ lag(otherName, lagsTry) to assess performance
    lmResults <- vector("list", length(lagsTry))
    n <- 1
    for (lagValue in lagsTry) {
        # Run the linear model with no intercept, save, and increment
        lmResults[[n]] <- lm(depVar ~ indepVar:state + 0, 
                             data=helperMakeLagData(df, 
                                                    depName=depName, 
                                                    indepName=indepName, 
                                                    valueMetric=valueMetric, 
                                                    lagValue=lagValue
                                                    )
                             )
        n <- n + 1
    }
    
    # Find the best lag and coefficients
    dfResults <- tibble::tibble(lags=lagsTry, 
                                rsq=sapply(lmResults, FUN=function(x) summary(x)$r.squared)
                                )
    p1 <- dfResults %>%
        ggplot(aes(x=lags, y=rsq)) + 
        geom_point() + 
        labs(x="Lag", y="R-squared", title="R-squared vs. lag for aligning curves")
    print(p1)
    
    # Calculate the best lag and coefficients
    bestLag <- dfResults %>%
        filter(rsq==max(rsq)) %>%
        pull(lags)
    bestCoef <- coef(lmResults[[which(lagsTry==bestLag)]]) %>%
        as.data.frame() %>% 
        purrr::set_names("mult") %>%
        tibble::rownames_to_column("state") %>%
        mutate(state=str_replace(state, "indepVar:state", ""))
    
    # Plot the curves using the coefficients and lags
    bestDF <- helperMakeLagData(df, 
                                depName=depName, 
                                indepName=indepName, 
                                valueMetric=valueMetric, 
                                lagValue=bestLag
                                ) %>%
        filter(!is.na(indepVar)) %>%
        left_join(bestCoef, by="state") %>%
        mutate(pred=mult*indepVar)
    p2 <- bestDF %>%
        select(state, date, depVar, pred, mult) %>%
        pivot_longer(-c(state, date, mult)) %>%
        mutate(name=case_when(name=="depVar" ~ "Actual value", 
                              name=="pred" ~ "Predicted value\n(lag, mult)", 
                              TRUE ~ "Unknown Element"
                              )
               ) %>%
        ggplot(aes(x=date, y=value)) + 
        geom_line(aes(group=name, color=name)) + 
        geom_text(data=~filter(., date==max(date)), 
                  aes(x=date, y=+Inf, label=paste0("Multiplier: ", round(mult, 3))), 
                  hjust=1, 
                  vjust=1
                  ) +
        labs(x="", 
             y=yLabel, 
             title=paste0("Predicting ", 
                          textMetric, 
                          " based on lagged ", 
                          depLabel, 
                          " (best lag: ", 
                          bestLag, 
                          " days)"
                          ),
             subtitle="Best lag is based on highest correlation/R-squared, common across all facets"
             ) + 
        facet_wrap(~state) + 
        scale_x_date(date_breaks="1 month", date_labels="%b") + 
        theme(axis.text.x = element_text(angle = 90)) + 
        scale_color_discrete("Metric")
    print(p2)
    
    # Return the key data
    list(bestLag=bestLag, bestCoef=bestCoef, bestDF=bestDF, lmResults=lmResults)
    
}



createAndAlignCurves <- function(df, 
                                 yVal, 
                                 namesPlot, 
                                 keyStates,
                                 lagValueMetric,
                                 lagDepName,
                                 namesSec=NULL,
                                 scaleSec=NULL,
                                 plotTitle=NULL,
                                 plotSub=NULL,
                                 plotCaption=NULL,
                                 primYLab=NULL,
                                 secYLab="Caution, different metric and scale",
                                 facetFixed=TRUE,
                                 mapper=varMapper, 
                                 combStates=vector("character", 0), 
                                 popData=NULL, 
                                 yValPerCap = (yVal %in% c("vpm", "vpm7")), 
                                 printPlot=TRUE, 
                                 ...
                                 ) {
    
    # FUNCTION ARGUMENTS:
    # df: data frame with integrated state data
    # yVal: column to use for the yValues
    # namesPlot: the values of column 'name' to be kept and plotted
    # keyStates: states to be included
    #            if more than one state is passed, facets will be created
    # lagValueMetric: the metric to be used for checking lags (typically 'vpm7')
    # lagDepName: dependent variable (records in column 'name') to be used for the lagging process
    # namesSec: names to be plotted on a secondary y-axes
    # scaleSec: scale to be used for the secondary axis 
    #           namesSec/scaleSec should be similar in magnitude to namesPlot
    # plotTitle: plot title to be used (NULL means none)
    # plotSub: plot subtitle to be used (NULL means none)
    # plotCaption: plot caption to be used (NULL means none)
    # primYLab: primary y label (NULL means use mapper)
    # secYLab: secondary y label (default is "Caution, different metric and scale")
    # facetFixed: boolean, if TRUE scales="fixed", if FALSE scales="free_y"
    #             only relevant if length(keyStates) > 1
    # mapper: mapping file for variable names to descriptive names
    # combStates: states that should be combined together for plotting (named vector, c("state"="newName"))
    # popData: a population file for combining states
    # yValPerCap: boolean, is the y-value of type per-capita?
    # printPlot: boolean, whether to print the plots
    # ...: other arguments to be passed to alignCurves()

    # Create a frame to be used by the lagging process
    tempMetrics <- plotStateMetric(df, 
                                   yVal=yVal, 
                                   namesPlot=namesPlot,
                                   keyStates=keyStates,
                                   namesSec=namesSec, 
                                   scaleSec=scaleSec,
                                   plotTitle=plotTitle, 
                                   plotSub=plotSub, 
                                   plotCaption=plotCaption,
                                   primYLab=primYLab,
                                   secYLab=secYLab,
                                   facetFixed=facetFixed,
                                   mapper=mapper,
                                   combStates=combStates,
                                   popData=popData,
                                   yValPerCap=yValPerCap,
                                   printPlot=printPlot,
                                   returnData=TRUE  # the data must be returned for the next function
                                   )

    # Run the lagging process    
    tempLM <- alignCurves(tempMetrics, valueMetric=lagValueMetric, depName=lagDepName, ...)
    
    # Return the key values
    list(dfList=tempMetrics, lmList=tempLM)
    
}


# Example for northeastern states
neCurveList <- createAndAlignCurves(stateData, 
                                    yVal="vpm7", 
                                    namesPlot=c("CTP_cases"),
                                    namesSec=c("CTP_deaths"), 
                                    keyStates=c("NY", "NJ", "MA", "CT", "RI", "NH", "VT", "ME", "DE", "DC"),
                                    combStates=c("MA"="S NE", "CT"="S NE", "RI"="S NE", 
                                                 "NH"="N NE", "VT"="N NE", "ME"="N NE", 
                                                 "NY"="NY/NJ", "NJ"="NY/NJ", 
                                                 "DE"="DE/DC", "DC"="DE/DC"
                                                 ),
                                    plotTitle="2020 coronavirus burden per million per day (select states)", 
                                    plotSub="Cases on main y-axis, deaths on secondary y-axis", 
                                    primYLab="Cases per million (7-day rolling mean)",
                                    secYLab="Deaths per million (7-day rolling mean)",
                                    facetFixed=TRUE, 
                                    popData=usafPrepped$usafDemo, 
                                    printPlot=TRUE,
                                    lagValueMetric="vpm7", 
                                    lagDepName="CTP_deaths", 
                                    lagsTry=0:30
                                    )

# Example for midwestern states
mwCurveList <- createAndAlignCurves(stateData, 
                                    yVal="vpm7", 
                                    namesPlot=c("CTP_cases"),
                                    namesSec=c("CTP_deaths"), 
                                    keyStates=c("OH", "MI", "IN", "IL"),
                                    plotTitle="2020 coronavirus burden per million per day (select states)", 
                                    plotSub="Cases on main y-axis, deaths on secondary y-axis", 
                                    primYLab="Cases per million (7-day rolling mean)",
                                    secYLab="Deaths per million (7-day rolling mean)",
                                    facetFixed=TRUE, 
                                    popData=usafPrepped$usafDemo, 
                                    printPlot=TRUE,
                                    lagValueMetric="vpm7", 
                                    lagDepName="CTP_deaths", 
                                    lagsTry=0:30
                                    )

```
  
The midwest is challenging to align.  If using a single value for lag and a single value for CFR (case fatality rate), then predictions will have far too few deaths in the early months and far too many deaths in the later months.

The changes in CFR over time can also be estimated:  
```{r}

# Updated for automatic lag time assessment
assessStateCFR <- function(lst, 
                           keyStates, 
                           depVar, 
                           indepVar,
                           depTitleName, 
                           indepTitleName,
                           keyMetric="vpm7", 
                           lagEarlyDate=as.Date("2020-03-31"), 
                           lagMidDate=NULL,
                           lagLateDate=as.Date("2020-10-15"), 
                           lagEarlyValue=10, 
                           lagLateValue=20, 
                           lagsTry=0:30
                           ) {
    
    # FUNCTION ARGUMENTS:
    # lst: A list such as produced by createAndAlignCurves()
    # keyStates: The key states to be extracted from the list
    # depVar: the dependent variable
    # indepVar: the independent variable
    # depTitleName: the name for the dependent variable in the title
    # indepTitleName: the name for the independent variable in the plot title
    # keyMetric: the name of the key metric that is being assessed
    # lagEarlyDate: the date for the earliest lagging calculation (dates before this will be at lagEarlyValue)
    # lagMidDate: if lags are found from data, what midpoint should be used to split data as early vs late?
    #             NULL means midway between lagEarlyDate and lagLateDate
    # lagLateDate: the date for the latest lagging calculation (dates after this will be at lagLateValue)
    # lagEarlyValue: the value for lag on lagEarlyDate, will be linearly interpolated to lagLateValue/Date
    #                NULL means calculate from data and may differ by state
    # lagLateValue: the value for lag on lagLateDate, will be linearly interpolated from lagEarlyValue/Date
    #               NULL means estimate from data and may differ by state
    # lagsTry: the values for lag to be attempted if lageEarlyValue and/or lagLateValue is NULL
    
    # Extract the data for keyStates
    df <- lst[["dfList"]] %>%
        filter(state %in% keyStates, !is.na(get(keyMetric))) %>%
        pivot_wider(names_from="name", values_from=keyMetric)

    # Function for finding lag time correlations
    helperLagCor <- function(lt, lf, dp, id) {
        lf %>%
            group_by(state) %>%
            mutate(y=get(dp), x=lag(get(id), lt)) %>%
            summarize(p=cor(x, y, use="complete.obs"), .groups="drop_last") %>%
            ungroup() %>%
            mutate(lag=lt)
    }
    
    # Middle date for splitting data
    if (is.null(lagMidDate)) lagMidDate <- mean(c(lagEarlyDate, lagLateDate))
    
    # Get the early lags from the data
    eLag <- map_dfr(.x=lagsTry, .f=helperLagCor, lf=filter(df, date<=lagMidDate), dp=depVar, id=indepVar) %>%
        group_by(state) %>%
        filter(p==max(p)) %>%
        filter(row_number()==1) %>%
        ungroup() %>%
        select(state, earlyLag=lag)
    
    # Get the late lags from the data
    lLag <- map_dfr(.x=lagsTry, .f=helperLagCor, lf=filter(df, date>lagMidDate), dp=depVar, id=indepVar) %>%
        group_by(state) %>%
        filter(p==max(p)) %>%
        filter(row_number()==1) %>%
        ungroup() %>%
        select(state, lateLag=lag)
    
    # Create the full lag frame, including substituting the fixed value(s) if provided
    lagFrame <- eLag %>%
        inner_join(lLag, by="state")
    if (!is.null(lagEarlyValue)) lagFrame <- lagFrame %>% mutate(earlyLag=lagEarlyValue)
    if (!is.null(lagLateValue)) lagFrame <- lagFrame %>% mutate(lateLag=lagLateValue)
    print(lagFrame)
    
    # Apply the assumed lagging information
    fullTime <- as.integer(lagLateDate-lagEarlyDate)
    df <- df %>%
        left_join(lagFrame, by="state") %>%
        arrange(state, date) %>%
        group_by(state) %>%
        mutate(eLag=lag(get(indepVar), mean(earlyLag)), 
               lLag=lag(get(indepVar), mean(lateLag)), 
               pctEarly=pmin(pmax(as.integer(lagLateDate-date)/fullTime, 0), 1), 
               x=ifelse(is.na(eLag), NA, pctEarly*eLag + (1-pctEarly)*ifelse(is.na(lLag), 0, lLag)), 
               y=get(depVar),
               mon=factor(month.abb[lubridate::month(date)], levels=month.abb)
               ) %>%
        filter(!is.na(x)) %>%
        ungroup()

    # Regression for data from keyStates
    if (length(keyStates) > 1) stateLM <- lm(y ~ x:mon:state + 0, data=df, na.action=na.exclude) 
    else stateLM <- lm(y ~ x:mon + 0, data=df, na.action=na.exclude)
    
    # Add the predicted value to df
    df <- df %>%
        mutate(pred=predict(stateLM))

    # Plot of curve overlaps
    p1 <- df %>%
        select(state, date, y, pred) %>%
        pivot_longer(-c(state, date)) %>%
        ggplot(aes(x=date, y=value)) + 
        geom_line(aes(color=c("pred"="Predicted", "y"="Actual")[name], group=name)) + 
        scale_x_date(date_breaks="1 month", date_labels="%b") + 
        labs(x="", 
             y=stringr::str_to_title(depTitleName), 
             title=paste0("Predicted vs. actual ", depTitleName)
             ) +
        scale_color_discrete("Metric") +
        facet_wrap(~state)
    print(p1)
    
    # Plot of rate by month
    p2 <- coef(stateLM) %>%
        as.data.frame() %>%
        purrr::set_names("CFR") %>%
        tibble::rownames_to_column("monState") %>%
        mutate(mon=factor(stringr::str_replace_all(monState, pattern="x:mon|:state.+", replacement=""), 
                          levels=month.abb
                          ), 
               state=if (length(keyStates)==1) keyStates 
                     else stringr::str_replace_all(monState, pattern="x:mon[A-Za-z]{3}:state", replacement="")
               ) %>%
        left_join(lagFrame, by="state") %>%
        ggplot(aes(x=mon, y=CFR)) + 
        geom_col(fill="lightblue") + 
        geom_text(aes(y=CFR/2, label=paste0(round(100*CFR, 1), "%"))) +
        geom_text(data=~filter(., mon==month.abb[lubridate::month(lagMidDate)]), 
                  aes(x=-Inf, y=Inf, label=paste0("Early Lag: ", earlyLag)), 
                  hjust=0, 
                  vjust=1
                  ) + 
        geom_text(data=~filter(., mon==month.abb[lubridate::month(lagMidDate)]), 
                  aes(x=Inf, y=Inf, label=paste0("Late Lag: ", lateLag)), 
                  hjust=1, 
                  vjust=1
                  ) + 
        labs(x="", 
             y=paste0(stringr::str_to_title(depTitleName), " as percentage of lagged ", indepTitleName), 
             title=paste0(stringr::str_to_title(depTitleName), 
                          " vs. lagged ", 
                          indepTitleName, 
                          " in state(s): ", 
                          paste0(keyStates, collapse=", ")
                          ), 
             subtitle=paste0("Assumed early lag on ", 
                             lagEarlyDate,
                             " interpolated to late lag on ", 
                             lagLateDate
                             ), 
             caption="Linear model coefficients on lagged data with no intercept used to estimate percentage"
             ) + 
        facet_wrap(~state)
    print(p2)

    # Return the data frame
    df
    
}

# Deaths vs. cases in Michigan
mwOut <- assessStateCFR(mwCurveList, 
                        keyStates=c("MI", "IL", "IN"), 
                        depVar="CTP_deaths", 
                        indepVar="CTP_cases", 
                        depTitleName="deaths", 
                        indepTitleName="cases", 
                        lagEarlyValue=NULL,
                        lagLateValue=NULL
                        )

# Deaths vs. cases in NY/NJ and S NE
neOut <- assessStateCFR(neCurveList, 
                        keyStates=c("NY/NJ", "S NE"), 
                        depVar="CTP_deaths", 
                        indepVar="CTP_cases", 
                        depTitleName="deaths", 
                        indepTitleName="cases", 
                        lagEarlyValue=NULL,
                        lagLateValue=NULL
                        )

```
  
The CFR declines in more recent months, possibly as a function of a greater number of tests finding less serious disease.  Lag times are variable but typically seem to be around a week.  The use of both lag times and variable CFR by month introduces some risk of over-fitting.

The process for investigating lags and leads can also be refreshed with new data:  
```{r}

lagVectorWindows <- function(v1, 
                             v2, 
                             lagsTry=0:30, 
                             windowSize=30, 
                             minNoNA=ceiling(windowSize/2), 
                             updateStatus=FALSE, 
                             isLag=TRUE
                             ) {
    
    # FUNCTION ARGUMENTS:
    # v1: the first vector, which will be used 'as is'
    # v2: the second vector, which will be lagged/led by various values for lagsTry
    # lagsTry: the values for x that will be used in cor(v1, lag/lead(v2, x))
    # windowSize: the size of the window to use in taking snippets of v1 and lagged/led v2
    # minNoNA: minimum number of non-NA lagged/led values needed to calculate a correlation
    # updateStates: whether to print which window is being worked on
    # isLag: boolean, should a lag or a lead be applied (TRUE is lag, FALSE is lead)
    
    # Find the function to be used
    func <- if (isLag) lag else lead
    
    # Find the list of all possible window start points
    windowStarts <- 1:(length(v1)-windowSize+1)
    
    # Helper function to create a frame of correlations
    helperCorr <- function(s) {
        
        # Create the end point for the vector
        e <- s + windowSize - 1
        
        # Announce the start
        if (updateStatus) cat("\nProcessing window starting at:", s)
        
        # Create the correlations tibble for all values of lag, and return
        tibble::tibble(startWindow=s, endWindow=e, lags=lagsTry) %>%
            mutate(na1=sum(is.na(v1[s:e])), 
                   na2=sapply(lags, FUN=function(x) sum(is.na(func(v2, x)[s:e]))), 
                   p=sapply(lags, 
                            FUN=function(x) { 
                                ifelse(sum(!is.na(func(v2, x)[s:e])) < minNoNA,
                                       NA, 
                                       cor(v1[s:e], func(v2, x)[s:e], use="complete.obs")
                                       ) 
                                } 
                            )
                   )
    }

    # Bind the correlations frames and return
    map_dfr(windowStarts, .f=helperCorr)
    
}



# Function to assess correlations by lag/lead and window by state
stateCorr <- function(lst, 
                      keyState, 
                      met="vpm7", 
                      v1Name="CTP_deaths", 
                      v2Name="CTP_cases", 
                      windowSize=42, 
                      isLag=TRUE
                      ) {
    
    # FUNCTION ARGUMENTS:
    # lst: the processed list
    # keyState: the state of interest
    # met: the metric of interest
    # v1Name: the name of the first vector (this is considered fixed)
    # v2Name: the name of the second vector (this will have the lead/lag applied to it)
    # windowSize: number of days in the window
    # isLag: boolean, whether to use lag (TRUE) or lead (FALSE) on v2Name
    
    # Extract the data for the key State
    df <- lst[["dfList"]] %>%
        filter(state %in% keyState, !is.na(get(met))) %>%
        arrange(state, date, name)
    
    # Get the minimum date that is common to both
    minDate <- df %>%
        group_by(name) %>%
        summarize(date=min(date), .groups="drop_last") %>%
        pull(date) %>%
        max()
    
    # Extract v1 and v2
    v1 <- df %>% 
        filter(name==v1Name, date>=minDate) %>% 
        pull(met)
    v2 <- df %>% 
        filter(name==v2Name, date>=minDate) %>% 
        pull(met)

    # Confirm that dates are the same for both vectors
    dfDates1 <- df %>% filter(name==v1Name, date>=minDate) %>% pull(date)
    dfDates2 <- df %>% filter(name==v2Name, date>=minDate) %>% pull(date)
    if (!all.equal(dfDates1, dfDates2)) stop("\nDate mismatch\n")

    # Find the lags in the data
    dfLags <- lagVectorWindows(v1, v2, lagsTry=0:30, windowSize=windowSize, isLag=isLag) %>%
        mutate(windowStartDate=dfDates1[startWindow])

    # Give the description of the lag or lead
    descr <- ifelse(isLag, "lag (days)", "lead (days)")
    
    # Boxplot of correlations by lag
    p1 <- dfLags %>%
        filter(!is.na(p)) %>%
        ggplot(aes(x=factor(lags), y=p)) + 
        geom_boxplot(fill="lightblue") + 
        labs(x=stringr::str_to_title(descr), 
             y="Correlation", 
             title=paste0("Box plot of correlation by ", descr)
             )
    print(p1)

    # Plot of best lags by starting date
    p2 <- dfLags %>%
        filter(!is.na(p)) %>%
        group_by(startWindow) %>%
        filter(p==max(p)) %>%
        ggplot(aes(x=windowStartDate, y=lags)) + 
        geom_point(aes(size=p)) + 
        labs(x="Window start date", 
             y=paste0("Best ", descr), 
             title=paste0("Best ", descr, " by window starting date")
             ) + 
        scale_size_continuous(paste0("p at best ", stringr::str_replace(descr, " .*", ""))) + 
        scale_x_date(date_breaks="1 month", date_labels="%b")
    print(p2)
    
    # Plot of correlations by lag
    p3 <- dfLags %>%
        filter(!is.na(p)) %>%
        ggplot(aes(x=windowStartDate, y=lags)) + 
        geom_tile(aes(fill=p)) + 
        labs(x="Window start date", 
             y=stringr::str_to_title(descr), 
             title=paste0(stringr::str_to_title(descr), " by window starting date")
             ) + 
        scale_color_continuous(paste0("p at ", stringr::str_replace(descr, " .*", ""))) + 
        scale_x_date(date_breaks="1 month", date_labels="%b")
    print(p3)

    # Rename variable lags to leads if isLag is FALSE
    if (isFALSE(isLag)) dfLags <- dfLags %>%
        rename(leads=lags)
    
    # Return dfLags
    dfLags
    
}


miLeadData <- stateCorr(mwCurveList, keyState="MI", v1Name="CTP_cases", v2Name="CTP_deaths", isLag=FALSE)
nynjLeadData <- stateCorr(neCurveList, keyState="NY/NJ", v1Name="CTP_cases", v2Name="CTP_deaths", isLag=FALSE)

```
  
And the full process can be run for the state of Texas:  
```{r}

# Example for southern states
soCurveList <- createAndAlignCurves(stateData, 
                                    yVal="vpm7", 
                                    namesPlot=c("CTP_cases"),
                                    namesSec=c("CTP_deaths"), 
                                    keyStates=c("AZ", "FL", "GA", "TX"),
                                    plotTitle="2020 coronavirus burden per million per day (select states)", 
                                    plotSub="Cases on main y-axis, deaths on secondary y-axis", 
                                    primYLab="Cases per million (7-day rolling mean)",
                                    secYLab="Deaths per million (7-day rolling mean)",
                                    facetFixed=TRUE, 
                                    popData=usafPrepped$usafDemo, 
                                    printPlot=TRUE,
                                    lagValueMetric="vpm7", 
                                    lagDepName="CTP_deaths", 
                                    lagsTry=0:30
                                    )

assessStateCFR(soCurveList, 
               keyStates=c("AZ", "FL", "GA", "TX"), 
               depVar="CTP_deaths", 
               indepVar="CTP_cases", 
               depTitleName="deaths", 
               indepTitleName="cases"
               )


txLeadData <- stateCorr(soCurveList, keyState="TX", v1Name="CTP_cases", v2Name="CTP_deaths", isLag=FALSE)

```

The process for assessing integrated data is converted to a main function:  
```{r}

integrateStateData <- function(stateData=NULL, 
                               popData=NULL,
                               ctpList=NULL,
                               usafData=NULL,
                               cdcList=NULL, 
                               glimpseStateData=NULL, 
                               runAll=FALSE,
                               runTwoAxis=runAll, 
                               yVal="vpm7", 
                               var1="CTP_cases", 
                               var2="CTP_deaths", 
                               keyStates=sort(c(state.abb, "DC")), 
                               combStates=vector("character", 0), 
                               mapper=varMapper, 
                               runCreateAlign=runAll, 
                               lagsTry=0:30, 
                               runCFR=runAll, 
                               lagEarlyValue=10, 
                               lagLateValue=20, 
                               lagEarlyDate=as.Date("2020-03-31"), 
                               lagMidDate=NULL,
                               lagLateDate=as.Date("2020-10-15")
                               ) {
    
    # FUNCTION ARGUMENTS:
    # stateData: an integrated state-level data file (NULL means create from components)
    # popData: a state-level population data file (must be passed if stateData is not NULL)
    # ctpList: a processed list of COVID Tracking Project data (must be provided if stateData=NULL)
    # usafData: a processed tibble of USA Facts data (must be provided if stateData=NULL)
    # cdcList: a processed list of CDC All-Cause deaths data (must be provided if stateData=NULL)
    # glimpseStateData: boolean, whether to glimpse the stateData file (NULL means only if from components)
    # runAll: boolean, whether to set al of runTwoAxis, runCreateAlign, and runCFR all to the same value
    # runTwoAxis: whether to show a plot of two metrics on two axes
    # yVal: the y-value to use from stateData
    # var1: the first of the two variables of interest (should be the leading component if a drives b)
    # var2: the second of the two variables of interest (should be the lagging component if a drives b)
    # keyStates: subset of states to use for analysis
    # combStates: states that should be combined together for plotting (named vector, c("state"="newName"))
    # mapper: mapping file for variables to descriptive names
    # runCreateAlign: boolean, should createAndAlignCurves() be run?
    # lagsTry: lag values to try (applies to both createAlignCurves and assessStateCFR)
    # runCFR: boolean, should assessStateCFR be run?
    # lagEarlyValue: the value for lag on lagEarlyDate, will be linearly interpolated to lagLateValue/Date
    #                NULL means calculate from data and may differ by state
    # lagLateValue: the value for lag on lagLateDate, will be linearly interpolated from lagEarlyValue/Date
    #               NULL means estimate from data and may differ by state
    # lagEarlyDate: the date for the earliest lagging calculation (dates before this will be at lagEarlyValue)
    # lagMidDate: if lags are found from data, what midpoint should be used to split data as early vs late?
    #             NULL means midway between lagEarlyDate and lagLateDate
    # lagLateDate: the date for the latest lagging calculation (dates after this will be at lagLateValue)
    
    # Check that either stateData or its components have been provided
    if (!is.null(stateData)) {
        cat("\nA file has been passed for stateData, components will be ignored\n")
        if (is.null(popData)) stop("Must also pass a popData file of state-level population\n")
        if (is.null(glimpseStateData)) glimpseStateData <- FALSE
    } else {
        if (is.null(ctpList) | is.null(usafData) | is.null(cdcList)) {
            stop("\nMust provided all of ctpList, usafData, cdcList when stateData is NULL\n")
        }
        cat("\nBuilding stateData from the passed components\n")
        if (is.null(glimpseStateData)) glimpseStateData <- TRUE
        
        # Create COVID Tracking Project File
        ctpPrepped <- prepCTPData(ctpList)
        
        # Create USA Facts file
        usafPrepped <- prepUSAFData(usafData)
        
        # Create an integrated state population demographics file
        demoData <- ctpPrepped$ctpDemo %>%
            rename(popCTP=pop) %>%
            full_join(rename(usafPrepped$usafDemo, popUSAF=pop), by="state") %>%
            mutate(pop=pmax(popCTP, popUSAF))
        
        # Create CDC All-Cause File
        cdcPrepped <- prepCDCData(cdcList, popData=demoData)

        # Integrated state data
        stateData <- ctpPrepped$ctpData %>%
            bind_rows(usafPrepped$usafData) %>%
            bind_rows(cdcPrepped$cdcData)
        
        # Create popData if not provided
        if (is.null(popData)) popData <- demoData %>% select(state, pop)
        
    }
    
    # Show summaries of stateData if requested
    if (glimpseStateData) {
        # Glimpse the file
        glimpse(stateData)
        # Show control totals
        stateData %>%
            group_by(name) %>%
            summarize(value=sum(value, na.rm=TRUE), value7=sum(value7, na.rm=TRUE), .groups="drop_last") %>%
            print()
    }
    
    # Run plotStateMetric if requested
    if (runTwoAxis) {
        caseDeath <- plotStateMetric(stateData, 
                                     yVal=yVal, 
                                     namesPlot=var1,
                                     namesSec=var2, 
                                     keyStates=keyStates,
                                     combStates=combStates,
                                     plotTitle="2020 coronavirus burden per million per day (select states)", 
                                     plotSub="Caution that metrics are on different axes and scales",
                                     primYLab=paste0(mapper[var1], "\n", mapper[yVal]), 
                                     secYLab=paste0(mapper[var2], "\n", mapper[yVal]), 
                                     facetFixed=TRUE, 
                                     popData=popData,
                                     returnData=TRUE
                                     )
    } else {
        caseDeath <- NULL
    }
 
    # Run createAndAlignCurves() if requested
    if (runCreateAlign) {
        curveList <- createAndAlignCurves(stateData, 
                                          yVal=yVal, 
                                          namesPlot=var1,
                                          namesSec=var2, 
                                          keyStates=keyStates,
                                          combStates=combStates,
                                          plotTitle="2020 coronavirus burden per million per day (select states)", 
                                          plotSub="Caution that metrics are on different axes and scales",
                                          primYLab=paste0(mapper[var1], "\n", mapper[yVal]), 
                                          secYLab=paste0(mapper[var2], "\n", mapper[yVal]), 
                                          facetFixed=TRUE, 
                                          popData=popData,
                                          printPlot=TRUE,
                                          lagValueMetric=yVal, 
                                          lagDepName=var2, 
                                          lagsTry=lagsTry
                                          )
        
    } else {
        curveList <- NULL
    }
    
    # Run assessStateCFR() if requested (requires that curveList have been created)
    if (runCFR & is.null(curveList)) {
        cat("\nassessStateCFR requires runCreateAlign=TRUE; skipping and setting runCFR=FALSE\n")
        runCFR <- FALSE
    }
    if (runCFR) {
        # Create the list of key states based on keyStates and combStates
        useStates <- keyStates
        for (ctr in 1:length(useStates)) { 
            if (useStates[ctr] %in% names(combStates)) useStates[ctr] <- combStates[useStates[ctr]]
        }
        useStates <- unique(useStates)
        # Run assessStateCFR
        cfrList <- assessStateCFR(curveList, 
                                  keyStates=useStates, 
                                  depVar=var2, 
                                  indepVar=var1, 
                                  depTitleName=stringr::str_replace(var2, ".*_", ""), 
                                  indepTitleName=stringr::str_replace(var1, ".*_", ""), 
                                  keyMetric=yVal,
                                  lagEarlyDate=lagEarlyDate,
                                  lagMidDate=lagMidDate,
                                  lagLateDate=lagLateDate,
                                  lagEarlyValue=lagEarlyValue,
                                  lagLateValue=lagLateValue,
                                  lagsTry=lagsTry
                                  )
    } else {
        cfrList <- NULL
    }
    
    # Return a list of the key data
    list(stateData=stateData, popData=popData, caseDeath=caseDeath, curveList=curveList, cfrList=cfrList)
    
}


# Example for creating a full stateData file
fullStateList <- integrateStateData(ctpList=readFromRDS("test_old_201108"), 
                                    usafData=readFromRDS("cty_old_20201109")$clusterStateData, 
                                    cdcList=readFromRDS("cdcList_20201110")
                                    )
fullStateList

# Example for using the full stateData file
nenynjList <- integrateStateData(stateData=fullStateList$stateData, 
                                 popData=fullStateList$popData,
                                 runAll=TRUE,
                                 keyStates=c("NY", "NJ", "MA", "CT", "RI", "NH", "VT", "ME"),
                                 combStates=c("MA"="S NE", "CT"="S NE", "RI"="S NE", 
                                              "NH"="N NE", "VT"="N NE", "ME"="N NE"
                                              ), 
                                 lagEarlyValue=NULL,
                                 lagLateValue=NULL
                                 )

# Example for alignment between USA Facts and CTP
testList <- integrateStateData(stateData=fullStateList$stateData, 
                               popData=fullStateList$popData,
                               runAll=TRUE,
                               keyStates=c("NY", "NJ", "MA", "CT", "RI", "NH", "VT", "ME"),
                               combStates=c("MA"="S NE", "CT"="S NE", "RI"="S NE", 
                                            "NH"="N NE", "VT"="N NE", "ME"="N NE"
                                            ), 
                               var1="CTP_deaths", 
                               var2="USAF_deaths",
                               lagEarlyValue=NULL,
                               lagLateValue=NULL
                               )

```
  
The differences in data reporting between CTP and USA Facts stand out.  Lags are generally zero, though the spikes mean that each source has a different cumulative number of deaths.  The process can similarly be run for the Great Lakes states (excluding Pennsylvania and New York):  
```{r}

# Example for using the full stateData file
glakesList <- integrateStateData(stateData=fullStateList$stateData, 
                                 popData=fullStateList$popData,
                                 runAll=TRUE,
                                 keyStates=c("MN", "WI", "IL", "IN", "MI", "OH"),
                                 lagEarlyValue=NULL,
                                 lagLateValue=NULL
                                 )

```
  
Creating separate lags by state as well as separate CFR by month is important in the Great Lakes.  Michigan had a very large spike early when there was little case-death lag and a high CFR.  By contrast, Wisconsin had a large late spike when there was more meaningful case-death lag and a much lower CFR.  Indiana especially needs the variation by month as its early spike had ~6% CFR and its late spike had ~1% CFR.

Functions have been updated so that .groups="drop_last" in every summarize() call to avoid the note about dplyr default behavior.  Further, the lm() has been updated to na.action=na.exclude so that predict() will return NA for all rows with missing data (required for hospital data which has variable date of entry by state).

Suppose that the goal is to check how hospitalizations and deaths correlate:  
```{r}

# Example for using the full stateData file
glakesHospList <- integrateStateData(stateData=fullStateList$stateData, 
                                     popData=fullStateList$popData,
                                     runAll=TRUE,
                                     keyStates=c("MN", "WI", "IL", "IN", "MI", "OH"),
                                     var1="CTP_hosp",
                                     var2="CTP_deaths",
                                     lagEarlyValue=NULL,
                                     lagLateValue=NULL
                                     )

```
  
Even with total hospitalized being a state variable rather than a flow variable, it appears to be a better predicor of changes in deaths in the next week or so.  Specifically, even when using a common 7-day lag across all states and dates, application of a single multiplier in the 2%-3% range by state appears to drive reasonably good convergence of the curves.  It is a much more stable predictor over time than cases.

Suppose that the goal is to assess whether increases in CDC all-cause deaths link to increases in coronavirus deaths:  
```{r}

# Example for using the full stateData file
glakesCDC1List <- integrateStateData(stateData=fullStateList$stateData, 
                                     popData=fullStateList$popData,
                                     runAll=TRUE,
                                     keyStates=c("MN", "WI", "IL", "IN", "MI", "OH"),
                                     var1="CDC_excess",
                                     var2="CTP_deaths",
                                     lagEarlyValue=NULL,
                                     lagLateValue=NULL
                                     )

# Example for using the full stateData file
glakesCDC2List <- integrateStateData(stateData=fullStateList$stateData, 
                                     popData=fullStateList$popData,
                                     runAll=TRUE,
                                     keyStates=c("MN", "WI", "IL", "IN", "MI", "OH"),
                                     var1="CTP_deaths",
                                     var2="CDC_excess",
                                     lagEarlyValue=NULL,
                                     lagLateValue=NULL
                                     )

```
  
The link between CDC excess all-cause deaths and reported coronavirus deaths is less clear.  There appear to be roughly 30% more excess all-cause deaths than reported coronavirus deaths, and with the excess all-cause deaths sometimes leading the reported coronavirus deaths (possibly due to differences in how death date is tracked).  Further, Wisconsin did not have excess deaths until Fall, so the predictive nature of this metric is poor in Wisconsin.

Do increases in coronavirus cases predict increases in CDC all-cause deaths?  
```{r}

# Example for using the full stateData file
glakesCDC3List <- integrateStateData(stateData=fullStateList$stateData, 
                                     popData=fullStateList$popData,
                                     runAll=TRUE,
                                     keyStates=c("MN", "WI", "IL", "IN", "MI", "OH"),
                                     var1="CTP_cases",
                                     var2="CDC_excess",
                                     lagEarlyValue=NULL,
                                     lagLateValue=NULL
                                     )

```
  
Since excess deaths and coronavirus deaths are reasonably correlated, increases in cases help predict increases in excess all-cause deaths.  The rate of excess death per case decreases significantly with time.
  
#### _Full Update (mid-November)_  
The full process is updated with an additional two weeks of data:  
```{r cache=TRUE}

# Use existing segments with updated data
locDownload <- "./RInputFiles/Coronavirus/CV_downloaded_201120.csv"
test_old_201120 <- readRunCOVIDTrackingProject(thruLabel="Nov 19, 2020", 
                                               downloadTo=if (file.exists(locDownload)) NULL else locDownload,
                                               readFrom=locDownload, 
                                               compareFile=readFromRDS("test_hier5_201025")$dfRaw,
                                               useClusters=readFromRDS("test_hier5_201025")$useClusters
                                               )
saveToRDS(test_old_201120, ovrWriteError=FALSE)


```
  
```{r cache=TRUE}

# Locations for the population, case, and death file
popLoc <- "./RInputFiles/Coronavirus/covid_county_population_usafacts.csv"
caseLoc <- "./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20201120.csv"
deathLoc <- "./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20201120.csv"

# Run old segments against new data
cty_old_20201120 <- readRunUSAFacts(maxDate="2020-11-18", 
                                    popLoc=popLoc, 
                                    caseLoc=caseLoc, 
                                    deathLoc=deathLoc, 
                                    dlCaseDeath=!(file.exists(caseLoc) & file.exists(deathLoc)),
                                    oldFile=readFromRDS("cty_20201026")$dfBurden, 
                                    existingCountyClusters=readFromRDS("cty_20201026")$clustVec
                                    )
saveToRDS(cty_old_20201120, ovrWriteError=FALSE)

```
  
There appears to be a county-level anomaly for FIPS 22053 showing 18,544 cases diagnosed on 18-NOV in a county with population ~30,000 people.  The process should be updated to allow for excluding spurious data points.

```{r cache=TRUE}

# Use data that have previously been downloaded
cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20201120.csv"
cdcList_20201120 <- readRunCDCAllCause(loc=cdcLoc, 
                                       startYear=2015, 
                                       curYear=2020,
                                       weekThru=38, 
                                       startWeek=9, 
                                       lst=readFromRDS("test_old_201120"), 
                                       epiMap=readFromRDS("epiMonth"), 
                                       agePopData=readFromRDS("usPopBucket2020"), 
                                       cvDeathThru="2020-09-19", 
                                       cdcPlotStartWeek=10, 
                                       dlData=!file.exists(paste0("./RInputFiles/Coronavirus/", cdcLoc)), 
                                       stateNoCheck=c("NC")
                                       )

saveToRDS(cdcList_20201120, ovrWriteError=FALSE)

```

```{r}

# Example for creating a full stateData file
fullStateList_20201120 <- integrateStateData(ctpList=readFromRDS("test_old_201120"), 
                                             usafData=readFromRDS("cty_old_20201120")$clusterStateData, 
                                             cdcList=readFromRDS("cdcList_20201120")
                                             )
fullStateList_20201120

# Example for using the full stateData file
glakesList_20201120 <- integrateStateData(stateData=fullStateList_20201120$stateData, 
                                          popData=fullStateList_20201120$popData,
                                          runAll=TRUE,
                                          keyStates=c("MN", "WI", "IL", "IN", "MI", "OH"),
                                          lagEarlyValue=NULL,
                                          lagLateValue=NULL
                                          )

```
  
Data can be run on some of the states currently experiencing heavy outbreaks, with NY, MI, AZ as reference states that previously had high spikes:  
```{r}

# Example for using the full stateData file
plainsList_20201120 <- integrateStateData(stateData=fullStateList_20201120$stateData, 
                                          popData=fullStateList_20201120$popData,
                                          runAll=TRUE,
                                          keyStates=c("MN", "ND", "SD", "MT", "NE", 
                                                      "KS", "IA", "MI", "NY", "AZ"
                                                      ),
                                          combStates=c("ND"="Dakotas", "SD"="Dakotas"),
                                          lagEarlyValue=NULL,
                                          lagLateValue=NULL
                                          )

# Example for using hospitalizations
plainsListHosp_20201120 <- integrateStateData(stateData=fullStateList_20201120$stateData, 
                                              popData=fullStateList_20201120$popData,
                                              runAll=TRUE,
                                              var1="CTP_hosp",
                                              keyStates=c("MN", "ND", "SD", "MT", "NE", 
                                                          "IA", "MI", "NY", "AZ"
                                                          ),
                                              combStates=c("ND"="Dakotas", "SD"="Dakotas"),
                                              lagEarlyValue=NULL,
                                              lagLateValue=NULL
                                              )

```
  
Two issues should be addressed, both related to x-variable and lag:  
  
1.  Small data samples lead to unreasonable coefficients for y ~ x regression in early months  
2.  Lack of data availability can crash the correlations process since there are no data points to correlate (occurs with hospitals in Kansas)  
  
The assessStateCFR() function is updated to use a ceiling value as the plotted estimate any time an estimate exceeds the ceiling, and to set a lag of 0 if there is insufficient data for running correlations:  
```{r}

# Updated for automatic lag time assessment
assessStateCFR <- function(lst, 
                           keyStates, 
                           depVar, 
                           indepVar,
                           depTitleName, 
                           indepTitleName,
                           keyMetric="vpm7", 
                           lagEarlyDate=as.Date("2020-03-31"), 
                           lagMidDate=NULL,
                           lagLateDate=as.Date("2020-10-15"), 
                           lagEarlyValue=10, 
                           lagLateValue=20, 
                           lagsTry=0:30, 
                           maxCFR=0.2
                           ) {
    
    # FUNCTION ARGUMENTS:
    # lst: A list such as produced by createAndAlignCurves()
    # keyStates: The key states to be extracted from the list
    # depVar: the dependent variable
    # indepVar: the independent variable
    # depTitleName: the name for the dependent variable in the title
    # indepTitleName: the name for the independent variable in the plot title
    # keyMetric: the name of the key metric that is being assessed
    # lagEarlyDate: the date for the earliest lagging calculation (dates before this will be at lagEarlyValue)
    # lagMidDate: if lags are found from data, what midpoint should be used to split data as early vs late?
    #             NULL means midway between lagEarlyDate and lagLateDate
    # lagLateDate: the date for the latest lagging calculation (dates after this will be at lagLateValue)
    # lagEarlyValue: the value for lag on lagEarlyDate, will be linearly interpolated to lagLateValue/Date
    #                NULL means calculate from data and may differ by state
    # lagLateValue: the value for lag on lagLateDate, will be linearly interpolated from lagEarlyValue/Date
    #               NULL means estimate from data and may differ by state
    # lagsTry: the values for lag to be attempted if lageEarlyValue and/or lagLateValue is NULL
    # maxCFR: the maximum CFR to use (anything above will be scaled back to this ceiling value)
    
    # Extract the data for keyStates
    df <- lst[["dfList"]] %>%
        select_at(vars(all_of(c("state", "date", "name", keyMetric)))) %>%
        filter(state %in% keyStates, !is.na(get(keyMetric))) %>%
        pivot_wider(names_from="name", values_from=keyMetric)

    # Function for finding lag time correlations
    helperLagCor <- function(lt, lf, dp, id) {
        allStates <- lf %>%
            count(state) %>%
            select(-n)
        lf %>%
            group_by(state) %>%
            mutate(y=get(dp), x=lag(get(id), lt)) %>%
            filter(!is.na(y), !is.na(x)) %>%
            summarize(p=cor(x, y, use="complete.obs"), .groups="drop_last") %>%
            ungroup() %>%
            right_join(allStates, by="state") %>%
            mutate(lag=ifelse(is.na(lt), 0, lt))
    }
    
    # Middle date for splitting data
    if (is.null(lagMidDate)) lagMidDate <- mean(c(lagEarlyDate, lagLateDate))
    
    # Get the early lags from the data
    eLag <- map_dfr(.x=lagsTry, .f=helperLagCor, lf=filter(df, date<=lagMidDate), dp=depVar, id=indepVar) %>%
        group_by(state) %>%
        filter(p==max(p)) %>%
        filter(row_number()==1) %>%
        ungroup() %>%
        select(state, earlyLag=lag)
    
    # Get the late lags from the data
    lLag <- map_dfr(.x=lagsTry, .f=helperLagCor, lf=filter(df, date>lagMidDate), dp=depVar, id=indepVar) %>%
        group_by(state) %>%
        filter(p==max(p)) %>%
        filter(row_number()==1) %>%
        ungroup() %>%
        select(state, lateLag=lag)
    
    # Create the full lag frame, including substituting the fixed value(s) if provided
    lagFrame <- eLag %>%
        full_join(lLag, by="state") %>%
        mutate(earlyLag=ifelse(is.na(earlyLag), 0, earlyLag), lateLag=ifelse(is.na(lateLag), 0, lateLag))
    if (!is.null(lagEarlyValue)) lagFrame <- lagFrame %>% mutate(earlyLag=lagEarlyValue)
    if (!is.null(lagLateValue)) lagFrame <- lagFrame %>% mutate(lateLag=lagLateValue)
    print(lagFrame)
    
    # Apply the assumed lagging information
    fullTime <- as.integer(lagLateDate-lagEarlyDate)
    df <- df %>%
        left_join(lagFrame, by="state") %>%
        arrange(state, date) %>%
        group_by(state) %>%
        mutate(eLag=lag(get(indepVar), mean(earlyLag)), 
               lLag=lag(get(indepVar), mean(lateLag)), 
               pctEarly=pmin(pmax(as.integer(lagLateDate-date)/fullTime, 0), 1), 
               x=ifelse(is.na(eLag), NA, pctEarly*eLag + (1-pctEarly)*ifelse(is.na(lLag), 0, lLag)), 
               y=get(depVar),
               mon=factor(month.abb[lubridate::month(date)], levels=month.abb)
               ) %>%
        filter(!is.na(x)) %>%
        ungroup()
    
    # Regression for data from keyStates
    if (length(keyStates) > 1) stateLM <- lm(y ~ x:mon:state + 0, data=df, na.action=na.exclude) 
    else stateLM <- lm(y ~ x:mon + 0, data=df, na.action=na.exclude)
    
    # Add the predicted value to df
    df <- df %>%
        mutate(pred=predict(stateLM))
    
    # Plot of curve overlaps
    p1 <- df %>%
        select(state, date, y, pred) %>%
        pivot_longer(-c(state, date)) %>%
        ggplot(aes(x=date, y=value)) + 
        geom_line(aes(color=c("pred"="Predicted", "y"="Actual")[name], group=name)) + 
        scale_x_date(date_breaks="1 month", date_labels="%b") + 
        labs(x="", 
             y=stringr::str_to_title(depTitleName), 
             title=paste0("Predicted vs. actual ", depTitleName)
             ) +
        scale_color_discrete("Metric") +
        facet_wrap(~state)
    print(p1)
    
    # Plot of rate by month
    p2 <- coef(stateLM) %>%
        as.data.frame() %>%
        purrr::set_names("CFR") %>%
        filter(!is.na(CFR)) %>%
        tibble::rownames_to_column("monState") %>%
        mutate(mon=factor(stringr::str_replace_all(monState, pattern="x:mon|:state.+", replacement=""), 
                          levels=month.abb
                          ), 
               state=if (length(keyStates)==1) keyStates 
                     else stringr::str_replace_all(monState, pattern="x:mon[A-Za-z]{3}:state", replacement=""), 
               colorUse=ifelse(CFR>maxCFR, "red", "lightblue"), 
               CFR=pmin(CFR, maxCFR)
               ) %>%
        left_join(lagFrame, by="state") %>%
        ggplot(aes(x=mon, y=CFR)) + 
        geom_col(aes(fill=colorUse)) + 
        geom_text(aes(y=CFR/2, label=paste0(round(100*CFR, 1), "%"))) +
        geom_text(data=~filter(., mon==month.abb[lubridate::month(lagMidDate)]), 
                  aes(x=-Inf, y=Inf, label=paste0("Early Lag: ", earlyLag)), 
                  hjust=0, 
                  vjust=1
                  ) + 
        geom_text(data=~filter(., mon==month.abb[lubridate::month(lagMidDate)]), 
                  aes(x=Inf, y=Inf, label=paste0("Late Lag: ", lateLag)), 
                  hjust=1, 
                  vjust=1
                  ) + 
        labs(x="", 
             y=paste0(stringr::str_to_title(depTitleName), " as percentage of lagged ", indepTitleName), 
             title=paste0(stringr::str_to_title(depTitleName), 
                          " vs. lagged ", 
                          indepTitleName, 
                          " in state(s): ", 
                          paste0(keyStates, collapse=", ")
                          ), 
             subtitle=paste0("Assumed early lag on ", 
                             lagEarlyDate,
                             " interpolated to late lag on ", 
                             lagLateDate, 
                             "\nValues above ", 
                             maxCFR, 
                             " reported as ", 
                             maxCFR, 
                             " and flagged in red"
                             ), 
             caption="Linear model coefficients on lagged data with no intercept used to estimate percentage"
             ) + 
        scale_fill_identity() +
        facet_wrap(~state)
    print(p2)

    # Return the data frame
    df
    
}


```

The updated function is then run:  
```{r}

# Example for using the full stateData file
plainsList_20201120 <- integrateStateData(stateData=fullStateList_20201120$stateData, 
                                          popData=fullStateList_20201120$popData,
                                          runAll=TRUE,
                                          keyStates=c("MN", "ND", "SD", "MT", "NE", 
                                                      "KS", "IA", "MI", "NY", "FL"
                                                      ),
                                          combStates=c("ND"="Dakotas", "SD"="Dakotas"),
                                          lagEarlyValue=NULL,
                                          lagLateValue=NULL
                                          )

# Example for using hospitalizations
plainsListHosp_20201120 <- integrateStateData(stateData=fullStateList_20201120$stateData, 
                                              popData=fullStateList_20201120$popData,
                                              runAll=TRUE,
                                              var1="CTP_hosp",
                                              keyStates=c("MN", "ND", "SD", "MT", "NE", 
                                                          "IA", "MI", "NY", "FL"
                                                          ),
                                              combStates=c("ND"="Dakotas", "SD"="Dakotas"),
                                              lagEarlyValue=NULL,
                                              lagLateValue=NULL
                                              )

```
  
The issues appear to be addressed, with the function now running as expected.

The process can be run using the state clusters:  
```{r}

# Get the cluster file
clustData <- readFromRDS("test_hier5_201025")$useClusters
clustStates <- names(clustData)
clustData <- paste0("Cluster ", clustData)
names(clustData) <- clustStates

# Example for using the full stateData file
clustList_20201120 <- integrateStateData(stateData=fullStateList_20201120$stateData, 
                                         popData=fullStateList_20201120$popData,
                                         runAll=TRUE,
                                         keyStates=clustStates,
                                         combStates=clustData,
                                         lagEarlyValue=NULL,
                                         lagLateValue=NULL
                                         )

# Example for using hospitalizations
clustListHosp_20201120 <- integrateStateData(stateData=fullStateList_20201120$stateData, 
                                             popData=fullStateList_20201120$popData,
                                             runAll=TRUE,
                                             var1="CTP_hosp",
                                             keyStates=clustStates,
                                             combStates=clustData,
                                             lagEarlyValue=NULL,
                                             lagLateValue=NULL
                                             )

```

A function is written to run the component states for a given cluster:  
```{r}

# Function to run the process for all states in specified cluster
regionComponents <- function(lst, 
                             clustVec,
                             clustNum,
                             combStates=vector("character", 0), 
                             lagEarlyValue=NULL,
                             lagLateValue=NULL,
                             returnData=FALSE,
                             ...
                             ) 
    {
    
    # FUNCTION ARGUMENTS:
    # lst: a processed list containing burden data and population data
    # clustVec: a named vector containing the assignment for each state
    # clustNum: cluster number to use OR a specific state to key on (that state's cluster will be used)
    # combStates: states that should be combined together for plotting (named vector, c("state"="newName"))
    # lagEarlyValue: can force an early lag by using an integer (NULL means estimate from data)
    # lagLateValue: can force an early lag by using an integer (NULL means estimate from data)
    # returnData: whether to return the data files produced
    # ...: other arguments to pass to integrateStateData()
    
    # Get the states to run from clustVec
    # If an integer, pull the states directly; if a character, pull states matching the state name passed
    if ("numeric" %in% class(clustNum) | "integer" %in% class(clustNum)) {
        keyStates <- names(clustVec)[clustVec %in% clustNum]
    } else if ("character" %in% class(clustNum)) {
        clustUse <- unique(clustVec[names(clustVec) %in% clustNum])
        keyStates <- names(clustVec)[clustVec %in% clustUse]
    } else {
        stop("\nCannot determine the desired states to plot, investigate and re-run\n")
    }
    
    # Run for cases vs. deaths
    caseDeathList <- integrateStateData(stateData=lst$stateData, 
                                        popData=lst$popData,
                                        runAll=TRUE,
                                        keyStates=keyStates,
                                        combStates=combStates,
                                        lagEarlyValue=lagEarlyValue,
                                        lagLateValue=lagLateValue, 
                                        ...
                                        )
    
    # Run for hospitalized vs. deaths
    hospDeathList <- integrateStateData(stateData=lst$stateData, 
                                        popData=lst$popData,
                                        runAll=TRUE,
                                        var1="CTP_hosp",
                                        keyStates=keyStates,
                                        combStates=combStates,
                                        lagEarlyValue=lagEarlyValue,
                                        lagLateValue=lagLateValue, 
                                        ...
                                        )
    
    # Return data if requested
    if (returnData) list(caseDeathList=caseDeathList, hospDeathList=hospDeathList)
    
}

```
  
The function is then run for the NY/NJ cluster:  
```{r}

regionComponents(fullStateList_20201120, 
                 clustVec=readFromRDS("test_hier5_201025")$useClusters, 
                 clustNum=c("NY", "NJ")
                 )

```

The function is then run for the southern cluster:  
```{r}

regionComponents(fullStateList_20201120, 
                 clustVec=readFromRDS("test_hier5_201025")$useClusters, 
                 clustNum=c("FL", "AZ")
                 )

```

The function is then run for the other early northern cluster:  
```{r}

regionComponents(fullStateList_20201120, 
                 clustVec=readFromRDS("test_hier5_201025")$useClusters, 
                 clustNum=c("MI")
                 )

```

The function is then run for the states impacted later:  
```{r}

regionComponents(fullStateList_20201120, 
                 clustVec=readFromRDS("test_hier5_201025")$useClusters, 
                 clustNum=c("ND")
                 )

```
  
This segment should likely be split further, both due to size and to meaningful differences by state in disease spike in November.

The function is then run for the handful of outlier states:  
```{r}

regionComponents(fullStateList_20201120, 
                 clustVec=readFromRDS("test_hier5_201025")$useClusters, 
                 clustNum=c("CO")
                 )

```
  
Data are also produced to show the early outlier region and low outlier region together:  
```{r}

regionComponents(fullStateList_20201120, 
                 clustVec=readFromRDS("test_hier5_201025")$useClusters, 
                 clustNum=c("CO", "NY")
                 )

```

#### _Full Update (new segments, late November)_  
New data from COVID Tracking Project are downloaded, and new state-level segments are created using similar business rules as previous:  
```{r cache=TRUE}

# Use existing segments with updated data
locDownload <- "./RInputFiles/Coronavirus/CV_downloaded_201130.csv"
test_hier5_201130 <- readRunCOVIDTrackingProject(thruLabel="Nov 29, 2020", 
                                                 downloadTo=if(file.exists(locDownload)) NULL else locDownload,
                                                 readFrom=locDownload, 
                                                 compareFile=readFromRDS("test_hier5_201025")$dfRaw,
                                                 hierarchical=TRUE, 
                                                 reAssignState=list("VT"="ME"), 
                                                 kCut=6, 
                                                 minShape=3, 
                                                 ratioDeathvsCase = 5, 
                                                 ratioTotalvsShape = 0.25, 
                                                 minDeath=100, 
                                                 minCase=10000
                                                 )
saveToRDS(test_hier5_201130, ovrWriteError=FALSE)


```
  
The state-level segments are compared for general overlap:  
```{r}

stateSegmentChange <- tibble::tibble(state=names(test_hier5_201130$useClusters), 
                                     newSegment=unname(test_hier5_201130$useClusters), 
                                     oldSegment=unname(test_old_201108$useClusters), 
                                     ckState=names(test_old_201108$useClusters)
                                     )

stateSegmentChange %>%
    summarize(wrongState=sum(state != ckState))

stateSegmentChange %>%
    count(oldSegment, newSegment) %>%
    ggplot(aes(x=fct_reorder(factor(oldSegment), n, .fun=sum), 
               y=fct_reorder(factor(newSegment), n, .fun=sum)
               )
           ) + 
    geom_tile(aes(fill=n)) + 
    geom_text(aes(label=n)) + 
    coord_flip() + 
    scale_fill_continuous("# States", low="white", high="green", limits=c(0, NA)) + 
    labs(title="State segment movement", x="Original Segment", y="New Segment")

```

With the segments able to incorporate the October-November spike, there is significant splitting of segments based on the degree to which they are impacted by the more recent increases.

Further, plots are made for the disease evolution by state for each of the segment overlaps:  
```{r}

stateSegChangePlotData <- test_hier5_201130$consolidatedPlotData %>%
    ungroup() %>%
    select(state, date, name, pop, vpm7) %>%
    filter(!is.na(vpm7)) %>%
    inner_join(select(stateSegmentChange, state, newSegment, oldSegment), by=c("state")) %>%
    bind_rows(mutate(., state="TOTAL")) %>%
    group_by(state, date, name, newSegment, oldSegment) %>%
    summarize(vpm7=sum(vpm7*pop)/sum(pop), pop=sum(pop), .groups="drop")

newSegLevels <- stateSegChangePlotData %>% count(newSegment) %>% arrange(n) %>% pull(newSegment)
oldSegLevels <- stateSegChangePlotData %>% count(oldSegment) %>% arrange(-n) %>% pull(oldSegment)

for (keyVar in c("deaths", "cases", "hosp")) {
    p1 <- stateSegChangePlotData %>%
        mutate(newSegment=factor(newSegment, levels=newSegLevels), 
               oldSegment=factor(oldSegment, levels=oldSegLevels)
               ) %>%
        filter(name==keyVar) %>%
        ggplot(aes(x=date, y=vpm7)) + 
        geom_line(data=~filter(., state != "TOTAL"), aes(group=state), color="grey") +
        geom_line(data=~filter(., state == "TOTAL"), aes(group=1, color=newSegment)) + 
        facet_grid(oldSegment ~ newSegment) + 
        scale_x_date(date_breaks="1 months", date_labels="%b") + 
        scale_color_discrete("New\nSegment") +
        theme(axis.text.x = element_text(angle = 90)) +
        labs(x="", 
             y="Per million (7-day rolling mean)", 
             title=paste0(stringr::str_to_title(keyVar), " per million per day by segment overlap")
             )
    print(p1)
}

```

New data from USA Facts are downloaded and new county-level segments are created using similar business rules as previous:  
```{r cache=TRUE}

# Locations for the population, case, and death file
popLoc <- "./RInputFiles/Coronavirus/covid_county_population_usafacts.csv"
caseLoc <- "./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20201203.csv"
deathLoc <- "./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20201203.csv"

# Run old segments against new data
cty_new_20201203 <- readRunUSAFacts(maxDate="2020-12-02", 
                                    popLoc=popLoc, 
                                    caseLoc=caseLoc, 
                                    deathLoc=deathLoc, 
                                    dlCaseDeath=!(file.exists(caseLoc) & file.exists(deathLoc)),
                                    oldFile=readFromRDS("cty_20201026")$dfBurden, 
                                    existingStateClusters=test_hier5_201130$useClusters,
                                    createClusters=TRUE,
                                    hierarchical=NA,
                                    minShape=4,
                                    maxShape=11,
                                    ratioDeathvsCase=5,
                                    ratioTotalvsShape=0.25,
                                    minDeath=100,
                                    minCase=5000,
                                    hmlSegs=3,
                                    eslSegs=3,
                                    seed=2012040236, 
                                    orderCluster="dpm"
                                    )
saveToRDS(cty_new_20201203, ovrWriteError=FALSE)

```
  
The overlap of county segments is calculated and plotted:  
```{r}

oldCountySegment <- cty_old_20201120$helperACC_county %>%
    select(state, oldSegment=cluster) %>%
    unique()
countySegmentChange <- cty_new_20201203$helperACC_county %>%
    select(state, newSegment=cluster) %>%
    unique() %>%
    full_join(oldCountySegment, by="state") %>%
    mutate(state=stringr::str_pad(state, width=5, side="left", pad="0"))
countySegmentChange %>%is.na() %>% colSums()

countySegmentChange %>%
    count(oldSegment, newSegment) %>%
    ggplot(aes(x=fct_reorder(factor(oldSegment), n, .fun=sum), 
               y=fct_reorder(factor(newSegment), n, .fun=sum)
               )
           ) + 
    geom_tile(aes(fill=n)) + 
    geom_text(aes(label=n)) + 
    coord_flip() + 
    scale_fill_continuous("# Counties", low="white", high="green", limits=c(0, NA)) + 
    labs(title="County segment movement", x="Original Segment", y="New Segment")

fisher.test(select(countySegmentChange, oldSegment, newSegment) %>% table(), simulate.p.value=TRUE)
chisq.test(select(countySegmentChange, oldSegment, newSegment) %>% table())
```
  
There is meaningful overlap between old county segment and new county segment.  Plots of disease burden by county segment overlap are also created:  
```{r}

countySegChangePlotData <- cty_new_20201203$clusterStateData %>%
    ungroup() %>%
    select(fipsCounty, date, countyName, state, pop, cpm7, dpm7) %>%
    filter(!is.na(cpm7), !is.na(dpm7)) %>%
    inner_join(select(countySegmentChange, fipsCounty=state, newSegment, oldSegment), by=c("fipsCounty")) %>%
    bind_rows(mutate(., fipsCounty="TOTAL", state="TOTAL", countyName="TOTAL")) %>%
    group_by(fipsCounty, date, countyName, state, newSegment, oldSegment) %>%
    summarize(cpm7=sum(cpm7*pop)/sum(pop), dpm7=sum(dpm7*pop)/sum(pop), pop=sum(pop), .groups="drop")

newSegLevels <- countySegChangePlotData %>% count(newSegment) %>% arrange(n) %>% pull(newSegment)
oldSegLevels <- countySegChangePlotData %>% count(oldSegment) %>% arrange(-n) %>% pull(oldSegment)

for (keyVar in c("cpm7", "dpm7")) {
    p1 <- countySegChangePlotData %>%
        mutate(newSegment=factor(newSegment, levels=newSegLevels), 
               oldSegment=factor(oldSegment, levels=oldSegLevels)
               ) %>%
        ggplot(aes(x=date, y=get(keyVar))) + 
        # geom_line(data=~filter(., state != "TOTAL"), aes(group=fipsCounty), color="grey") +
        geom_line(data=~filter(., state == "TOTAL"), aes(group=1, color=newSegment)) + 
        facet_grid(oldSegment ~ newSegment) + 
        scale_x_date(date_breaks="1 months", date_labels="%b") + 
        scale_color_discrete("New\nSegment") +
        theme(axis.text.x = element_text(angle = 90)) +
        labs(x="", 
             y="Per million (7-day rolling mean)", 
             title=paste0(stringr::str_to_title(keyVar), " per million per day by segment overlap")
             )
    print(p1)
}

```

Further, updated CDC data are downloaded:  
```{r cache=TRUE}

# Download new data
cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20201206.csv"
cdcList_20201206 <- readRunCDCAllCause(loc=cdcLoc, 
                                       startYear=2015, 
                                       curYear=2020,
                                       weekThru=39, 
                                       startWeek=9, 
                                       lst=test_hier5_201130, 
                                       epiMap=readFromRDS("epiMonth"), 
                                       agePopData=readFromRDS("usPopBucket2020"), 
                                       cvDeathThru="2020-09-26", 
                                       cdcPlotStartWeek=10, 
                                       dlData=!file.exists(paste0("./RInputFiles/Coronavirus/", cdcLoc)), 
                                       stateNoCheck=c("NC")
                                       )

saveToRDS(cdcList_20201206, ovrWriteError=FALSE)

```

A function is written to compare CDC deaths for the same time period in two different files:  
```{r}

cdcDeathCompare <- function(loc1, 
                            loc2, 
                            dir="./RInputFiles/Coronavirus/", 
                            periodKeep="2015-2019", 
                            weekThru=53, 
                            stateNoCheck=c(state.abb, "DC"), 
                            threshPct=0.0005, 
                            returnList=FALSE
                            ) {
    
    # FUNCTION ARGUMENTS:
    # loc1: the first raw CDC file (either character location of CSV or data frame)
    # loc2: the second raw CDC file (either character location of CSV or data frame)
    # dir: the directory containing the raw CDC files
    # periodKeep: keep all data from this time period
    # weekThru: keep all data that is from this week or earlier, even if not in periodKeep
    # stateNoCheck: do not run error checks for these states (all in this case)
    # threshPct: threshold for plotting as a difference
    # returnList: boolean, whether to return a list including both CDC file and the final difference file
    #             if FALSE (default), only the difference file is returned, and it is returned as tibble
    
    # Function to read raw CDC data
    readRawCDC <- function(x) {
        readProcessCDC(x, weekThru=weekThru, periodKeep=periodKeep, fDir=dir, stateNoCheck=stateNoCheck) %>%
            group_by(weekEnding) %>%
            summarize(deaths=sum(deaths, na.rm=TRUE), .groups="drop")
    }
    
    # Read the data if character, otherwise keep "as is"
    if ("character" %in% class(loc1)) cdc1 <- readRawCDC(loc1)
    else cdc1 <- loc1
    if ("character" %in% class(loc2)) cdc2 <- readRawCDC(loc2)
    else cdc2 <- loc2
    
    # Merge the files
    cdc <- select(cdc1, weekEnding, deaths1=deaths) %>%
        full_join(select(cdc2, weekEnding, deaths2=deaths), by="weekEnding")
    
    # Mapping file
    if ("character" %in% class(loc1)) name1 <- stringr::str_extract(loc1, pattern="\\d{8}")
    else name1 <- loc1 %>% pull(weekEnding) %>% max() %>% as.character() %>% stringr::str_replace_all("-", "")
    if ("character" %in% class(loc2)) name2 <- stringr::str_extract(loc2, pattern="\\d{8}")
    else name2 <- loc2 %>% pull(weekEnding) %>% max() %>% as.character() %>% stringr::str_replace_all("-", "")
    mapFile <- c(name1, name2)
    names(mapFile) <- c("deaths1", "deaths2")
    
    
    # Plot differences
    p1 <- cdc %>%
        pivot_longer(-weekEnding) %>%
        mutate(name=mapFile[name]) %>%
        ggplot(aes(x=weekEnding, y=value)) +
        geom_line(aes(group=name, color=name)) + 
        labs(x="", 
             y="Total deaths", 
             title="Change in total deaths (predicted) reported in CDC data by time period"
             ) + 
        scale_color_discrete("CDC Time Period") + 
        ylim(0, NA)
    print(p1)
    
    # Extract any weeks with change greater than threshPct
    p2 <- cdc %>%
        filter(!is.na(deaths1), !is.na(deaths2)) %>%
        mutate(delta=deaths2-deaths1) %>%
        filter(abs(delta) >= threshPct*pmax(deaths1, deaths2)) %>%
        ggplot(aes(x=weekEnding, y=delta)) + 
        geom_col(aes(fill=delta>0)) + 
        geom_text(aes(y=delta+100, label=delta), hjust=0) +
        labs(x="", 
             y="Delta between files (positive means more in second file)", 
             title="Change in CDC reported deaths by week", 
             subtitle=paste0("Includes only weeks with change at least ", round(threshPct*100, 3), "%\n", 
                             "Dates: ", name1," and ", name2
                             )
             ) + 
        coord_flip() + 
        scale_fill_discrete("Positive Delta")
    print(p2)
    
    # Return the CDC data
    if (returnList) list(cdc=cdc, cdc1=cdc1, cdc2=cdc2)
    else cdc
    
}

loc1 <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20200923.csv"
loc2 <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20201206.csv"

cdcCompare_0923_1206 <- cdcDeathCompare(loc1=loc1, loc2=loc2, returnList=TRUE)
str(cdcCompare_0923_1206)

```

There is eventual modest restatement of CDC data in most weeks, and more significant restatement of CDC data in the four most recent weeks of the September 23, 2020 data file (last week available week ending September 5, last mostly non-restated data week ending August 8).

The function is updated to return either a list (includes each CDC data file) or just the differences file.

The function is run again for two different time periods:  
```{r}

loc3 <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20201014.csv"
loc4 <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20201120.csv"

cdcCompare_1014_1120 <- cdcDeathCompare(loc1=loc3, loc2=loc4, returnList=TRUE)
str(cdcCompare_1014_1120)

```
  
A similar pattern is seen, with larger restatements in the more recent months of the older data file.

The function is updated to allow for taking a data frame or character path to a CSV.  Direct use of the file is for example:  
```{r}

cdcCompare_1014_1206 <- cdcDeathCompare(loc1=cdcCompare_1014_1120$cdc1, 
                                        loc2=cdcCompare_0923_1206$cdc2, 
                                        returnList=FALSE
                                        )
str(cdcCompare_1014_1206)

```

Data are integrated from across four files:  
```{r}

cdcFourFiles <- cdcCompare_0923_1206$cdc %>%
    rename('20200923'=deaths1, '20201206'=deaths2) %>%
    full_join(rename(cdcCompare_1014_1120$cdc, '20201014'=deaths1, '20201120'=deaths2)) %>%
    pivot_longer(-weekEnding, names_to="source", values_to="reportedDeaths") %>%
    mutate(source=lubridate::ymd(source)) %>%
    arrange(weekEnding, source)
cdcFourFiles

# Function to plot restatement levels for a file
plotCDCRestatement <- function(df, 
                               keyVar="reportedDeaths", 
                               keyYears=c(2020), 
                               firstWeek=NULL
                               ) {
    
    # FUNCTION ARGUMENTS
    # df: a frame containing weekEnding-source-reportedDeaths
    # keyVar: character string, defaults to "reportedDeaths"
    # keyYears: years to be included
    # firstWeek: character vector for description of first week (NULL means calculate from data)
    
    dfNoNA <- df %>%
        rename("numKey"=all_of(keyVar)) %>%
        group_by(weekEnding) %>%
        summarize(numNA=sum(is.na(numKey)), .groups="drop") %>%
        filter(numNA==0) %>%
        select(weekEnding) %>%
        inner_join(df, by="weekEnding") %>%
        rename("numKey"=keyVar)
    
    if (is.null(firstWeek)) firstWeek <- dfNoNA %>% pull(source) %>% min() %>% as.character()
    
    dfRatio <- dfNoNA %>%
        arrange(weekEnding, source) %>%
        group_by(weekEnding) %>%
        mutate(firstNum=first(numKey), pctFirst=numKey/firstNum) %>%
        ungroup()
    
    p1 <- dfRatio %>%
        filter(lubridate::year(weekEnding) %in% keyYears) %>%
        ggplot(aes(x=weekEnding, y=pctFirst)) + 
        geom_line(aes(group=source, color=factor(source))) + 
        labs(x="Data reported for week", 
             y=paste0("Ratio vs. reported in ", firstWeek, " file"), 
             title="Ratio of CDC all-cause deaths reported by week", 
             subtitle=paste0("Compared to number by week reported in ", firstWeek, " file")
             ) + 
        scale_color_discrete("Download Date")
    print(p1)
    
    p2 <- dfRatio %>%
        filter(lubridate::year(weekEnding) %in% keyYears) %>%
        mutate(weeksPrior=as.integer(max(weekEnding)-weekEnding)/7) %>%
        group_by(weekEnding) %>%
        filter(row_number()==n()) %>%
        ggplot(aes(x=weeksPrior, y=pctFirst)) + 
        geom_text(aes(label=paste0(round(100*pctFirst), "%")), size=3) + 
        labs(x=paste0("Weeks prior to latest week reported in ", firstWeek, " file"), 
             y=paste0("Ratio vs. reported in ", firstWeek, " file"), 
             title="Ratio of CDC all-cause deaths reported by week", 
             subtitle=paste0("Compared to number by week reported in ", firstWeek, " file")
             )
    print(p2)
    
}

plotCDCRestatement(cdcFourFiles)

```
  
It appears that projected deaths in the 23-SEP-2020 file were mostly finalized prior to the most recent four weeks.  Inflation factors of ~125%, ~110%, ~105%, and ~105% would have been needed for the current week and the three preceding weeks to match the 'final' totals for those weeks as reported in the 2020-DEC-06 file.

The plotting routine has been converted to functional form and re-run.  A comparison of percentages is then made using the data from 2020-10-14 as the baseline:  
```{r}

cdcFourFiles %>%
    filter(source >= as.Date("2020-10-14")) %>%
    plotCDCRestatement()

```
  
And the process is repeated, but excluding the 2020-12-06 file:  
```{r}

cdcFourFiles %>%
    filter(source < as.Date("2020-12-06")) %>%
    plotCDCRestatement()

```
  
There is some directional evidence that the extra lag may be less in the 2020-10-14 file than in the 2020-09-23 file.  Further exploration of this topic could be interesting.

The latest CDC all-cause death data are downloaded:  
```{r cache=TRUE}

# Download new data
cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20201213.csv"
cdcList_20201213 <- readRunCDCAllCause(loc=cdcLoc, 
                                       startYear=2015, 
                                       curYear=2020,
                                       weekThru=40, 
                                       startWeek=9, 
                                       lst=test_hier5_201130, 
                                       epiMap=readFromRDS("epiMonth"), 
                                       agePopData=readFromRDS("usPopBucket2020"), 
                                       cvDeathThru="2020-10-03", 
                                       cdcPlotStartWeek=10, 
                                       dlData=!file.exists(paste0("./RInputFiles/Coronavirus/", cdcLoc)), 
                                       stateNoCheck=c("NC")
                                       )

saveToRDS(cdcList_20201213, ovrWriteError=FALSE)

```

New state-level data are downloaded, with existing segments used:  
```{r cache=TRUE}

# Use existing segments with updated data
locDownload <- "./RInputFiles/Coronavirus/CV_downloaded_201214.csv"
old_hier5_201214 <- readRunCOVIDTrackingProject(thruLabel="Dec 13, 2020", 
                                                downloadTo=if(file.exists(locDownload)) NULL else locDownload,
                                                readFrom=locDownload, 
                                                compareFile=readFromRDS("test_hier5_201025")$dfRaw,
                                                useClusters=readFromRDS("test_hier5_201130")$useClusters
                                                )
saveToRDS(old_hier5_201214, ovrWriteError=FALSE)

```

New county-level data are downloaded, with existing segments used:  
```{r cache=TRUE}

# Locations for the population, case, and death file
popLoc <- "./RInputFiles/Coronavirus/covid_county_population_usafacts.csv"
caseLoc <- "./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20201215.csv"
deathLoc <- "./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20201215.csv"

# Run old segments against new data
cty_old_20201215 <- readRunUSAFacts(maxDate="2020-12-13", 
                                    popLoc=popLoc, 
                                    caseLoc=caseLoc, 
                                    deathLoc=deathLoc, 
                                    dlCaseDeath=!(file.exists(caseLoc) & file.exists(deathLoc)),
                                    oldFile=readFromRDS("cty_20201026")$dfBurden, 
                                    existingCountyClusters=readFromRDS("cty_new_20201203")$clustVec
                                    )
saveToRDS(cty_old_20201215, ovrWriteError=FALSE)

```

Comparisons are made between the state-level totals as reflected in COVID Tracking Project and USA Facts:  
```{r}

usaFacts <- cty_old_20201215$clusterStateData %>% 
    filter(date <= as.Date("2020-12-10")) %>% 
    group_by(state) %>%
    summarize(cases=sum(cases, na.rm=TRUE), deaths=sum(deaths), .groups="drop")

ctp <- old_hier5_201214$plotData %>% 
    filter(date <= as.Date("2020-12-10")) %>% 
    group_by(state) %>% 
    summarize(cases=sum(cases), deaths=sum(deaths), .groups="drop")

usaCTP <- usaFacts %>%
    bind_rows(ctp, .id="source") %>%
    mutate(source=c('1'="USA Facts", '2'="COVID Tracking Project")[source]) %>%
    pivot_longer(-c(source, state), names_to="metric", values_to="value")

# Plot percentage difference by metric and state
usaCTP %>%
    pivot_wider(c(state, metric), names_from="source", values_from="value") %>%
    mutate(pct=`COVID Tracking Project`/`USA Facts`) %>%
    ggplot(aes(x=fct_reorder(state, abs(pct-1), .fun=max), y=pct)) + 
    geom_point() + 
    coord_flip() +
    labs(x="", 
         y="COVID Tracking Project as % of USA Facts", 
         title="Comparison of COVID Tracking Project and USA Facts", 
         subtitle="Data as of 10-DEC-2020"
         ) +
    geom_hline(yintercept=1, lty=2) +
    facet_wrap(~metric)

# Plot percentage difference by metric and state
usaCTP %>%
    pivot_wider(c(state, metric), names_from="source", values_from="value") %>%
    mutate(pct=`COVID Tracking Project`/`USA Facts`) %>%
    group_by(state) %>%
    filter(max(abs(pct-1))>=0.025) %>%
    ggplot(aes(x=fct_reorder(state, abs(pct-1), .fun=max), y=pct)) + 
    geom_text(aes(label=paste0(round(100*pct, 1), "%")), size=3) + 
    coord_flip() +
    labs(x="", 
         y="COVID Tracking Project as % of USA Facts", 
         title="Comparison of COVID Tracking Project and USA Facts", 
         subtitle="Data as of 10-DEC-2020 (filtered to only states at least 2.5% different on one metric)"
         ) +
    geom_hline(yintercept=1, lty=2) +
    facet_wrap(~metric)

```

It may be particularly interesting to explore some of the larger differences:  
  
* Cases - VA, IA, RI, TX  
* Deaths - VA, NY, IA, GA, KS  
  
Virginia is particularly of note for being ~25% different on both cases and deaths.  Iowa is particularly of note for being ~15% different on both cases and deaths, but in different directions.
  
A function is written to explore the daily data for a give state:  
```{r}

exploreState <- function(keyState, 
                         ctp, 
                         usa, 
                         maxDate=NULL, 
                         minDate=NULL
                         ) {
    
    # FUNCtION ARGUMENTS:
    # keyState: the state abbreviation of interest
    # ctp: a processed list from COVID Tracking Project
    # usa: a processed list from USA Facts
    # maxDate: the latest date to use (NULL means use all)
    # minDate: the minimum date to use (NULL means use all)
    
    # Extract the relevant data from COVID Tracking Project
    ctp <- ctp[["plotData"]] %>% 
        filter(state %in% keyState) %>% 
        group_by(date) %>% 
        summarize(cases=sum(cases), deaths=sum(deaths), .groups="drop")
    
    # Extract the relevant data from USA Facts
    usa <- usa[["clusterStateData"]] %>% 
        filter(state %in% keyState) %>% 
        group_by(date) %>%
        summarize(cases=sum(cases, na.rm=TRUE), deaths=sum(deaths), .groups="drop")
    
    # Integrate the data
    ctpUSA <- mutate(ctp, source="COVID Tracking Project") %>%
        bind_rows(mutate(usa, source="USA Facts"))
    
    # Filter for minDate and maxDate if requested
    if (!is.null(minDate)) ctpUSA <- filter(ctpUSA, date >= as.Date(minDate))
    if (!is.null(maxDate)) ctpUSA <- filter(ctpUSA, date >= as.Date(maxDate))

    # Create a pivoted data frame
    pivotDF <- ctpUSA %>%
        pivot_longer(-c(date, source), names_to="metric", values_to="value") %>%
        arrange(source, metric, date) %>%
        group_by(source, metric) %>%
        mutate(cumValue=cumsum(value))
    
    # Plot the data by date
    p1 <- pivotDF %>%
        ggplot(aes(x=date, y=value)) + 
        geom_line(aes(group=source, color=source)) + 
        facet_wrap(~metric, scales="free_y") + 
        labs(x="", y="Impact", title=paste0("Impact by date for: ", keyState)) + 
        scale_color_discrete("Source")
    print(p1)
    
    # Plot cumulative data by date
    p2 <- pivotDF %>%
        ggplot(aes(x=date, y=cumValue)) + 
        geom_line(aes(group=source, color=source)) + 
        facet_wrap(~metric, scales="free_y") + 
        labs(x="", y="Cumulative Impact", title=paste0("Cumulative impact by date for: ", keyState)) + 
        scale_color_discrete("Source")
    print(p2)
    
    # Return the processed file
    pivotDF
    
}


# Test the function for NY
exploreState("NY", ctp=old_hier5_201214, usa=cty_old_20201215)

```
  
The data sources agree almost perfectly on cases, but there are some significant differences on deaths by day leading to a total of ~25k in COVID Tracking Project and ~35k in USA Facts.  Reported data are closer to ~35k so there may be some further digging needed for the COVID Tracking Project process.

The function is also run for VA and IA as they are the two other largest outliers:  
```{r}

exploreState("VA", ctp=old_hier5_201214, usa=cty_old_20201215)
exploreState("IA", ctp=old_hier5_201214, usa=cty_old_20201215)

```

With the Virginia data, USA Facts consistently reports lower than COVID Tracking Project, reaching ~3500 deaths with ~225k cases while COVID Tracking Project reports ~4500 deaths and ~275k cases.  The COVID Tracking Project data re much closer to official numbers than the USA Facts data.

With the Iowa data, the disconnect in cases begins roughly in September, with USA Facts reporting ~250k cases total and COVID Tracking Project reporting ~225k cases total (both report ~3200 deaths).  Official data for Iowa are closer to ~260k deaths and ~3300 deaths.

Further exploration of the raw data files may be merited to see if any data are being deleted (e.g., county name/FIPS mismatch or NYC tracked separately from NYS or the like).

The raw data files from COVID Tracking Project are explored:  
```{r}

# Raw data from COVID Tracking Project, summed
ctpRaw <- old_hier5_201214$dfRaw %>% 
    group_by(state) %>% 
    summarize_if(is.numeric, sum, na.rm=TRUE)

# States in ctpRaw that are not in c(state.abb, "DC)
# Includes only American Samoa, Guam, Mariana Islands, Puerto Rico, Virgin Islands
ctpRaw %>%
    filter(!(state %in% c(state.abb, "DC")))

# Metrics for New York
ctpRaw %>%
    filter(state %in% c("NY", "IA", "VA")) %>%
    column_to_rownames("state") %>%
    t()

```
  
There is no state-level surrogate missing (e.g., 'YC' is not being used to distinguish NYC from NYS).  There are several variables that potentially relate to deaths:  
  
* death  
* deathConfirmed  
* deathProbable  
* deathIncrease  
  
The data are filtered to just these columns, and the results displayed for easier viewing:  
```{r}

# Metrics for New York
ctpRaw %>%
    filter(state %in% c("NY", "IA", "VA")) %>%
    select(state, death, deathConfirmed, deathProbable, deathIncrease) %>%
    column_to_rownames("state") %>%
    t()

```
  
The variable 'death' is potentially of interest, as it appears to be an attempt at cumsum(deathIncrease).  Is this observed in the data?  
```{r}

# Raw data from COVID Tracking Project, summed
ctpDaily <- old_hier5_201214$dfRaw %>% 
    arrange(state, date) %>%
    select(state, date, death, deathIncrease) %>%
    group_by(state) %>% 
    mutate(cumDeathIncrease=cumsum(ifelse(is.na(deathIncrease), 0, deathIncrease))) %>%
    ungroup()

ctpDaily %>% filter(death != cumDeathIncrease)

```
  
The data fields are aligned.  According to COVID Tracking Project, their NYS data include a significant undercount of the LTC deaths, driven by reporting issues with NYS.  

Further, [COVID Tracking Project](https://covidtracking.com/data/state/new-york) explain that "As of June 1, 2020, New York City reported 5740 more deaths (probable and confirmed) than New York State reports for NYC. Due to an exclusion of probable COVID-19 deaths in the state's data, New York City and New York State report substantially diverging death counts. We use the data from the state, so our dataset excludes these probable COVID-19 deaths."

While the disconnect is large, NYC is a very large component of NYS and LTC is a very large component of COVID death.  This would likely explain very different numbers of deaths reported in NYS, even as there is close agreement on the number of cases.

