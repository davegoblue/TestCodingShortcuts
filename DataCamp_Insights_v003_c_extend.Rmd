---
title: "Data Camp Insights"
author: "davegoblue"
date: "September 24, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

library(tidyverse)

```

## Background and Overview  
This document is a complement to DataCamp_Insights_v003_c.Rmd to be merged and integrated later.
  

***
  
###_Survey and Measure Development in R_  
  
Chapter 1 - Preparing to Analyze Survey Data  
  
Surveys in Marketing Research:  
  
* Surveys can consist of items rated on the Likert scale (commonly, but not necessarily, 1-5 scales)  
	* Step 1 - item generation (expert review, SME, etc.)  
    * Step 2 - questionnaire administration  
    * Setp 3 - initial item reduction  
    * Step 4 - confirmatory factor analysis  
    * Step 5 - Convergent/Discriminant Validity  
    * Step 6 - Replication  
* Example for inter-rater reliability  
	* library(irr)  
    * agree(experts)  
    * cohen.kappa(experts)  # 0-0.4 is poor, 0.4-0.6 is mediocre, 0.6-0.8 is substantial, 0.8+ is very strong  
* Example for content validity ratios  
	* Lawshe's Content Validity Ratio (CVR): what percent of experts judge that item essential to what's being measured  
    * CVR = [ E - (N/2) ] / (N/2)  where N is the total number of experts and E is the number who rated the item as essential  
    * psychometric::CVratio(NTOTAL=, NESSENTIAL=)  # -1 is consensus againt, +1 is consensus in favor  
  
Measurement, Validity, and Reliability:  
  
* Measurement is the process of observing and recording events  
	* Requires a measurement device and a calibration standard  
* Reliability can be assessed on three prongs  
	* Equivalence (inter-rater)  
    * Internal consistency (coefficient alpha, split-half)  
    * Stability (test-retest)  
* Validity checks whether measurments are as-claimed  
	* Content  
    * Construct (convergent, discriminant)  
    * Criterion (concurrent, predictive)  
* Exploratory Data Analysis can be considered as step 2.5 - between questionnaire administration and initial item reduction  
	* c_sat_likert <- c_sat %>% mutate_if(is.integer, as.factor) %>% likert()  
    * plot(c_sat_likert)  
* Can use EDA to check for items that are reverse coded (where 5 would be bad and 1 would be good)  
	* car::recode(myVar, "1=5; 2=4; 3=3; 4=2; 5=1")  
  
Describing Survey Results:  
  
* Generally, if there are less than 5% missing values and with equal distribution, then just omit them  
	* Hmisc::naclus(bad_survey))  
* Item correlations can be valuable - high correlations with each other, but not outside their own group  
	* corr.test(myDF)  
    * corrplot(cor(myDF), method="circle")  
  
Example code includes:  
```{r}

library(lavaan)


file001 <- readr::read_csv("./RInputFiles/brandrep-cleansurvey-extraitem.csv")
file002 <- readr::read_csv("./RInputFiles/brandquall11-recodedbutextraitem.csv")
file003 <- readr::read_csv("./RInputFiles/customersatisfactionclean.xls")
file004 <- readr::read_csv("./RInputFiles/brandloyalty.xls")


sme <- data.frame(Rater_A=c(1, 2, 3, 2, 1, 1, 1, 2, 3, 3, 2, 1, 1), 
                  Rater_B=c(1, 2, 2, 3, 3, 1, 1, 1, 2, 3, 3, 3, 1)
                  )


# Print beginning of sme data frame
head(sme)

# Correlation matrix of expert ratings
cor(sme)

# Percentage agreement of experts
irr::agree(sme)


# Check inter-rater reliability
psych::cohen.kappa(sme)

# While our Cohen's kappa and Pearson correlation happen to be similar in value, these are not measuring the same thing
# We are interested in agreement between the pairs of expert ratings on each item rather than a linear relationship between the item ratings in total
# In the next exercise, we'll look at content validity
# This is a measure of the assessment by a panel of experts (not just two, as in in Cohen's kappa) about the strength of an individual item


lawshe <- data.frame(item=rep(1:5, each=3), 
                     expert=rep(LETTERS[1:3], times=5), 
                     rating=factor(c("Essential", "Useful", "Not necessary", "Useful", "Not necessary", 
                                     "Useful",  "Not necessary", "Not necessary", "Essential", "Essential", 
                                     "Useful", "Essential", "Essential", "Essential", "Essential"
                                     )
                                   )
                     )


# Calculate the CVR for each unique item in the data frame
lawshe %>% 
    group_by(item) %>% 
    summarize(CVR = psychometric::CVratio(NTOTAL = length(unique(expert)), 
                                          NESSENTIAL = sum(rating == 'Essential')
                                          )
              )


brand_rep <- file001
glimpse(brand_rep)


# Convert items to factor
b_rep_likert <- brand_rep %>% 
    mutate(poor_workman_r=6-poor_workman_r) %>%
    mutate_if(is.double, as.factor) %>%
    as.data.frame()

# Response frequencies - base R
summary(b_rep_likert)

# Plot response frequencies
result <- likert::likert(b_rep_likert)
plot(result)


brand_qual <- file002 %>%
    mutate(tired=6-tired_r) %>%
    select(-innovator) %>%
    as.data.frame()
glimpse(brand_qual)

brand_qual_items <- c('trendy = This brand is trendy.', 'latest = This brand offers the latest products.', 'tired = This is a tired brand.', "happy_pay = I am happy paying what I do for this brand's products.", "reason_price = This brand's products are reasonably priced.", "good_deal = This brand's products are a good deal.", "strong_perform = This brand's products are strong performers.", 'leader = This brand is a leader in its field.', 'serious = This brand takes its product quality seriously.')
brand_qual_items


# Get response frequencies from psych
psych::response.frequencies(brand_qual)

# Print item descriptions
brand_qual_items

# Reverse code the "opposite" item
brand_qual$tired_r <- car::recode(brand_qual$tired, "1 = 5; 2 = 4; 4 = 2; 5 = 1")

# Check recoding frequencies
brand_qual %>% 
    select(tired, tired_r) %>%
    psych::response.frequencies() %>%
    round(2)


missing_lots <- file002 %>%
    mutate(tired=6-tired_r) %>%
    select(-tired_r)
set.seed(1908181013)
naRow <- sample(1:nrow(missing_lots), round(0.2*nrow(missing_lots)*ncol(missing_lots)), replace=TRUE)
naCol <- sample(1:ncol(missing_lots), round(0.2*nrow(missing_lots)*ncol(missing_lots)), replace=TRUE)
for (j in seq_along(naRow)) { missing_lots[naRow[j], naCol[j]] <- NA }
glimpse(missing_lots)
    

# Total number of rows
nrow(missing_lots)

# Total number of incomplete cases
sum(!complete.cases(missing_lots))

# Number of incomplete cases by variable
colSums(is.na(missing_lots))

# Hierarchical plot -- what values are missing together?
plot(Hmisc::naclus(missing_lots))


brand_qual_9 <- file002
glimpse(brand_qual_9)


# View significance of item correlations
psych::corr.test(brand_qual_9)

# Visualize item correlations -- corrplot
corrplot::corrplot(cor(brand_qual_9), method = "circle")


b_rep_items <- c("well_made: Crunchola's products are well-made.", 'consistent: Crunchola offers consistently high-quality products.', 'poor_workman: Crunchola suffers from poor workmanship in its products.', 'higher_price: I am willing to pay a higher price for Crunchola products.', 'lot_more: I am willing to pay a lot more for Crunchola products.', 'go_up: The price of Crunchola products would have to go up quite a bit before I would switch to another brand.', "stands_out: Crunchola's brand really stands out from its competitors.", "unique: Crunchola's brand is unique from other brands.", "one_of_a_kind: Crunchola's brand is truly one of a kind.")
b_rep_items


brand_rep_9 <- file001 %>%
    mutate(poor_workman = 6-poor_workman_r) %>%
    select(-poor_workman_r) %>%
    as.data.frame()
glimpse(brand_rep_9)


# Get response frequencies
psych::response.frequencies(brand_rep_9)

# Recode the appropriate item 
brand_rep_9$poor_workman_r <- car::recode(brand_rep_9$poor_workman, "1 = 5; 2 = 4; 4 = 2; 5 = 1")

# Adjust brandrep 9 dataset
brand_rep_9_new <- select(brand_rep_9, -poor_workman)

# Visualize item correlation
corrplot::corrplot(cor(brand_rep_9_new), method = "circle")

```
  
  
  
***
  
Chapter 2 - Exploratory Factor Analysis and Survey Development  
  
Latent Variables:  
  
* Latent variables are inferred from manifest variables - for example, brand loyalty  
* Parsimony is a general goal of survey development - how do the manifest variables help identify the latent variables  
	* psych::fa.parallel(myDF)  # scree of dataset against random dataset  
    * myEFA <- psych::fa(myDF, nfactors=3)  
    * myEFA$loadings  
    * psych::scree(myDF)  
  
EFA and Item Refinement:  
  
* Factor loadings are a valuable statistic - relationship between manifest variables and latent variables  
	* Ideally, only one latent variable per manifest variables  
    * 0 - 0.4 are poor  
    * 0.7+ are strong  
    * 0.4 - 0.7 are equivocal  
* What makes for a strong EFA?  
	* c_sat_11_EFA_3$e.values  # check that the number of eigenvalues >1 is the same as the number of factors (rule of thumb)  
    * Factor score correlations of 0.6 and under are "not too similar"  
    * myEFA$score.cor  
* If results are not favorable can either 1) drop poorly performing items, or 2) revist the number of factors  
  
Assessing Internal Reliability:  
  
* Internal consistency is a measure of survey reliability - consistency within itself  
* Split-half reliability checks whether all parts of the survey contribute equally  
	* psych::splitHalf(mySurvey)  # generally, 0.8+ indicates internal reliability  
* Coefficient (Cornbach) alpha measures the consistency of measures of the construct  
	* psych::alpha(mySurvey)  # std.alpha is considered a more reliable metric due to standardization  
    * Target is 0.8 - 0.9 with 0.7 - 0.8 also respectable and 0.65 - 0.7 minimally acceptable  
    * Values > 0.9 may suggest collinearity problems; drop items  
    * Values < 0.65 are undesirable and/or unacceptable; drop items as they may not be measuring the same construct  
  
Example code includes:  
```{r}

b_loyal_10 <- file004
glimpse(b_loyal_10)


# Print correlation matrix
psych::corr.test(b_loyal_10)

# Visualize b_loyal_10 correlation matrix
corrplot::corrplot(cor(b_loyal_10))

# Parallel analysis
psych::fa.parallel(b_loyal_10)


brand_rep_9 <- file001 %>%
    mutate(poor_workman = 6-poor_workman_r) %>%
    select(-poor_workman) %>%
    as.data.frame()
glimpse(brand_rep_9)


# Scree plot
psych::scree(brand_rep_9)

# Conduct three-factor EFA
brand_rep_9_EFA <- psych::fa(brand_rep_9, nfactors = 3)

# Print output of EFA
names(brand_rep_9_EFA)


# Summarize results of three-factor EFA
summary(brand_rep_9_EFA)

# Build and print loadings for a two-factor EFA
brand_rep_9_EFA_2 <- psych::fa(brand_rep_9, nfactors = 2)
brand_rep_9_EFA_2$loadings

# Build and print loadings for a four-factor EFA
brand_rep_9_EFA_4 <- psych::fa(brand_rep_9, nfactors = 4)
brand_rep_9_EFA_4$loadings


# (Factor loadings greater than 1, while rare, are not necessarily an issue.)

# Three factor EFA - brand_rep_9
brand_rep_9_EFA_3 <- psych::fa(brand_rep_9, nfactors = 3)

# Eigenvalues
brand_rep_9_EFA_3$e.values

# Factor score correlations
brand_rep_9_EFA_3$score.cor

# Factor loadings
brand_rep_9_EFA_3$loadings


# Create brand_rep_8 data frame
brand_rep_8 <- brand_rep_9 %>% select(-one_of_a_kind)

# Create three-factor EFA
brand_rep_8_EFA_3 <- psych::fa(brand_rep_8, nfactors=3)

# Factor loadings
brand_rep_8_EFA_3$loadings

# Factor correlations -- 9 versus 8 item model
brand_rep_8_EFA_3$score.cor
brand_rep_9_EFA_3$score.cor


# Three factor EFA loadings
brand_rep_8_EFA_3$loadings

# Two factor EFA & loadings
brand_rep_8_EFA_2 <- psych::fa(brand_rep_8, nfactors = 2)
brand_rep_8_EFA_2$loadings

# Four factor EFA & loadings
brand_rep_8_EFA_4 <- psych::fa(brand_rep_8, nfactors = 4)
brand_rep_8_EFA_4$loadings

# Scree plot of brand_rep_8
psych::scree(brand_rep_8)


# Standardized coefficient alpha
psych::alpha(brand_rep_9)$total$std.alpha

# 3-factor EFA
brand_rep_9_EFA_3 <- psych::fa(brand_rep_9, nfactors = 3)
brand_rep_9_EFA_3$loadings

# Standardized coefficient alpha - refined scale
psych::alpha(brand_rep_8)$total$std.alpha

# A survey with poorly-loading items can still be reliable – that's why we do EFA first
# Remember that a reliable survey in itself is not the goal of measurement – it is necessary but not sufficient


# Get names of survey items
names(brand_rep_8)

# Create new data frames for each of three dimensions
p_quality <- brand_rep_8 %>% select(1:3)
p_willingness <- brand_rep_8 %>% select(4:6)
# p_difference <- brand_rep_8 %>% select(7:8)

# Check the standardized alpha for each dimension
psych::alpha(p_quality)$total$std.alpha
psych::alpha(p_willingness)$total$std.alpha
# psych::alpha(p_difference)$total$std.alpha
psych::alpha(brand_rep_8)$total$std.alpha


# Get split-half reliability 
psych::splitHalf(brand_rep_8)

# Get averages of even and odd row scores
odd_scores <- rowMeans(brand_rep_8[c(TRUE, FALSE), ])
even_scores <- rowMeans(brand_rep_8[c(FALSE,TRUE), ])

# Correlate scores from even and odd items
cor(odd_scores[1:length(even_scores)], even_scores)


# 3 factor EFA
b_loyal_10_EFA_3 <- psych::fa(b_loyal_10, nfactors = 3)

# Factor loadings, eigenvalues and factor score correlations
b_loyal_10_EFA_3$loadings
b_loyal_10_EFA_3$e.values
b_loyal_10_EFA_3$score.cor

# 2 factor EFA
b_loyal_10_EFA_2 <- psych::fa(b_loyal_10, nfactors = 2)

# Factor loadings, eigenvalues and factor score correlations
b_loyal_10_EFA_2$loadings
b_loyal_10_EFA_2$e.values
b_loyal_10_EFA_2$score.cor

```
  
  
  
***
  
Chapter 3 - Confirmatory Factor Analysis and Construct Validation  
  
CFA and EFA:  
  
* Confirmatory Factor Analysis (CFA) is a means of construct validation  
	* Do the number of factors reflected in the data match theory and hypotheses  
* Can use the lavaan package for latent variable analysis  
	* la(tent) va(riable) an(alaysis)  
    * Use =~ to assign items to factors  
* Example for using lavaan on the 9-item survey  
	* bq_9_CFAModel <- "VAL =~ reason_price + happy_pay + good deal PERF =~ serious + leader +  strong_perform FUN =~ trendy + latest + tired_r"  
    * bq_9_CFA <- cfa(model = bq_9_CFAModel, data=bq_9)  
    * summary(bq_9_CFA, fit.measures=TRUE, standardized=TRUE)  
    * inspect(bq_9_CFA, "std")$lambda  
    * semPlot::semPaths(bq_9_CFA)  
  
CFA Assumptions and Interpretation:  
  
* Can test for multivariate normality - p-values for skewness and kurtosis  
	* psych::mardia(myData)  
* The default for lavaan is maximum likelihood, which assumes normality  
	* Can instead use MLR to mitigate non-normality  
    * bq_cfa <- cfa(model=myModel, data=myData, estimator="MLR")  
* Can look at fit measures and assess model performance  
	* CFI (comparative fit index) - should be 0.9+  
    * TLI (Tucker Lewis Index) - should be 0.9+  
    * Chi-squared - should be < 0.05 (though often will be for large sample sizes, even with a bad model)  
    * RMSEA - ideally less than 0.05  
* Can use the fit measures function to get 42 fit measures  
	* fitMeasures(myModel)  
    * fitMeasures(myModel, fit.measures=c("cfi", "tli"))  
* Can inspect estimates using standardizedSolution()  
	* standardizedSolution(myModel)  
  
Construct Validity:  
  
* Construct validity is the extent to which the actual measurements and the claims of what is being measured are congruent  
	* Validity is like being centered on a bullseye  
    * Reliability is based on being tightly clustered around the mean  
* If two dimensions are measuring the same things, then they should be combined in the interests of parsimony  
	* semTools::reliability(myModel)  
* Discriminant validity means that items should be distinct, but not unrelated  
	* avevar should be 0.5+  
    * CR (omega) should be 0.7+  
    * alpha (Cronbach) should be 0.7+  
  
Example code includes:  
```{r}

brand_rep_EFA <- brand_rep_8_EFA_3
brand_rep_8_model <- 'F1 =~ well_made + consistent + poor_workman_r
F2 =~ higher_price + lot_more + go_up
F3 =~ stands_out + unique'
brand_rep_CFA <- lavaan::cfa(model=brand_rep_8_model, data=brand_rep_8)


# Factor loadings -- EFA
brand_rep_EFA$loadings

# Factor loadings -- CFA
lavaan::inspect(brand_rep_CFA, what = "std")$lambda

# Plot diagram -- EFA
psych::fa.diagram(brand_rep_EFA)

# Plot diagram -- CFA
semPlot::semPaths(brand_rep_CFA)


# Rename items based on proposed dimensions
colnames(b_loyal_10) <- c("ID1", "ID2", "ID3", "PV1", "PV2", "PV3", "BT1", "BT2", "BT3", "BT4")

# Define the model
b_loyal_cfa_model <- 'ID =~ ID1 + ID2 + ID3
                    PV =~ PV1 + PV2 + PV3
                    BT =~ BT1 + BT2 + BT3 + BT4'
                        
# Fit the model to the data
b_loyal_cfa <- lavaan::cfa(model=b_loyal_cfa_model, data=b_loyal_10)

# Check the summary statistics -- include fit measures and standardized estimates
summary(b_loyal_cfa, fit.measures=TRUE, standardized=TRUE)


# Two dimensions: odd- versus even-numbered items
bad_model <- 'ODD =~ CS1 + CS3 + CS5 + CS7 + CS9
              EVEN =~ CS2 + CS4 + CS6 + CS8 + CS10'
                
# Fit the model to the data
c_sat_bad_CFA <- cfa(model=bad_model, data=file003)

# Summary measures
summary(c_sat_bad_CFA, fit.measures=TRUE, standardized=TRUE)


c_sat_model <- 'F1 =~ CS1 + CS2 + CS3 + CS4
F2 =~ CS5 + CS6 + CS7
F3 =~ CS8 + CS9 + CS10'
c_sat_50 <- file003[1:50, ]


# Mardia's test for multivarite normality
psych::mardia(c_sat_50)

# Fit model to the data using robust standard errors
c_sat_cfa_mlr <- cfa(model=c_sat_model, data=c_sat_50, estimator="MLR")

# Summary including standardized estimates and fit measures
summary(c_sat_cfa_mlr, fit.measures=TRUE, standardized=TRUE)


c_sat_model_a <- 'F1 =~ CS1 + CS2 + CS3 + CS4
F2 =~ CS5 + CS6 + CS7
F3 =~ CS8 + CS9 + CS10'
c_sat_model_b <- 'F1 =~ CS1 + CS3 + CS5 + CS7 + CS9
F2 =~ CS2 + CS4 + CS6 + CS8 + CS10'


# Fit the models to the data
c_sat_cfa_a <- cfa(model = c_sat_model_a, data = file003)
c_sat_cfa_b <- cfa(model = c_sat_model_b, data = file003)

# Print the model definitions
cat(c_sat_model_a)
cat(c_sat_model_b)

# Calculate the desired model fit statistics
fitMeasures(c_sat_cfa_a, fit.measures=c("cfi", "tli"))
fitMeasures(c_sat_cfa_b, fit.measures=c("cfi", "tli"))


c_sat <- file003
names(c_sat) <- c("CSU1", "CSU2", "CSU3", "CSU4", "EU1", "EU2", "EU3", "PS1", "PS2", "PS3")


# Add EU1 to the CSU factor
c_sat_model_a <- 'CSU =~ CSU1 + CSU2 + CSU3 + CSU4
                EU =~ EU1 + EU2 + EU3
                PS =~ PS1 + PS2 + PS3'

# View current c_sat model
cat(c_sat_model_a)

# Add EU1 to the CSU factor
c_sat_model_b <- 'CSU =~ CSU1 + CSU2 + CSU3 + CSU4 + EU1
                EU =~ EU1 + EU2 + EU3
                PS =~ PS1 + PS2 + PS3'

# Fit Models A and B to the data
c_sat_cfa_a <- cfa(model = c_sat_model_a, data = c_sat)
c_sat_cfa_b <- cfa(model = c_sat_model_b, data = c_sat)

# Compare the nested models
anova(c_sat_cfa_a, c_sat_cfa_b)


# Fit the model to the data 
# c_sat_cfa <- cfa(model = c_sat_model, data = c_sat_group, group = "COUNTRY")

# Summarize results -- include fit measures and standardized estimates
# summary(c_sat_cfa, fit.measures=TRUE, standardized=TRUE)

# Get average estimate for both groups
# standardized_solution <- standardizedSolution(c_sat_cfa)
# standardized_solution %>%
#   filter(op == "=~") %>%
#   group_by(group) %>% 
#   summarize(mean(est.std))


c_sat_cfa_model_3 <- 'F1 =~ CS1 + CS2 + CS3 + CS4
F2 =~ CS5 + CS6 + CS7
F3 =~ CS8 + CS9 + CS10'
c_sat_cfa_model_2 <- 'F1 =~ CS1 + CS2 + CS3 + CS4 + CS5 + CS6 + CS7
F2 =~ CS8 + CS9 + CS10'

# Fit three-factor CFA
c_sat_cfa_3 <- cfa(model = c_sat_cfa_model_3, data = file003)

# Inspect key fit measures - three-factor CFA
fitMeasures(c_sat_cfa_3, fit.measures = c("cfi","tli","rmsea"))

# Fit two-factor CFA
c_sat_cfa_2 <- cfa(model = c_sat_cfa_model_2, data = file003)

# Inspect key fit measures - two-factor CFA
fitMeasures(c_sat_cfa_2, fit.measures = c("cfi","tli","rmsea"))

# Compare measures of construct validity for three- versus two-factor models
semTools::reliability(c_sat_cfa_3)
semTools::reliability(c_sat_cfa_2)


brand_rep_CFA_model <- 'F1 =~ well_made + consistent + poor_workman_r
F2 =~ higher_price + lot_more + go_up
F3 =~ stands_out + unique'
brand_rep_CFA <- lavaan::cfa(model=brand_rep_8_model, data=brand_rep_8)


# Print CFA model
cat(brand_rep_CFA_model)

# semTools reliability measures
semTools::reliability(brand_rep_CFA)

# psych standardized coefficient alpha measure
psych::alpha(brand_rep_9)$total$std.alpha


# Store F1 estimates as object loadings
loadings <- standardizedSolution(c_sat_cfa_3) %>%
    filter(op == "=~", lhs == "F1") %>% 
    select(est.std)

# Composite reliability
re <- 1 - loadings ^ 2
result <- sum(loadings) ^ 2 / ((sum(loadings)^ 2)  + sum(re))
result

# Average variance extracted
l2 <- loadings ^ 2
avg_var <- sum(l2) / nrow(loadings)
avg_var

# Compare versus semTools
semTools::reliability(c_sat_cfa_3)


# Print brand_rep_factors
# brand_rep_factors

# Build model for lavaan
brand_rep_8_cfa_model <- "QUAL =~ consistent + well_made + poor_workman_r
PRICE =~ go_up + lot_more + higher_price
UNIQUE =~ stands_out + unique"

# Summarize results with fit measures and standardized estimates
# summary(brand_rep_8_CFA, standardized = TRUE, fit.measures = TRUE)

# Construct validity
# semTools::reliability(brand_rep_8_CFA)

```
  
  
  
***
  
Chapter 4 - Criterion Validity and Replication  
  
Concurrent Validity and Model Diagrams:  
  
* Criterion validity is a measure of relationship between the construct and external variable of interest  
* Variables are not always on the 1-5 scale, and differences in units can negatively impact model validity  
	* describe(myData)  # check means and standard deviations (ideally, everything is N(0, 1)  
* Can latentize a variable by adding it with =~  
	* myModel <- '… age_fact =~ age'  # latentizes age to age_fact  
* Can correlate manifest and latent variable with ~~  
	* myModel <- '… age_fact =~ age\n age_fact ~~ F1 + F2 + F3'  # latentizes age to age_fact and gets latent statistics (F1, F2, F3 already defined in the model)  
    * mySEM <- sem(myModel, data=myData, estimator="MLR")  
    * summary(mySEM, fit.measures=TRUE, standardized=TRUE)  
* Diagrams are sometimes called "spaghetti and meatballs", representing that they can be busy diagrams  
  
Predictive Validity and Factor Scores:  
  
* Predictive validity assesses the degree to which models predict future outcomes  
* Linear regression can be used for this task  
	* Begin by binding and scaling all of the relevant variables  
* Can run regression in lavaan using ~  
	* c_sat_model = "… spend ~ F1 + F2 + F3"  # assumes F1, F2, F3 each defined as usual using =~  
    * semPaths(c_sat_sem, rotation=2)  
    * standardizedSolution(c_sat_sem) %>% filter(op == "~") %>% mutate_if(is.numeric, round, digits=3)  
    * inspect(c_sat_rem, "r2")  # pull the R-squared  
* Factors scores are numerical scores reflecting relative standings on the latent factor  
	* csat_cfa <- cfa(model = csat_model, data = c_sat)  
    * csat_scores <- as.data.frame(predict(csat_cfa))  
    * describe(csat_scores)  
    * multi.hist(csat_scores)  
  
Repeated Measures, Replication, and Factor Scores:  
  
* Stability is a third form of reliability measurement  
	* Does an instrument get similar responses if measuring the same population near the same time?  
    * "Test-retest reliability"  
    * survey_test_retest <- testRetest(t1 = survey_t_1, t2 = survey_t_2, id = "id")  
    * Generally, scores of 0.9+ are very good and scores of 0.7- are unreliable  
* Replication is a different step that can be taken in the event that it is not possible to get people to retake the survey  
	* Split the data by rows - odd vs. even  
  
Wrap Up:  
  
* Six step process for building and testing models  
  
Example code includes:  
```{r eval=FALSE}

spendData <- c(94.5, 715, 145.5, 772.5, 133.5, 350, 75.5, 304.5, 117, 81, 234.5, 102, 152.5, 295, 145, 222, 121.5, 142, 82.5, 144, 130, 141, 545, 142.5, 175, 154, 130, 148.5, 255, 139.5, 420, 373.5, 197.5, 487.5, 337.5, 133.5, 114, 84, 255.5, 129, 114, 275, 297, 84, 87, 109.5, 123, 405, 123, 158, 145, 139.5, 112.5, 458, 138, 91.5, 190, 257.5, 155, 259, 120, 84, 84, 755, 84, 412, 270, 134, 285, 227.5, 133.5, 123, 127.5, 825, 418, 103.5, 144, 124, 120, 445.5, 150.5, 75, 129, 312, 330, 182.5, 282, 91.5, 218, 245, 157.5, 118.5, 148.5, 505, 87, 182, 111, 294, 110, 325.5, 115.5, 312, 120, 510, 91.5, 139.5, 85.5, 189, 152, 141, 138, 387, 114, 84, 213, 120, 115.5, 231, 78, 85.5, 354, 142.5, 128, 212, 547.5, 145, 103.5, 294, 354, 182.5, 185, 212, 97.5, 103.5, 235, 395, 105.5, 283.5, 155, 91.5, 94.5, 297.5, 283.5, 125, 159, 139.5, 95, 198, 104, 138, 155, 200, 97.5, 224, 588, 108, 100.5, 183, 350, 153, 150, 155, 91.5, 138, 117, 135.5, 138, 202, 257, 103.5, 114, 282, 112, 198, 159, 420, 315, 402, 507, 259.5, 81, 127.5, 144, 225, 141, 84, 150, 150.5, 455, 75, 294, 102, 199.5, 385, 155, 144, 135, 142.5, 172, 390, 94.5, 153, 472.5, 105, 123, 188, 325, 504, 99, 111, 151.5, 78, 545, 170, 123, 93, 381.5, 735, 100.5, 97.5, 155, 252.5, 192, 132, 252.5, 121.5, 90, 257, 151.5, 94.5, 153.5, 311.5, 79.5, 284, 151.5, 95, 78, 480, 102, 215, 115.5, 330, 592.5, 79.5, 355.5, 195, 105.5, 142.5, 154, 155, 312, 321, 75.5, 185, 324, 155, 530, 127.5, 148.5, 152, 111, 157.5, 151.5, 772.5, 123, 115.5, 145.5, 84, 515, 82.5, 108, 130.5, 138, 279, 151.5, 207, 150, 109.5, 150, 153.5, 152.5, 150.5, 88.5, 185, 115.5, 123, 150, 114, 321, 144, 142.5, 152, 82.5, 187.5, 97.5, 145, 257, 435, 250, 310.5, 78, 105.5, 102, 138, 303, 285, 155, 124.5, 240, 204, 118.5, 241.5, 147, 118.5, 105, 591.5, 180, 93, 252, 103.5, 287, 575, 75, 238, 189, 204, 210, 153, 145.5, 117, 559, 153.5, 79.5, 222.5, 145.5, 88.5, 159, 155, 255, 127.5, 300, 154, 213, 135, 84, 151.5, 127.5, 99, 200, 135, 522.5, 297, 152, 127.5, 203, 103.5, 178.5, 130.5, 255, 100.5, 213, 185, 228, 115.5, 109.5, 75.5, 273, 511, 414, 152, 217, 150, 102, 537.5, 282, 440, 288, 172.5, 112.5, 577.5, 140, 291.5, 152, 582.5, 210, 318.5, 185, 145.5, 148.5, 324, 145, 105.5, 132, 85.5, 135, 152, 135, 324, 200, 155, 247.5, 197.5, 95, 304.5, 215, 577.5, 111, 495, 141, 139.5, 112.5, 110, 135.5, 97.5, 157.5, 243, 159, 155, 185, 155, 114, 395, 130.5, 238, 345.5, 597.5, 210, 220, 210, 222.5, 124.5, 158, 150, 490.5, 270, 88.5, 205, 135, 90, 152, 309, 153, 105, 111, 78, 123, 159, 95, 115, 435, 235, 292.5, 155, 304.5, 114, 104, 135, 397.5, 93, 257, 102, 204, 252, 152, 215, 108, 148.5, 79.5, 155, 114, 94.5, 118.5, 178.5, 111, 150.5, 195, 85.5, 84, 93, 575, 148.5, 757.5, 155, 87, 112.5, 88.5, 255, 358, 84, 405, 153, 127.5, 81, 135.5, 154.5, 247.5, 182, 79.5, 373.5, 95, 147, 145.5, 152.5, 294, 259.5, 354, 103.5, 187.5, 124.5, 218, 227.5, 481.5, 125, 123, 450, 129, 318, 170, 319.5, 91.5, 183, 154, 391.5, 458, 303, 114, 111, 112.5, 222, 742.5, 234, 120, 81, 312, 335, 135, 133.5, 118.5, 390, 518, 215, 373.5, 118.5, 195, 111, 205, 94.5, 123, 99, 75.5, 102, 244, 380, 357.5, 254, 227.5, 198, 192.5, 151.5)
brand_rep_spend <- tibble::tibble(spend=spendData)
brand_rep <- file001 %>%
    mutate(poorworkman = 6-poor_workman_r) %>%
    select(-poorworkman)
brand_rep
brand_rep_spend


# Check if brand_rep and brand_rep_spend have the same number of rows
same_rows <- nrow(brand_rep) == nrow(brand_rep_spend)
same_rows

# Append spend column to brand_rep
brand_rep <- cbind(brand_rep, brand_rep_spend)

# Scale the data
brand_rep_scaled <- scale(brand_rep)

# Get summary statistics of scaled dataframe
psych::describe(brand_rep)
psych::describe(brand_rep_scaled)


# Correlate F1, F2 and F3 to spend_f, the 'latentized' spend
brand_rep_model <- 'F1 =~ well_made + consistent + poor_workman_r
F2 =~ higher_price + lot_more + go_up
F3 =~ stands_out + unique
spend_f =~ spend
spend_f ~~ F1 + F2 + F3'

# Fit the model to the data -- sem()
brand_rep_cv <- lavaan::sem(data = brand_rep_scaled, model = brand_rep_model)

# Print the standardized covariances b/w spend_f and other factors
lavaan::standardizedSolution(brand_rep_cv) %>% 
    filter(rhs == "spend_f")

# Plot the model with standardized estimate labels
semPlot::semPaths(brand_rep_cv, whatLabels = "est.std", edge.label.cex = .8)


c_sat <- file003
c_sat_recommend <- tibble::tibble(Rec_1=c(4, 3, 3, 3, 4, 3, 2, 3, 3, 3, 4, 3, 3, 4, 4, 3, 3, 4, 4, 3, 4, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 3, 4, 4, 3, 2, 3, 3, 3, 4, 4, 3, 4, 4, 5, 3, 4, 4, 4, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 2, 3, 3, 4, 4, 3, 4, 3, 3, 4, 3, 3, 3, 1, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 2, 4, 4, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 4, 2, 4, 3, 4, 3, 3, 4, 3, 2, 3, 2, 3, 3, 4, 3, 4, 2, 3, 3, 2, 4, 3, 4, 2, 3, 4, 3, 3, 3, 4, 4, 4, 3, 3, 4, 3, 3, 4, 4, 4, 3, 2, 3, 3, 4, 2, 5, 3, 4, 4, 4, 3, 3, 3, 3, 4, 3, 3, 3, 3, 4, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 3, 3, 3, 3, 4, 2, 4, 3, 3, 3, 3, 4, 4, 4, 3, 3, 3, 2, 4, 4, 3, 3, 3, 4, 3, 3, 4, 4, 3, 3, 5, 4, 4, 3, 4, 2, 4, 4, 4, 4, 3, 4, 3, 3, 3, 2, 3, 3, 3, 4, 3, 3, 4, 5, 4, 4, 3, 4, 4, 3, 3, 4, 4, 3, 4, 3, 4, 4, 4, 1, 4, 3, 4, 3, 3, 3, 4, 3, 5, 4, 3, 3, 4, 3, 4, 3, 3, 3, 3, 4, 2, 3, 4, 3, 4, 3, 4, 4, 4, 3, 3, 3, 5, 3, 3, 4, 3, 3, 4, 4, 4, 4, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 4, 2, 4, 3, 2, 3, 3, 5, 4, 2, 5, 3, 5, 3, 2, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 5, 4, 4, 3, 3, 5, 3, 4, 3, 5, 4, 3, 2, 2))
c_sat
c_sat_recommend


# Bind & scale the variables
c_sat_rec_scale <- c_sat %>% 
    bind_cols(c_sat_recommend) %>% scale()

# Define the model - Rec_f covaries with F1, F2, F3
c_sat_rec_model <- 'F1 =~ CS1 + CS2 + CS3 + CS4
F2 =~ CS5 + CS6 + CS7
F3 =~ CS8 + CS9 + CS10
Rec_f =~ Rec_1
Rec_f ~~ F1 + F2 + F3'

# Fit the model to the data 
c_sat_rec_sem <- lavaan::sem(model = c_sat_rec_model, data = c_sat_rec_scale)

# Look up standardized covariances
lavaan::standardizedSolution(c_sat_rec_sem) %>% 
    filter(rhs == "Rec_f")


# Define the model
b_q_model <- 'HIP =~ trendy + latest + tired_r
            VALUE =~ happy_pay + reason_price + good_deal
            PERFORM =~ strong_perform + leader + serious
            spend ~ HIP + VALUE + PERFORM'

# Fit the model to the data
# b_q_pv <- lavaan::sem(data = b_q_scale, model = b_q_model)

# Check fit, r-square, standardized estimates
# summary(b_q_pv, standardized = TRUE, fit.measures = TRUE, rsquare = TRUE)

# Plot the model -- rotate from left to right
# semPlot::semPaths(b_q_pv, rotation = 2, whatLabels = "est.std", edge.label.cex = 0.8)


# Plot the new model
# semPlot::semPaths(brand_rep_sem, rotation = 2)

# Get the coefficient information
# lavaan::standardizedSolution(brand_rep_sem) %>% filter(op == "~")

# Get the r-squared
# r_squared <- car::inspect(brand_rep_sem, "r2")["F2"]
# r_squared


# Compute factor scores in lavaan -- store as data frame
brand_rep_scores <- as.data.frame(predict(brand_rep_CFA))

# Summary statistics of our factor scores
psych::describe(brand_rep_scores)

# Plot histograms for each variable
psych::multi.hist(brand_rep_scores)

# Are they normally distributed? Check using map()
map(brand_rep_scores, shapiro.test)


# Linear regression of standardized spending and factor scores
# bq_fs_reg <- lm(spend ~ F1 + F2 + F3, data = bq_fs_spend)

# Summarize results, round estimates
# rounded_summary <- round(coef(bq_fs_reg), 3)
# rounded_summary

# Summarize the results of CFA model
# summary(brand_qual_pv)

# Compare the r-squared of each
# inspect_rsq <- car::inspect(brand_qual_pv, "r2")["spend"]
# inspect_rsq
# summary(bq_fs_reg)$r.squared


# Descriptive statistics grouped by 'time'
# psych::describeBy(brand_rep_t1_t2, "time")

# Test retest: time == 1 versus time == 2 by id = "id"
# brand_rep_test_retest <- psych::testRetest(t1 = filter(brand_rep_t1_t2, time == 1), t2 = filter(brand_rep_t1_t2, time == 2), id = "id")

# brand_rep_test_retest$r12


brand_rep <- file001 %>%
    select(-one_of_a_kind)
brand_rep


# Split data into odd and even halves
brand_rep_efa_data <- as.data.frame(brand_rep)[c(TRUE,FALSE),]
brand_rep_cfa_data <- as.data.frame(brand_rep)[c(FALSE,TRUE),]

# Get factor loadings of brand_rep_efa_data EFA
efa <- psych::fa(brand_rep_efa_data, nfactors = 3)
efa$loadings

# Confirm the data that the model was fit to
# car::inspect(brand_rep_cfa, what = "call")

# Check fit measures
# fitmeasures(brand_rep_cfa)[c("cfi", "tli", "rmsea")]

```
  
  
  
