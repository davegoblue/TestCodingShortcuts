---
title: "Open Meteo Weather Exploration"
author: "davegoblue"
date: "2025-08-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background
Open-Meteo maintains an [API for historical weather](https://open-meteo.com/en/docs/historical-weather-api) that allows for non-commercial usage of historical weather data maintained by the website.

This file builds on _v001, _v002, _v003, _v004, and _v005 to run exploratory analysis on some historical weather data.

## Functions and Libraries
The exploration process uses tidyverse, ranger, several generic custom functions, and several functions specific to Open Meteo processing. First, tidyverse, ranger, and the generic functions are loaded:  
```{r}

library(tidyverse) # tidyverse functionality is included throughout
library(ranger) # predict() does not work on ranger objects unless ranger has been called

source("./Generic_Added_Utility_Functions_202105_v001.R") # Basic functions

```
  
Next, specific functions written in _v001, _v002, _v003, _v004, and _v005 are sourced:  
```{r}

source("./SimpleOneVar_Functions_202411_v001.R") # Functions for basic single variable analysis
source("./OpenMeteo_NextBest_202411_v001.R") # Functions for finding 'next best' predictor given existing model
source("./OpenMeteo_Functions_202411_v001.R") # Core functions for loading, processing, analysis of Open Meteo
source("./Generic_Analysis_Functions_202411_v001.R") # Additional functions for random forest and related analysis

```
  
Key mapping tables for available metrics are also copied:  
```{r}

hourlyMetrics <- "temperature_2m,relativehumidity_2m,dewpoint_2m,apparent_temperature,pressure_msl,surface_pressure,precipitation,rain,snowfall,cloudcover,cloudcover_low,cloudcover_mid,cloudcover_high,shortwave_radiation,direct_radiation,direct_normal_irradiance,diffuse_radiation,windspeed_10m,windspeed_100m,winddirection_10m,winddirection_100m,windgusts_10m,et0_fao_evapotranspiration,weathercode,vapor_pressure_deficit,soil_temperature_0_to_7cm,soil_temperature_7_to_28cm,soil_temperature_28_to_100cm,soil_temperature_100_to_255cm,soil_moisture_0_to_7cm,soil_moisture_7_to_28cm,soil_moisture_28_to_100cm,soil_moisture_100_to_255cm"
dailyMetrics <- "weathercode,temperature_2m_max,temperature_2m_min,apparent_temperature_max,apparent_temperature_min,precipitation_sum,rain_sum,snowfall_sum,precipitation_hours,sunrise,sunset,windspeed_10m_max,windgusts_10m_max,winddirection_10m_dominant,shortwave_radiation_sum,et0_fao_evapotranspiration"

hourlyDescription <- "Air temperature at 2 meters above ground\nRelative humidity at 2 meters above ground\nDew point temperature at 2 meters above ground\nApparent temperature is the perceived feels-like temperature combining wind chill factor, relative humidity and solar radiation\nAtmospheric air pressure reduced to mean sea level (msl) or pressure at surface. Typically pressure on mean sea level is used in meteorology. Surface pressure gets lower with increasing elevation.\nAtmospheric air pressure reduced to mean sea level (msl) or pressure at surface. Typically pressure on mean sea level is used in meteorology. Surface pressure gets lower with increasing elevation.\nTotal precipitation (rain, showers, snow) sum of the preceding hour. Data is stored with a 0.1 mm precision. If precipitation data is summed up to monthly sums, there might be small inconsistencies with the total precipitation amount.\nOnly liquid precipitation of the preceding hour including local showers and rain from large scale systems.\nSnowfall amount of the preceding hour in centimeters. For the water equivalent in millimeter, divide by 7. E.g. 7 cm snow = 10 mm precipitation water equivalent\nTotal cloud cover as an area fraction\nLow level clouds and fog up to 2 km altitude\nMid level clouds from 2 to 6 km altitude\nHigh level clouds from 6 km altitude\nShortwave solar radiation as average of the preceding hour. This is equal to the total global horizontal irradiation\nDirect solar radiation as average of the preceding hour on the horizontal plane and the normal plane (perpendicular to the sun)\nDirect solar radiation as average of the preceding hour on the horizontal plane and the normal plane (perpendicular to the sun)\nDiffuse solar radiation as average of the preceding hour\nWind speed at 10 or 100 meters above ground. Wind speed on 10 meters is the standard level.\nWind speed at 10 or 100 meters above ground. Wind speed on 10 meters is the standard level.\nWind direction at 10 or 100 meters above ground\nWind direction at 10 or 100 meters above ground\nGusts at 10 meters above ground of the indicated hour. Wind gusts in CERRA are defined as the maximum wind gusts of the preceding hour. Please consult the ECMWF IFS documentation for more information on how wind gusts are parameterized in weather models.\nET0 Reference Evapotranspiration of a well watered grass field. Based on FAO-56 Penman-Monteith equations ET0 is calculated from temperature, wind speed, humidity and solar radiation. Unlimited soil water is assumed. ET0 is commonly used to estimate the required irrigation for plants.\nWeather condition as a numeric code. Follow WMO weather interpretation codes. See table below for details. Weather code is calculated from cloud cover analysis, precipitation and snowfall. As barely no information about atmospheric stability is available, estimation about thunderstorms is not possible.\nVapor Pressure Deificit (VPD) in kilopascal (kPa). For high VPD (>1.6), water transpiration of plants increases. For low VPD (<0.4), transpiration decreases\nAverage temperature of different soil levels below ground.\nAverage temperature of different soil levels below ground.\nAverage temperature of different soil levels below ground.\nAverage temperature of different soil levels below ground.\nAverage soil water content as volumetric mixing ratio at 0-7, 7-28, 28-100 and 100-255 cm depths.\nAverage soil water content as volumetric mixing ratio at 0-7, 7-28, 28-100 and 100-255 cm depths.\nAverage soil water content as volumetric mixing ratio at 0-7, 7-28, 28-100 and 100-255 cm depths.\nAverage soil water content as volumetric mixing ratio at 0-7, 7-28, 28-100 and 100-255 cm depths."
dailyDescription <- "The most severe weather condition on a given day\nMaximum and minimum daily air temperature at 2 meters above ground\nMaximum and minimum daily air temperature at 2 meters above ground\nMaximum and minimum daily apparent temperature\nMaximum and minimum daily apparent temperature\nSum of daily precipitation (including rain, showers and snowfall)\nSum of daily rain\nSum of daily snowfall\nThe number of hours with rain\nSun rise and set times\nSun rise and set times\nMaximum wind speed and gusts on a day\nMaximum wind speed and gusts on a day\nDominant wind direction\nThe sum of solar radiaion on a given day in Megajoules\nDaily sum of ET0 Reference Evapotranspiration of a well watered grass field"

# Create tibble for hourly metrics
tblMetricsHourly <- tibble::tibble(metric=hourlyMetrics %>% str_split_1(","), 
                                   description=hourlyDescription %>% str_split_1("\n")
                                   )
tblMetricsHourly %>% 
    print(n=50)

# Create tibble for daily metrics
tblMetricsDaily <- tibble::tibble(metric=dailyMetrics %>% str_split_1(","), 
                                  description=dailyDescription %>% str_split_1("\n")
                                   )
tblMetricsDaily

```

A previously existing hourly dataset is loaded, with key analysis variables defined in a vector:  
```{r}

# Load previous data
allCityHourly <- readFromRDS("allCity_20241116")

# Get core training variables
varsTrainHourly <- getVarsTrain(allCityHourly)
varsTrainHourly

# Assign default label
keyLabel <- genericKeyLabelOM()
keyLabel

# Get years of data available
allCityHourly %>% 
    mutate(year=year(date)) %>%
    group_by(src) %>%
    summarize(n=n(), minYear=min(year), maxYear=max(year), minDate=min(date), maxDate=max(date))

```

A daily dataset is created from existing data:  
```{r, fig.height=9, fig.width=9}

omCityMap <- c("bos"="Boston MA", 
               "ord"="Chicago IL", 
               "hou"="Houston TX",
               "lax"="Los Angeles CA", 
               "las"="Las Vegas NV",
               "mia"="Miami FL", 
               "nyc"="New York NY"
               )

allCityDaily <- map_dfr(.x=names(omCityMap), 
                        .f=function(x) omRunAllSteps(dlData=FALSE, runStats=FALSE, abbCity=x, returnDF=TRUE), 
                        .id="src"
                        ) %>%
    mutate(cityName=unname(omCityMap)[as.integer(src)])

allCityDaily %>% 
    mutate(year=year(date)) %>%
    group_by(cityName) %>%
    summarize(n=n(), minYear=min(year), maxYear=max(year), minDate=min(date), maxDate=max(date))

```

Hourly data is updated with city name to match daily data:  
```{r, fig.height=9, fig.width=9}

hourlyCityMap <- c("Boston"="Boston MA", 
                   "Chicago"="Chicago IL", 
                   "Houston"="Houston TX",
                   "LA"="Los Angeles CA", 
                   "Vegas"="Las Vegas NV",
                   "Miami"="Miami FL", 
                   "NYC"="New York NY"
                   )

allCityHourly <- allCityHourly %>%
    mutate(cityName=hourlyCityMap[src]) 

allCityHourly %>%
    group_by(src, cityName) %>%
    summarize(n=n(), minDate=min(date), maxDate=max(date), .groups="drop")

```

Alignment of maximum temperature is explored:  
```{r, fig.height=9, fig.width=9}

maxTDelta <- allCityHourly %>%
    group_by(cityName, date) %>%
    summarize(maxT=max(temperature_2m), .groups="drop") %>%
    filter(year(date)<=2022) %>%
    left_join(select(allCityDaily, cityName, date, temperature_2m_max), by=c("cityName", "date")) %>%
    mutate(delta=maxT-temperature_2m_max)

maxTDelta %>%
    summary()

maxTDelta %>%
    group_by(cityName) %>%
    summarize(pctDiff=mean(abs(delta)>0.01))

```
  
10% of observations in Chicago differ, potentially due to time zone conversions. All other cities align

The differences in Chicago observations are further explored:  
```{r, fig.height=9, fig.width=9}

maxTDelta %>%
    filter(cityName=="Chicago IL") %>%
    mutate(mon=month(date), year=year(date), isDiff=abs(delta)>0.01) %>%
    group_by(year, mon) %>%
    summarize(pctDiff=mean(isDiff), n=n(), .groups="drop") %>%
    ggplot(aes(x=factor(month.abb[mon], levels=month.abb), y=pctDiff, group=1)) + 
    geom_line() + 
    geom_hline(data=~summarize(., yint=sum(n*pctDiff)/sum(n)), aes(yintercept=yint), lty=2) +
    facet_wrap(~year) + 
    labs(x=NULL, y="Proportion mismatched", title="Mismatches between daily and hourly maximum temperature")

```

In general, mismatches seem to be more common in the colder season

A sample of the larger mismatches are explored:  
```{r, fig.height=9, fig.width=9}

tmpDates <- maxTDelta %>%
    filter(cityName=="Chicago IL") %>%
    mutate(mon=month(date), year=year(date), isDiff=abs(delta)>2.5) %>%
    filter(isDiff) %>%
    pull(date)
tmpDates

tmpDF <- allCityHourly %>%
    filter(cityName=="Chicago IL") %>%
    select(cityName, time, date, hour, temperature_2m)

map_dfr(.x=tmpDates, 
        .f=function(x) tmpDF %>% filter(date %in% c(x, x-1, x+1)), 
        .id="src"
        ) %>%
    mutate(src=tmpDates[as.integer(src)], isSame=(src==date)) %>%
    left_join(select(maxTDelta, cityName, src=date, temperature_2m_max), by=c("cityName", "src")) %>%
    ggplot(aes(x=time, y=temperature_2m)) +
    geom_line() + 
    geom_line(aes(y=temperature_2m_max), lty=2) +
    facet_wrap(~src, scales="free") + 
    labs(x=NULL, y="Temperature (C)", title="Hourly temperatures near key disconnect dates")

```

Disconnects appear to arise when the maximum temperature is reached very early and/or very late in the day. This is consistent with time zones potentially driving the differences.

Shading is added for clarity:  
```{r, fig.height=9, fig.width=9}

map_dfr(.x=tmpDates, 
        .f=function(x) tmpDF %>% filter(date %in% c(x, x-1, x+1)), 
        .id="src"
        ) %>%
    mutate(src=tmpDates[as.integer(src)], isSame=(src==date)) %>%
    left_join(select(maxTDelta, cityName, src=date, temperature_2m_max), by=c("cityName", "src")) %>%
    ggplot(aes(x=time, y=temperature_2m)) +
    geom_line() + 
    geom_line(aes(y=temperature_2m_max), lty=2) +
    facet_wrap(~src, scales="free") + 
    labs(x=NULL, 
         y="Temperature (C)", 
         title="Hourly temperatures near key disconnect dates", 
         subtitle="Line is hourly data, shaded region is the 24 hours in the key date", 
         caption="Dotted line is maximum temperature reported in daily data"
         ) +
    geom_tile(data=~filter(., isSame), fill="lightblue", aes(x=time, y=0, height=+Inf), alpha=0.5)

```

Chicago data are shifted by an hour to check whether time zones fully explain the differences:  
```{r, fig.height=9, fig.width=9}

# Run previously
# tmpDF <- allCityHourly %>%
#     filter(cityName=="Chicago IL") %>%
#     select(cityName, time, date, hour, temperature_2m)

tmpDF %>% 
    mutate(newtime=time-hours(1), date=date(newtime)) %>% 
    filter(!(date %in% c(min(date)))) %>% 
    group_by(cityName, date) %>% 
    summarize(maxT=max(temperature_2m), .groups="drop") %>% 
    filter(year(date)<=2022) %>% 
    left_join(select(allCityDaily, cityName, date, temperature_2m_max), by=c("cityName", "date")) %>%
    mutate(delta=maxT-temperature_2m_max) %>% 
    summary()

```

If date is recalculated based on time minus one hour, the Chicago hourly data aligns with the Chicago daily data for maximum temperature

Alignment of precipitation is explored, first with time zones in hourly data "as is":  
```{r, fig.height=9, fig.width=9}

sumPDelta <- allCityHourly %>%
    group_by(cityName, date) %>%
    summarize(sumP=sum(precipitation), .groups="drop") %>%
    filter(year(date)<=2022) %>%
    left_join(select(allCityDaily, cityName, date, precipitation_sum), by=c("cityName", "date")) %>%
    mutate(delta=sumP-precipitation_sum)

sumPDelta %>%
    summary()

sumPDelta %>%
    group_by(cityName) %>%
    summarize(pctDiff=mean(abs(delta)>0.005))

```
  
25% of observations in Chicago differ, likely due to time zone conversions. All other cities align

Chicago data is updated to be one hour earlier:  
```{r, fig.height=9, fig.width=9}

sumPDelta <- allCityHourly %>%
    mutate(date=as.Date(ifelse(cityName %in% c("Chicago IL"), time-hours(1), date))) %>%
    group_by(cityName, date) %>%
    summarize(sumP=sum(precipitation), .groups="drop") %>%
    filter(year(date)<=2022) %>%
    left_join(select(allCityDaily, cityName, date, precipitation_sum), by=c("cityName", "date")) %>%
    mutate(delta=sumP-precipitation_sum)

sumPDelta %>%
    summary()

sumPDelta %>%
    group_by(cityName) %>%
    summarize(pctDiff=mean(abs(delta)>0.005))

```
  
After adjusting for time zone in Chicago, all observations align

The process is generalized in a function that adjusts only Chicago and with other significant hard-coding:  
```{r, fig.height=9, fig.width=9}

tmpDailyVsHourly <- function(fn=sum) {

    df <- allCityHourly %>%
        mutate(date=as.Date(ifelse(cityName %in% c("Chicago IL"), time-hours(1), date))) %>%
        group_by(cityName, date) %>%
        summarize(across(.cols="precipitation", .fns=fn, .names="agg"), .groups="drop") %>%
        filter(year(date)<=2022) %>%
        left_join(select(allCityDaily, all_of(c("cityName", "date", "precipitation_sum"))), 
                         by=c("cityName", "date")
                  ) %>%
        mutate(delta=agg-get("precipitation_sum"))

    df %>%
        summary() %>%
        print()

    df %>%
        group_by(cityName) %>%
        summarize(pctDiff=mean(abs(delta)>0.005)) %>%
        print()
}

tmpDailyVsHourly()

```

