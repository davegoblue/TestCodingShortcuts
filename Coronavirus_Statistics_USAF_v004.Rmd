---
title: "Coronavirus US - USA Facts"
author: "davegoblue"
date: "5/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background
This module builds on code contained in Coronavirus_Statistics_USAF_v003.Rmd.  This file includes the latest code for analyzing data from [USA Facts](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/).  USA Facts maintains data on cases and deaths by county for coronavirus in the US.  Downloaded data are unique by county with date as a column and a separate file for each of cases, deaths, and population.

The intent of this module is to rebuild the function readRunUSAFacts() so that it works with 2021 data as currently formatted by USA Facts.  The code will then be included in appropriate .R modules that can be sourced.

## Sourcing Functions  
The tidyverse library is loaded, and the functions used for CDC daily processing are sourced:  
```{r}

library(tidyverse)

# Functions are available in source file
source("./Generic_Added_Utility_Functions_202105_v001.R")
source("./Coronavirus_CDC_Daily_Functions_v001.R")

```

## Updating Functions  
The current readRunUSAFacts() function is copied:  
```{r eval=FALSE}

# Function to run the USA Facts (US county-level coronavirus data) clustering process
readRunUSAFacts <- function(maxDate, 
                            popLoc, 
                            caseLoc, 
                            deathLoc, 
                            dlPop=FALSE, 
                            dlCaseDeath=FALSE, 
                            ovrWrite=FALSE, 
                            ovrWriteError=TRUE, 
                            oldFile=NULL, 
                            showBurdenMinPop=10000, 
                            minPopCluster=25000,
                            existingStateClusters=NULL, 
                            existingCountyClusters=NULL, 
                            createClusters=FALSE, 
                            hierarchical=FALSE,
                            kCut=6,
                            orderCluster=TRUE,
                            ...
                            ) {
    
    # FUNCTION ARGUMENTS:
    # maxDate: the maximum data to use for data from the cases and deaths file
    # popLoc: location where the county-level population data are stored
    # caseLoc: location where the county-level cases data are stored
    # deathLoc: location where the county-level deaths data are stored
    # dlPop: boolean, should new population data be downloaded to popLoc
    # dlCaseDeath: boolean, should new case data and death data be downloaded to caseLoc and deathLoc
    # ovrWrite: boolean, if data are downloaded to an existing file, should it be over-written
    # ovrWriteError: boolean, if ovrWrite is FALSE and an attempt to overwrite is made, should it error out?
    # oldFile: old file for comparing metrics against (NULL means no old file for comarisons)
    # showBurdenMinPop: minimum population for showing in burden by cluster plots (NULL means skip plot)
    # minPopCluster: minimum population for including county in running cluster-level metrics
    # existingStateClusters: location of an existing named vector with clusters by state (NULL means none)
    # existingCountyClusters: location of an existing named vector with clusters by county (NULL means none)
    #                         if existingStateClusters is not NULL, then existingCountyClusters is ignored
    # createClusters: boolean, whether to create new clusters (only set up for kmeans)
    # hierarchical: whether to create hierarchical clusters
    #               TRUE means run hierarchical clustering
    #               FALSE means run kmeans clustering
    #               NA means run rules-based clustering
    # kCut; if hierarchical clustering is used, what k (number of clusters in cutree) should be used?
    # orderCluster: if FALSE, ignore; if TRUE, order by "dpm"; if anything else, order by orderCluster
    # ...: other arguments that will be passed to prepClusterCounties
    
    # STEP 0: Download new files (if requested)
    urlCase <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv"
    urlDeath <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv"
    urlPop <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_county_population_usafacts.csv"
    
    # Helper function to download a file
    helperDownload <- function(url, loc, ovrWrite=ovrWrite, ovrWriteError=ovrWriteError) {
        # If the file exists, mention it and proceed as per the guard checks
        if (file.exists(loc)) {
            cat("\nFile:", loc, "already exists\n")
            if (!ovrWrite & ovrWriteError) stop("\nExiting due to ovrWrite=FALSE and ovrWriteError=TRUE\n")
            if (!ovrWrite & !ovrWriteError) {
                cat("\nFile is NOT downloaded again\n")
                return(NULL)
            }
        }
        # Download the file and change to read-only
        download.file(url, destfile=loc, method="curl")
        Sys.chmod(loc, mode="0555", use_umask = FALSE)
    }
    
    if (dlPop) helperDownload(urlPop, loc=popLoc)
    if (dlCaseDeath) helperDownload(urlCase, loc=caseLoc)
    if (dlCaseDeath) helperDownload(urlDeath, loc=deathLoc)
    
    # STEP 1: Read in the population file
    pop <- readr::read_csv(popLoc) %>%
        rename(countyName=`County Name`, state=State)
    
    # STEP 2: Read case and death data, combine, and add population totals and existing clusters
    burdenData <- readUSAFacts(
        caseFile=caseLoc, 
        deathFile=deathLoc, 
        countyPopFile=pop,
        oldFile=oldFile,
        showBurdenMinPop=showBurdenMinPop,
        maxDate=maxDate,
        stateClusters=existingStateClusters, 
        countyClusters=existingCountyClusters, 
        glimpseRaw=FALSE
    )
    
    # STEP 3: Create appropriately filtered data, and new clusters if requested
    clusterData <- prepClusterCounties(burdenFile=burdenData, 
                                       maxDate=maxDate, 
                                       minPop=minPopCluster,
                                       createClusters=createClusters, 
                                       hierarchical=hierarchical, 
                                       returnList=TRUE,
                                       ...
    )
    
    # STEP 4: Assess clusters against the new data
    # STEP 4a: Extract the county-level clusters (new clusters if created, existing otherwise)
    if (createClusters) {
        if (is.na(hierarchical)) clustVec <- clusterData$objCluster$objCluster
        else if (hierarchical) clustVec <- cutree(clusterData$objCluster$objCluster, k=kCut)
        else clustVec <- clusterData$objCluster$objCluster$cluster
    }
    else {
        clustVec <- existingCountyClusters
    }
    
    # STEP 4b: Show the cumulative data, order by cluster, and keep the plots together
    helperACC_county <- helperAssessCountyClusters(vecCluster=clustVec, 
                                                   dfPop=clusterData$countyFiltered, 
                                                   dfBurden=clusterData$countyFiltered, 
                                                   showCum=TRUE,
                                                   thruLabel=format(as.Date(maxDate), "%b %d, %Y"), 
                                                   plotsTogether=TRUE, 
                                                   orderCluster=orderCluster
    )
    
    # STEP 5: Add back clusters not used for analysis (code 999) and associated disease data
    # May want to change the approach to population data
    clusterStateData <- helperMakeClusterStateData(dfPlot=helperACC_county, 
                                                   dfPop=usmap::countypop,
                                                   dfBurden=clusterData$countyDailyPerCapita,
                                                   orderCluster=orderCluster
    )
    
    # STEP 6: Return a list of the key files
    list(pop=pop, 
         burdenData=burdenData, 
         clusterData=clusterData, 
         clustVec=clustVec, 
         helperACC_county=helperACC_county, 
         clusterStateData=clusterStateData,
         maxDate=maxDate
    )
    
}

```

The function is updated to make better use of the functional form.  Broadly, the process will include:  
  
* Step 1: Get county-level population data  
* Step 2: Download and QC each requested data element  
* Step 3: Process each requested data element  
* Step 4: Integrate to create a per capita file  
* Step 5: Create clusters  
* Step 6: Assess clusters  
  
The function includes:  
```{r}

# Function to get county-level population data
getCountyData <- function(df=readFromRDS("countyPop2021"), 
                          renameVars=c("State"="state", "County Name"="countyName", "population"="pop"), 
                          keepVars=c("countyFIPS", "countyName", "state", "pop")
                          ) {
    
    # FUNCTION ARGUMENTS:
    # df: the data frame containing state data
    # renameVars: variables to be renamed, using named list with format "originalName"="newName"
    # keepVars: variables to be kept in the final file (NULL means keep all)
    
    # Rename variables where appropriate
    names(df) <- ifelse(is.na(renameVars[names(df)]), names(df), renameVars[names(df)])

    # Keep all variables if keepVars is NULL
    if (is.null(keepVars)) keepVars <- names(df)
    
    # Return file with only key variables kept
    df %>%
        select_at(vars(all_of(keepVars)))
    
}



# Mapping list for combining data elements from raw files
# Mapping for urlType to url
usafMainURL <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/"
urlMapper <- c("cdcDaily"="https://data.cdc.gov/api/views/9mfq-cb36/rows.csv?accessType=DOWNLOAD", 
               "cdcHosp"="https://beta.healthdata.gov/api/views/g62h-syeh/rows.csv?accessType=DOWNLOAD", 
               "usafCase"=paste0(usafMainURL, "covid_confirmed_usafacts.csv"), 
               "usafDeath"=paste0(usafMainURL, "covid_deaths_usafacts.csv"),
               "usafPop"=paste0(usafMainURL, "covid_county_population_usafacts.csv")
               )

# Mapping for urlType to colRenamer(vecRename=...)
renMapper <- list("cdcDaily"=c('submission_date'='date', 'new_case'='new_cases', 
                               'tot_death'='tot_deaths', 'new_death'='new_deaths'
                               ), 
                  "cdcHosp"=c("inpatient_beds_used_covid"="inp", 
                              "total_adult_patients_hospitalized_confirmed_and_suspected_covid"="hosp_adult", 
                              "total_pediatric_patients_hospitalized_confirmed_and_suspected_covid"="hosp_ped"
                              ), 
                  "usafCase"=c("County Name"="countyName", "State"="state"), 
                  "usafDeath"=c("County Name"="countyName", "State"="state"),
                  "default"=c()
                  )



# Function for zero-padding a character string
zeroPad <- function(x, width, side="left", pad="0", convChar=TRUE) {
    stringr::str_pad(if(convChar) as.character(x) else x, width=width, side=side, pad=pad)
}
zeroPad5 <- function(x, ...) zeroPad(x, width=5, ...)
zeroPad2 <- function(x, ...) zeroPad(x, width=2, ...)



# Mapping for urlType to colMutater(selfList=...)
selfListMapper <- list("cdcDaily"=list('date'=lubridate::mdy), 
                       "cdcHosp"=list(), 
                       "usafCase"=list('countyFIPS'=zeroPad5, 'stateFIPS'=zeroPad2), 
                       "usafDeath"=list('countyFIPS'=zeroPad5, 'stateFIPS'=zeroPad2),
                       "default"=list()
                       )

# Mapping for urlType to colMutater(fullList=...)
fullListMapper <- list("cdcDaily"=list(), 
                       "cdcHosp"=list(), 
                       "usafCase"=list(),
                       "usafDeath"=list(),
                       "default"=list()
                       )

# Mapping for urlType to pivotData(pivotBy=...)
pivotMapper <- list("usafCase"=c("countyFIPS", "countyName", "state", "stateFIPS"), 
                    "usafDeath"=c("countyFIPS", "countyName", "state", "stateFIPS")
                    )

# Mapping for urlType to pivotted variable
rawMakeVarMapper <- list("usafCase"=c("cases"), 
                         "usafDeath"=c("deaths")
                         )

# Mapping for urlType to checkUniqueRows(uniqueBy=...)
uqMapper <- list("cdcDaily"=c("state", "date"), 
                 "cdcHosp"=c("state", "date"), 
                 "usafCase"=c("countyFIPS", "stateFIPS", "date"), 
                 "usafDeath"=c("countyFIPS", "stateFIPS", "date")
                 )

# Mapping list for rows to be filtered (typically, states to be kept)
# Formatted as named list per urlType, with name being the field and element being the allowed values
lstFilterMapper <- list("cdcDaily"=list("state"=c(state.abb, "DC")), 
                        "cdcHosp"=list("state"=c(state.abb, "DC"))
                        )

# Mapping list for vector selection in processed data
# Formatted as a named list where the names are urlType and the values are fields to be kept
vecSelectMapper <- list("cdcDaily"=c("date", "state", "tot_cases", "tot_deaths", "new_cases", "new_deaths"), 
                        "cdcHosp"=c("date", "state", "inp", "hosp_adult", "hosp_ped")
                        )

# Mapping file for group_by variable per urlType
checkControlGroupMapper <- list("cdcDaily"="date",
                                "cdcHosp"="date",
                                "usafDeath"="date",
                                "usafCase"="date",
                                "default"=c()
                                )

# Mapping file for numerics to summarize by group_by variable per urlType
checkControlVarsMapper <- list("cdcDaily"=c("new_cases", "new_deaths"),
                               "cdcHosp"=c("inp", "hosp_adult", "hosp_ped"), 
                               "usafDeath"=c("deaths", "new_deaths"), 
                               "usafCase"=c("cases", "new_cases")
                               )

# Mapping for urlType to checkSimilarity(..., keyVars=); universe similarity checks to perform and report
checkSimilarityMapper <- list("cdcDaily"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                              state=list(label='state', countOnly=FALSE)
                                              ), 
                              "cdcHosp"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                             state=list(label='state', countOnly=FALSE)
                                             ), 
                              "usafCase"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                              countyFIPS=list(label='county', countOnly=FALSE)
                                             ), 
                              "usafDeath"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                              countyFIPS=list(label='county', countOnly=FALSE)
                                             ),                               
                              "default"=list()
                              )

# Mapping for urlType to plotSimilarity(..., ); fields where change in universe should be reported
plotSimilarityMapper <- list("cdcDaily"=c("date"), 
                             "cdcHosp"=c("date"), 
                             "usafCase"=c("date"),
                             "usafDeath"=c("date"),
                             "default"=c()
                             )

# Mapping file for aggregated control total checks to perform
# Formatted as one list per urlType
# Within each urlType list, sublists drive the grouping variable, numerical aggregates, and reporting
keyAggMapper <- list("cdcDaily"=list("l1"=list("grpVar"="date",
                                               "numVars"=c("new_cases", "new_deaths",
                                                           "tot_cases", "tot_deaths"
                                               ),
                                               "sameUniverse"=NA,
                                               "plotData"=TRUE,
                                               "isLine"=TRUE,
                                               "returnDelta"=TRUE,
                                               "flagLargeDelta"=TRUE,
                                               "pctTol"=0.05,
                                               "absTol"=5,
                                               "sortBy"=c("name", "pctDelta", "absDelta"),
                                               "dropNA"=TRUE,
                                               "printAll"=TRUE
                                               ),
                                     "l2"=list("grpVar"="state",
                                               "numVars"=c("new_cases", "new_deaths"),
                                               "sameUniverse"=NA,
                                               "plotData"=TRUE,
                                               "isLine"=FALSE,
                                               "returnDelta"=FALSE,
                                               "flagLargeDelta"=FALSE
                                               ),
                                     "l3"=list("grpVar"="state",
                                               "numVars"=c("new_cases", "new_deaths",
                                                           "tot_cases", "tot_deaths"
                                                           ),
                                               "sameUniverse"="date",
                                               "plotData"=TRUE,
                                               "isLine"=FALSE,
                                               "returnDelta"=TRUE,
                                               "flagLargeDelta"=TRUE,
                                               "pctTol"=0.001,
                                               "absTol"=0,
                                               "sortBy"=c("name", "pctDelta", "absDelta"),
                                               "dropNA"=TRUE,
                                               "printAll"=TRUE
                                               )
                                     ),
                     "cdcHosp"=list("l1"=list("grpVar"="date",
                                              "numVars"=c("inp", "hosp_adult", "hosp_ped"),
                                              "sameUniverse"=NA,
                                              "plotData"=TRUE,
                                              "isLine"=TRUE,
                                              "returnDelta"=TRUE,
                                              "flagLargeDelta"=TRUE,
                                              "pctTol"=0.05,
                                              "absTol"=5,
                                              "sortBy"=c("name", "pctDelta", "absDelta"),
                                              "dropNA"=TRUE,
                                              "printAll"=TRUE
                                              ),
                                    "l2"=list("grpVar"="state",
                                              "numVars"=c("inp", "hosp_adult", "hosp_ped"),
                                              "sameUniverse"=NA,
                                              "plotData"=TRUE,
                                              "isLine"=FALSE,
                                              "returnDelta"=FALSE,
                                              "flagLargeDelta"=FALSE
                                              ),
                                    "l3"=list("grpVar"="state",
                                              "numVars"=c("inp", "hosp_adult", "hosp_ped"),
                                              "sameUniverse"="date",
                                              "plotData"=TRUE,
                                              "isLine"=FALSE,
                                              "returnDelta"=TRUE,
                                              "flagLargeDelta"=TRUE,
                                              "pctTol"=0.001,
                                              "absTol"=0,
                                              "sortBy"=c("name", "pctDelta", "absDelta"),
                                              "dropNA"=TRUE,
                                              "printAll"=TRUE
                                              )
                                    ), 
                     "usafDeath"=list("l1"=list("grpVar"="date",
                                                "numVars"=c("deaths", "new_deaths"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=TRUE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.05,
                                                "absTol"=5,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                ),
                                      "l2"=list("grpVar"="state",
                                                "numVars"=c("deaths", "new_deaths"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=FALSE,
                                                "returnDelta"=FALSE,
                                                "flagLargeDelta"=FALSE
                                                ),
                                      "l3"=list("grpVar"=c("countyFIPS", "countyName", "state"),
                                                "numVars"=c("deaths", "new_deaths"),
                                                "sameUniverse"="date",
                                                "plotData"=FALSE,
                                                "isLine"=FALSE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.001,
                                                "absTol"=0,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                )
                                      ), 
                     "usafCase"=list("l1"=list("grpVar"="date",
                                                "numVars"=c("cases", "new_cases"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=TRUE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.05,
                                                "absTol"=5,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                ),
                                      "l2"=list("grpVar"="state",
                                                "numVars"=c("cases", "new_cases"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=FALSE,
                                                "returnDelta"=FALSE,
                                                "flagLargeDelta"=FALSE
                                                ),
                                      "l3"=list("grpVar"=c("countyFIPS", "countyName", "state"),
                                                "numVars"=c("cases", "new_cases"),
                                                "sameUniverse"="date",
                                                "plotData"=FALSE,
                                                "isLine"=FALSE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.001,
                                                "absTol"=0,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                )
                                      )
                     )

# Formatted as one list per urlType, with that list having one list for each combination of data
lstComboMapper <- list("cdcDaily"=list("nyc"=list("comboVar"="state", 
                                                  "uqVars"="date", 
                                                  "vecCombo"=c("NY"="NY", "NYC"="NY"),
                                                  "fn"=specNA(sum)
                                                  )
                                       ), 
                       "cdcHosp"=list()
                       )

# Mapping file for creating per-capita metrics
# Formatted as c('raw variable name'='associated per capita variable name')
perCapMapper <- c("tot_cases"="tcpm", 
                  "tot_deaths"="tdpm", 
                  "new_cases"="cpm", 
                  "new_deaths"="dpm", 
                  "inp"="hpm", 
                  "hosp_adult"="ahpm", 
                  "hosp_ped"="phpm"
                  )



# Function to pivot the data file longer
pivotData <- function(df, 
                      pivotKeys, 
                      nameVar="name", 
                      valVar="value",
                      toLonger=TRUE, 
                      ...
                      ) {
    
    # FUNCTION ARGUMENTS:
    # df: the data frame
    # pivotKeys: the keys (everything but cols for pivot_longer, id_cols for pivot_wider)
    # nameVar: variable name for names_to or names_from
    # valVar: variable name for values_to or values_from
    # toLonger: boolean, should pivot_longer() be used rather than pivot_wider()?
    # ...: other arguments to be passed to pivot_*()

    if (isTRUE(toLonger)) pivot_longer(df, -all_of(pivotKeys), names_to=nameVar, values_to=valVar, ...)
    else pivot_wider(df, all_of(pivotKeys), names_from=all_of(nameVar), values_from=all_of(valVar), ...)
    
}


# Function to read and QC raw USA Facts data
readQCRawUSAF <- function(fileName, 
                          writeLog=NULL,
                          ovrwriteLog=TRUE,
                          dfRef=NULL,
                          urlType=NULL, 
                          url=NULL, 
                          getData=TRUE, 
                          ovrWriteDownload=FALSE, 
                          vecRename=NULL, 
                          selfList=NULL,
                          fullList=NULL,
                          uniqueBy=NULL, 
                          pivotBy=NULL,
                          rawMakeVar=NULL,
                          step3Group=NULL,
                          step3Vals=NULL, 
                          step4KeyVars=NULL, 
                          step5PlotItems=NULL,
                          step6AggregateList=NULL,
                          inferVars=list("url"=urlMapper, 
                                         "vecRename"=renMapper, 
                                         "selfList"=selfListMapper, 
                                         "fullList"=fullListMapper, 
                                         "uniqueBy"=uqMapper, 
                                         "pivotBy"=pivotMapper,
                                         "rawMakeVar"=rawMakeVarMapper,
                                         "step3Group"=checkControlGroupMapper,
                                         "step3Vals"=checkControlVarsMapper,
                                         "step4KeyVars"=checkSimilarityMapper, 
                                         "step5PlotItems"=plotSimilarityMapper,
                                         "step6AggregateList"=keyAggMapper
                                         )
                          ) {
    
    # FUNCtiON ARGUMENTS:
    # fileName: the location where downloaded data either is, or will be, stored
    # writeLog: the external file location for printing (NULL means use the main log stdout)
    # ovrwriteLog: boolean, if using an external log, should it be started from scratch (overwritten)?
    # dfRef: a reference data frame for comparison (either NULL or NA means do not run comparisons)
    # urlType: character vector that can be mapped using urlMapper and keyVarMapper
    # url: direct URL passed as character string
    #      NOTE that if both url and urlType are NULL, no file will be downloaded
    # getData: boolean, should an attempt be made to get new data using urlType or url?
    # ovrWriteDownload: boolean, if fileName already exists, should it be overwritten?
    # vecRename: vector for renaming c('existing name'='new name'), can be any length from 0 to ncol(df)
    #            NULL means infer from urlType, if not available there use c()
    # selfList: list for functions to apply to self, list('variable'=fn) will apply variable=fn(variable)
    #           processed in order, so more than one function can be applied to self
    #           NULL means infer from urlType, if not available in mapping file use list()
    # fullList: list for general functions to be applied, list('new variable'=expression(code))
    #           will create 'new variable' as eval(expression(code))
    #           for now, requires passing an expression
    #           NULL means infer from urlType, use list() if not in mapping file
    # pivotBy: combination of variables that should NOT be pivoted
    # uniqueBy: combination of variables for checking uniqueness of pivoted file
    #           NULL means infer from data, keep as NULL (meaning use-all) if cannot be inferred
    # rawMakeVar: variable name to be used for the numeric data pivoted down from columns
    #           NULL means infer from data, keep as NULL (meaning use-all) if cannot be inferred
    # step3Group: variable to be used as the x-axis (grouping) for step 3 plots
    #             NULL means infer from data
    # step3Vals: values to be plotted on the y-axis for step 3 plots
    #            NULL means infer from data
    # step4KeyVars: list of parameters to be passed as keyVars= in step 4
    #               NULL means infer from urlType
    # step5PlotItems: items to be plotted in step 5
    #                 NULL means infer from urlType
    # step6AggregateList: drives the elements to be passed to compareAggregate() and flagLargeDelta()
    #                     NULL means infer from urlType
    # inferVars: vector of c('variable'='mapper') for inferring parameter values when passed as NULL    
    
    # Step 0a: Use urlType to infer key variables if passed as NULL
    for (vrbl in names(inferVars)) {
        mapper <- inferVars[[vrbl]]
        if (is.null(get(vrbl))) {
            if (urlType %in% names(mapper)) assign(vrbl, mapper[[urlType]])
            else if ("default" %in% names(mapper)) assign(vrbl, mapper[["default"]])
        }
    }

    # Step 1: Download a new file (if requested)
    if (!is.null(url) & isTRUE(getData)) fileDownload(fileName=fileName, url=url, ovrWrite=ovrWriteDownload)
    else cat("\nNo file has been downloaded, will use existing file:", fileName, "\n")

    # Step 2: Read file, rename and mutate variables, confirm uniqueness by expected levels
    dfRaw <- fileRead(fileName) %>% 
        colRenamer(vecRename) %>% 
        colMutater(selfList=selfList, fullList=fullList) %>%
        checkUniqueRows(uniqueBy=pivotBy) %>%
        pivotData(pivotKeys=pivotBy, nameVar="date", valVar=rawMakeVar) %>%
        colMutater(selfList=list("date"=lubridate::mdy)) %>%
        checkUniqueRows(uniqueBy=uniqueBy) %>%
        arrange(across(c(setdiff(uniqueBy, "date"), "date"))) %>%
        group_by(across(setdiff(uniqueBy, "date"))) %>%
        mutate(newBurden=ifelse(row_number()==1, get(rawMakeVar), get(rawMakeVar)-lag(get(rawMakeVar)))) %>%
        ungroup() %>%
        colRenamer(vecRename=c("newBurden"=paste0("new_", rawMakeVar)))
    
    # Step 3: Plot basic control totals for new cases and new deaths by month
    dfRaw %>%
        checkControl(groupBy=step3Group, useVars=step3Vals, printControls=FALSE, na.rm=TRUE) %>%
        helperLinePlot(x=step3Group, y="newValue", facetVar="name", facetScales="free_y", groupColor="name")
    
    # If there is no file for comparison, return the data
    if (is.null(dfRef) | (if(length(dfRef)==1) is.na(dfRef) else FALSE)) return(dfRaw)

    # Step 4b: Check similarity of existing and reference file
    # ovrWriteLog=FALSE since everything should be an append after the opening text line in step 0
    diffRaw <- checkSimilarity(df=dfRaw, 
                               ref=dfRef, 
                               keyVars=step4KeyVars, 
                               writeLog=writeLog, 
                               ovrwriteLog=FALSE
                               )
    
    # Step 5: Plot the similarity checks
    plotSimilarity(diffRaw, plotItems=step5PlotItems)
    
    # Step 6: Plot and report on differences in aggregates
    helperAggMap <- function(x) {
        h1 <- compareAggregate(df=dfRaw, ref=dfRef, grpVar=x$grpVar, numVars=x$numVars, 
                               sameUniverse=x$sameUniverse, plotData=x$plotData, isLine=x$isLine, 
                               returnDelta=x$returnDelta)
        if (isTRUE(x$flagLargeDelta)) {
            h2 <- flagLargeDelta(h1, pctTol=x$pctTol, absTol=x$absTol, sortBy=x$sortBy, 
                                 dropNA=x$dropNA, printAll=x$printAll
            )
            if (is.null(writeLog)) print(h2)
            else {
                cat(nrow(h2), " records", sep="")
                txt <- paste0("\n\n***Differences of at least ", 
                              x$absTol, 
                              " and at least ", 
                              round(100*x$pctTol, 3), "%\n\n"
                )
                printLog(h2, txt=txt, writeLog=writeLog)
            }
        }
    }
    lapply(step6AggregateList, FUN=helperAggMap)
    
    cat("\n\n")

    dfRaw
    
}



# Function to obtain county clusters and return the county clusters vector
getCountyClusters <- function(obj, 
                              hierarchical=FALSE, 
                              kCut=0, 
                              reAssign=list(), 
                              defaultCluster=NULL
                              ) {

    # FUNCTION ARGUMENTS
    # obj: a clustering object returned by clusterCounties()
    # hierarchical: whether the clustering object is based on hierarchical clusters
    #               TRUE means from hierarchical clustering
    #               FALSE means from kmeans clustering
    #               NA means from rules-based clustering
    # kCut; if hierarchical clustering is used, what k (number of clusters in cutree) should be used?
    # reAssign: mapping file to change segments, as list('entity'='other entity cluster to use')
    # defaultCluster: cluster label to be assigned to any county that is not in obj$objCluster
    #                 NULL means do not add these to the clustering vector
    
    # Get the clusters from obj$objCluster
    clust <- getClusters(obj$objCluster, hier=hierarchical, kCut=kCut, reAssign=reAssign)
    
    # Add the defaultCluster label to any county that does not have a cluster label
    if (!is.null(defaultCluster)) {
        ctyAdd <- obj$countyBelow %>% pull(state) %>% unique() %>% sort()
        vecAdd <- rep(defaultCluster, length(ctyAdd)) %>% purrr::set_names(ctyAdd)
        clust <- c(clust, vecAdd)
    }
    
    # Return the cluster vector
    clust
    
}



# Function to take county-level data, prepare for clusterStates, and return resulting outputs
clusterCounties <- function(dfPerCapita, 
                            hierarchical,
                            vecRename=c(),
                            clusterBy=c("state"),
                            arrangeBy=c("date"),
                            burdenMetrics=c("cpm", "dpm"),
                            popVar=c("population"),
                            vecSelect=c(clusterBy, arrangeBy, burdenMetrics, popVar),
                            uniqueBy=c(clusterBy, arrangeBy),
                            minPopCluster=1,
                            returnList=TRUE, 
                            ...
                            ) {
    
    # FUNCTION ARGUMENTS:
    # dfPerCapita: a county-level file with per-capita metrics
    # hierarchical: whether to create hierarchical clusters
    #               TRUE means run hierarchical clustering
    #               FALSE means run kmeans clustering
    #               NA means run rules-based clustering
    # vecRename: renaming of input variables
    # clusterBy: the variable name used for clustering
    # arrangeBy: data will be sorted by this a mix of clusterBy and this variable
    # burdenMetrics: the metrics to be used for burden in clustering
    # popVar: the column containing population data
    # vecSelect: selection of input variables
    # uniqueBy: the input file must be unique by, and will then be sorted by, uniqueBy
    # minPopCluster: minimum population for including county in running cluster-level metrics
    # returnList: boolean, if FALSE just the cluster object is returned
    #                      if TRUE, a list is returned with dfCluster and the cluster object
    # ...: other arguments that will be passed to clusterStates

    # STEP 1: Select and rename variables from the dfPerCapita file
    countyData <- dfPerCapita %>%
        colRenamer(vecRename=vecRename) %>%
        colSelector(vecSelect=vecSelect) %>%
        checkUniqueRows(uniqueBy=uniqueBy, returnDF=TRUE) %>%
        arrange(across(all_of(uniqueBy))) %>%
        mutate(popThresh=(get(popVar)>=minPopCluster)) %>%
        colMutater(selfList=c("state"=as.character))
    
    # STEP 2: Split data based on population threshold
    countyFiltered <- countyData %>% filter(popThresh)
    countyBelow <- countyData %>% filter(!popThresh)
    
    # STEP 2a: Confirm that no county is in both data sets
    count(countyFiltered, a=get(clusterBy), popThresh) %>%
        bind_rows(count(countyBelow, a=get(clusterBy), popThresh)) %>%
        checkUniqueRows(uniqueBy=c("a"), returnDF=FALSE, noteUnique=FALSE)
    
    # STEP 3: Run county-level clusters
    objCluster <- clusterStates(countyFiltered, hierarchical=hierarchical, returnList=returnList, ...)
    
    # Return all of the relevant objects
    list(objCluster=objCluster, 
         countyFiltered=countyFiltered, 
         countyBelow=countyBelow
    )
    
}



# Function to run the USA Facts (US county-level coronavirus data) clustering process
readRunUSAFacts <- function(maxDate, 
                            downloadTo=list("usafCase"=NA, "usafDeath"=NA),
                            readFrom=downloadTo,
                            compareFile=list("usafCase"=NA, "usafDeath"=NA),
                            writeLog=NULL,
                            ovrWriteLog=TRUE,
                            dfPerCapita=NULL,
                            showBurdenMinPop=10000, 
                            minPopCluster=25000,
                            defaultCluster=NULL,
                            existingStateClusters=NULL, 
                            existingCountyClusters=NULL, 
                            createClusters=FALSE, 
                            hierarchical=FALSE,
                            kCut=6,
                            orderCluster=TRUE,
                            reAssignCounty=list(),
                            skipAssessmentPlots=FALSE,
                            brewPalette=NA,
                            ...
                            ) {
    
    # FUNCTION ARGUMENTS:
    # maxDate: the maximum data to use for data from the cases and deaths file
    # downloadTo: named list for locations to download data (usafCase, usafDeath, usafPop)
    #             NA means do not download data for that particular element
    # readFrom: named list for locations to read data from (defaults to donwloadTo)
    # compareFile: named list for the reference file to be used for usafCase, usafDeath, usafPop
    #              NA means do not use a reference file for that element
    # writeLog: name of a separate log file for capturing detailed data on changes between files
    #           NULL means no detailed data captured
    # ovrwriteLog: boolean, should the log file be overwritten and started again from scratch?
    # dfPerCapita: file can be passed directly, which bypasses the loading and processing steps
    #              default NULL means create dfPerCapita using steps 2-4
    # showBurdenMinPop: minimum population for showing in burden by cluster plots (NULL means skip plot)
    # minPopCluster: minimum population for including county in running cluster-level metrics
    # defaultCluster: cluster label to be assigned to any county that falls below minPopCluster
    #                 NULL means do not add these to the clustering vector
    # existingStateClusters: location of an existing named vector with clusters by state (NULL means none)
    # existingCountyClusters: location of an existing named vector with clusters by county (NULL means none)
    #                         if existingStateClusters is not NULL, then existingCountyClusters is ignored
    # createClusters: boolean, whether to create new clusters (only set up for kmeans)
    # hierarchical: whether to create hierarchical clusters
    #               TRUE means run hierarchical clustering
    #               FALSE means run kmeans clustering
    #               NA means run rules-based clustering
    # kCut; if hierarchical clustering is used, what k (number of clusters in cutree) should be used?
    # orderCluster: if FALSE, ignore; if TRUE, order by "dpm"; if anything else, order by orderCluster
    # reAssignCounty: mapping file for assigning a county to another county's cluster
    #                format list("countyToChange"="countyClusterToAssign")
    # skipAssessmentPlots: boolean, should cluster assessment plots be skipped?
    # brewPalette: character vector length-1 referencing a color scheme from brewer_pal to use
    #              NA means use R default color schemes
    # ...: other arguments that will be passed to prepClusterCounties

    # STEP 1: Get a county-level population file
    countyData <- getCountyData()

    # If a log file is requested, create the log file (allows for append=TRUE for all downstream functions)
    if (!is.null(writeLog)) genNewLog(writeLog=writeLog, ovrwriteLog=ovrwriteLog)
    
    # Get the data types to be used (elements of readFrom) and create a file storage list
    elemUsed <- names(readFrom)
    dfRawList <- vector("list", length=length(elemUsed)) %>% purrr::set_names(elemUsed)
    dfProcessList <- vector("list", length=length(elemUsed)) %>% purrr::set_names(elemUsed)
    
    # Steps 2-4 are required only if dfPerCapita has not been passed
    if (is.null(dfPerCapita)) {
    
        # STEP 2: Download and QC each requested data element
        for (elem in elemUsed) {
            # dfRawList[[elem]] <- readQCRawCDCDaily(fileName=readFrom[[elem]], 
            #                                        writeLog=writeLog, 
            #                                        ovrwriteLog=FALSE,
            #                                        urlType=elem, 
            #                                        getData=if(is.na(downloadTo[[elem]])) FALSE else TRUE, 
            #                                        dfRef=compareFile[[elem]]
            #                                        )
            # glimpseLog(dfRawList[[elem]], txt=paste0("\nRaw file for ", elem, ":\n"), logFile=writeLog)
        }
    
        # STEP 3: Process all requested data
        for (elem in elemUsed) {
            # dfProcessList[[elem]] <- processRawFile(dfRawList[[elem]], 
            #                                         vecRename=c(), # already handled in readQCRawCDCDaily()
            #                                         vecSelect=vecSelectMapper[[elem]], 
            #                                         lstCombo=lstComboMapper[[elem]], 
            #                                         lstFilter=lstFilterMapper[[elem]]
            #                                         )
            # glimpseLog(dfProcessList[[elem]], txt=paste0("\nProcessed for ", elem, ":\n"), logFile=writeLog)
        }
    
        # STEP 4: Integrate to create a per-capita data file
        # dfPerCapita <- createPerCapita(dfProcessList, 
        #                                uqBy=c("state", "date"), 
        #                                popData=stateData, 
        #                                mapper=perCapMapper
        #                                )
        # glimpseLog(dfPerCapita, txt="\nIntegrated per capita data file:\n", logFile=writeLog)
    
    } else {
        dfRawList <- NULL
        dfProcessList <- NULL
    }

    # STEP 5: Create clusters (if requested)
    if (isTRUE(createClusters)) {
        clData <- clusterCounties(dfPerCapita=dfPerCapita, 
                                  hierarchical=hierarchical, 
                                  minPopCluster=minPopCluster,
                                  ...
                                  )
        useClusters <- getCountyClusters(clData, 
                                         hier=hierarchical, 
                                         kCut=kCut, 
                                         reAssign=reAssignCounty, 
                                         defaultCluster=defaultCluster
                                         )
    }
    
    # STEP 6: Assess clusters
    
    # Temporary return statement, since code below has not yet been modified
    return(countyData)
    
    # STEP 2: Read case and death data, combine, and add population totals and existing clusters
    burdenData <- readUSAFacts(
        caseFile=caseLoc, 
        deathFile=deathLoc, 
        countyPopFile=pop,
        oldFile=oldFile,
        showBurdenMinPop=showBurdenMinPop,
        maxDate=maxDate,
        stateClusters=existingStateClusters, 
        countyClusters=existingCountyClusters, 
        glimpseRaw=FALSE
    )
    
    # STEP 3: Create appropriately filtered data, and new clusters if requested
    clusterData <- prepClusterCounties(burdenFile=burdenData, 
                                       maxDate=maxDate, 
                                       minPop=minPopCluster,
                                       createClusters=createClusters, 
                                       hierarchical=hierarchical, 
                                       returnList=TRUE,
                                       ...
    )
    
    # STEP 4: Assess clusters against the new data
    # STEP 4a: Extract the county-level clusters (new clusters if created, existing otherwise)
    if (createClusters) {
        if (is.na(hierarchical)) clustVec <- clusterData$objCluster$objCluster
        else if (hierarchical) clustVec <- cutree(clusterData$objCluster$objCluster, k=kCut)
        else clustVec <- clusterData$objCluster$objCluster$cluster
    }
    else {
        clustVec <- existingCountyClusters
    }
    
    # STEP 4b: Show the cumulative data, order by cluster, and keep the plots together
    helperACC_county <- helperAssessCountyClusters(vecCluster=clustVec, 
                                                   dfPop=clusterData$countyFiltered, 
                                                   dfBurden=clusterData$countyFiltered, 
                                                   showCum=TRUE,
                                                   thruLabel=format(as.Date(maxDate), "%b %d, %Y"), 
                                                   plotsTogether=TRUE, 
                                                   orderCluster=orderCluster
    )
    
    # STEP 5: Add back clusters not used for analysis (code 999) and associated disease data
    # May want to change the approach to population data
    clusterStateData <- helperMakeClusterStateData(dfPlot=helperACC_county, 
                                                   dfPop=usmap::countypop,
                                                   dfBurden=clusterData$countyDailyPerCapita,
                                                   orderCluster=orderCluster
    )
    
    # STEP 6: Return a list of the key files
    list(pop=pop, 
         burdenData=burdenData, 
         clusterData=clusterData, 
         clustVec=clustVec, 
         helperACC_county=helperACC_county, 
         clusterStateData=clusterStateData,
         maxDate=maxDate
    )
    
}

```

The function is tested as it evolves:  
```{r, fig.height=9, fig.width=9}

readRunUSAFacts(maxDate="2021-05-27")

testCluster <- clusterCounties(dfPerCapita=readFromRDS("cty_20201026")$clusterData$countyDailyPerCapita, 
                               minPopCluster=25000, 
                               hierarchical=NA,
                               minShape="2020-04",
                               maxShape="2020-09",
                               ratioDeathvsCase = 0.001,
                               ratioTotalvsShape = 0.25,
                               minDeath=100,
                               minCase=5000, 
                               hmlSegs=3, 
                               eslSegs=3, 
                               seed=2010261358
                               )
table(testCluster$objCluster$objCluster, readFromRDS("cty_20201026")$clustVec)
identical(names(testCluster$objCluster$objCluster), names(readFromRDS("cty_20201026")$clustVec))

vecTestCluster_001 <- getCountyClusters(testCluster, hierarchical=NA, defaultCluster="999")
vecTestCluster_002 <- getCountyClusters(testCluster, hierarchical=NA)
usmap::plot_usmap(regions="counties", 
                  data=vecToTibble(vecTestCluster_001, colNameName="fips"), 
                  values="value"
                  )
usmap::plot_usmap(regions="counties", 
                  data=vecToTibble(vecTestCluster_002, colNameName="fips") %>% mutate(value=factor(value)), 
                  values="value"
                  )

testDFRefDeath <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20200917.csv", 
                                getData=FALSE, 
                                urlType="usafDeath"
                                )
usafDeathTest <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20210104.csv", 
                               getData=FALSE, 
                               urlType="usafDeath", 
                               dfRef=testDFRefDeath
                               )

testDFRefCase <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20200917.csv", 
                                getData=FALSE, 
                                urlType="usafCase"
                                )
usafCaseTest <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20210104.csv", 
                              getData=FALSE, 
                              urlType="usafCase", 
                              dfRef=testDFRefCase
                              )

```

* The function completes step 1, reading and formatting the county population data file  
* The clustering function works the same as previous, provided a properly formatted per capita data file  
* The function to create a cluster vector works on data returned by the clustering function  
* The function to read and QC an existing downloaded file, with comparison to previous, is included  
  
