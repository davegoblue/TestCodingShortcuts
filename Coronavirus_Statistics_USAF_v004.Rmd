---
title: "Coronavirus US - USA Facts"
author: "davegoblue"
date: "5/29/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background
This module builds on code contained in Coronavirus_Statistics_USAF_v003.Rmd.  This file includes the latest code for analyzing data from [USA Facts](https://usafacts.org/visualizations/coronavirus-covid-19-spread-map/).  USA Facts maintains data on cases and deaths by county for coronavirus in the US.  Downloaded data are unique by county with date as a column and a separate file for each of cases, deaths, and population.

The intent of this module is to rebuild the function readRunUSAFacts() so that it works with 2021 data as currently formatted by USA Facts.  The code will then be included in appropriate .R modules that can be sourced.

## Sourcing Functions  
The tidyverse library is loaded, and the functions used for CDC daily processing are sourced:  
```{r}

library(tidyverse)

# Functions are available in source file
source("./Generic_Added_Utility_Functions_202105_v001.R")
source("./Coronavirus_CDC_Daily_Functions_v001.R")

```

## Updating Functions  
The current readRunUSAFacts() function is copied:  
```{r eval=FALSE}

# Function to run the USA Facts (US county-level coronavirus data) clustering process
readRunUSAFacts <- function(maxDate, 
                            popLoc, 
                            caseLoc, 
                            deathLoc, 
                            dlPop=FALSE, 
                            dlCaseDeath=FALSE, 
                            ovrWrite=FALSE, 
                            ovrWriteError=TRUE, 
                            oldFile=NULL, 
                            showBurdenMinPop=10000, 
                            minPopCluster=25000,
                            existingStateClusters=NULL, 
                            existingCountyClusters=NULL, 
                            createClusters=FALSE, 
                            hierarchical=FALSE,
                            kCut=6,
                            orderCluster=TRUE,
                            ...
                            ) {
    
    # FUNCTION ARGUMENTS:
    # maxDate: the maximum data to use for data from the cases and deaths file
    # popLoc: location where the county-level population data are stored
    # caseLoc: location where the county-level cases data are stored
    # deathLoc: location where the county-level deaths data are stored
    # dlPop: boolean, should new population data be downloaded to popLoc
    # dlCaseDeath: boolean, should new case data and death data be downloaded to caseLoc and deathLoc
    # ovrWrite: boolean, if data are downloaded to an existing file, should it be over-written
    # ovrWriteError: boolean, if ovrWrite is FALSE and an attempt to overwrite is made, should it error out?
    # oldFile: old file for comparing metrics against (NULL means no old file for comarisons)
    # showBurdenMinPop: minimum population for showing in burden by cluster plots (NULL means skip plot)
    # minPopCluster: minimum population for including county in running cluster-level metrics
    # existingStateClusters: location of an existing named vector with clusters by state (NULL means none)
    # existingCountyClusters: location of an existing named vector with clusters by county (NULL means none)
    #                         if existingStateClusters is not NULL, then existingCountyClusters is ignored
    # createClusters: boolean, whether to create new clusters (only set up for kmeans)
    # hierarchical: whether to create hierarchical clusters
    #               TRUE means run hierarchical clustering
    #               FALSE means run kmeans clustering
    #               NA means run rules-based clustering
    # kCut; if hierarchical clustering is used, what k (number of clusters in cutree) should be used?
    # orderCluster: if FALSE, ignore; if TRUE, order by "dpm"; if anything else, order by orderCluster
    # ...: other arguments that will be passed to prepClusterCounties
    
    # STEP 0: Download new files (if requested)
    urlCase <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv"
    urlDeath <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv"
    urlPop <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_county_population_usafacts.csv"
    
    # Helper function to download a file
    helperDownload <- function(url, loc, ovrWrite=ovrWrite, ovrWriteError=ovrWriteError) {
        # If the file exists, mention it and proceed as per the guard checks
        if (file.exists(loc)) {
            cat("\nFile:", loc, "already exists\n")
            if (!ovrWrite & ovrWriteError) stop("\nExiting due to ovrWrite=FALSE and ovrWriteError=TRUE\n")
            if (!ovrWrite & !ovrWriteError) {
                cat("\nFile is NOT downloaded again\n")
                return(NULL)
            }
        }
        # Download the file and change to read-only
        download.file(url, destfile=loc, method="curl")
        Sys.chmod(loc, mode="0555", use_umask = FALSE)
    }
    
    if (dlPop) helperDownload(urlPop, loc=popLoc)
    if (dlCaseDeath) helperDownload(urlCase, loc=caseLoc)
    if (dlCaseDeath) helperDownload(urlDeath, loc=deathLoc)
    
    # STEP 1: Read in the population file
    pop <- readr::read_csv(popLoc) %>%
        rename(countyName=`County Name`, state=State)
    
    # STEP 2: Read case and death data, combine, and add population totals and existing clusters
    burdenData <- readUSAFacts(
        caseFile=caseLoc, 
        deathFile=deathLoc, 
        countyPopFile=pop,
        oldFile=oldFile,
        showBurdenMinPop=showBurdenMinPop,
        maxDate=maxDate,
        stateClusters=existingStateClusters, 
        countyClusters=existingCountyClusters, 
        glimpseRaw=FALSE
    )
    
    # STEP 3: Create appropriately filtered data, and new clusters if requested
    clusterData <- prepClusterCounties(burdenFile=burdenData, 
                                       maxDate=maxDate, 
                                       minPop=minPopCluster,
                                       createClusters=createClusters, 
                                       hierarchical=hierarchical, 
                                       returnList=TRUE,
                                       ...
    )
    
    # STEP 4: Assess clusters against the new data
    # STEP 4a: Extract the county-level clusters (new clusters if created, existing otherwise)
    if (createClusters) {
        if (is.na(hierarchical)) clustVec <- clusterData$objCluster$objCluster
        else if (hierarchical) clustVec <- cutree(clusterData$objCluster$objCluster, k=kCut)
        else clustVec <- clusterData$objCluster$objCluster$cluster
    }
    else {
        clustVec <- existingCountyClusters
    }
    
    # STEP 4b: Show the cumulative data, order by cluster, and keep the plots together
    helperACC_county <- helperAssessCountyClusters(vecCluster=clustVec, 
                                                   dfPop=clusterData$countyFiltered, 
                                                   dfBurden=clusterData$countyFiltered, 
                                                   showCum=TRUE,
                                                   thruLabel=format(as.Date(maxDate), "%b %d, %Y"), 
                                                   plotsTogether=TRUE, 
                                                   orderCluster=orderCluster
    )
    
    # STEP 5: Add back clusters not used for analysis (code 999) and associated disease data
    # May want to change the approach to population data
    clusterStateData <- helperMakeClusterStateData(dfPlot=helperACC_county, 
                                                   dfPop=usmap::countypop,
                                                   dfBurden=clusterData$countyDailyPerCapita,
                                                   orderCluster=orderCluster
    )
    
    # STEP 6: Return a list of the key files
    list(pop=pop, 
         burdenData=burdenData, 
         clusterData=clusterData, 
         clustVec=clustVec, 
         helperACC_county=helperACC_county, 
         clusterStateData=clusterStateData,
         maxDate=maxDate
    )
    
}

```

The function is updated to make better use of the functional form.  Broadly, the process will include:  
  
* Step 1: Get county-level population data  
* Step 2: Download and QC each requested data element  
* Step 3: Process each requested data element  
* Step 4: Integrate to create a per capita file  
* Step 5: Create clusters  
* Step 6: Assess clusters  
  
The function includes:  
```{r}

# Function to get county-level population data
getCountyData <- function(df=readFromRDS("countyPop2021"), 
                          renameVars=c("State"="state", "County Name"="countyName", "population"="pop"), 
                          keepVars=c("countyFIPS", "countyName", "state", "pop"), 
                          selfList=list(),
                          fullList=list(), 
                          lstFilter=list(), 
                          lstExclude=list()
                          ) {
    
    # FUNCTION ARGUMENTS:
    # df: the data frame containing state data
    # renameVars: variables to be renamed, using named list with format "originalName"="newName"
    # keepVars: variables to be kept in the final file (NULL means keep all)
    # selfList: list for functions to apply to self, list('variable'=fn) will apply variable=fn(variable)
    #           processed in order, so more than one function can be applied to self
    # fullList: list for general functions to be applied, list('new variable'=expression(code))
    #           will create 'new variable' as eval(expression(code))
    #           for now, requires passing an expression
    # lstFilter: a list for filtering records, of form list("field"=c("allowed values"))
    # lstExclude: a list for filtering records, of form list("field"=c("disallowed values"))
    
    # Read the file, rename and keep variables, apply functions as appropriate
    df %>%
        colRenamer(vecRename=renameVars) %>%
        colSelector(vecSelect=keepVars) %>%
        colMutater(selfList=selfList, fullList=fullList) %>%
        rowFilter(lstFilter=lstFilter, lstExclude=lstExclude)

}



# Mapping list for combining data elements from raw files
# Mapping for urlType to url
usafMainURL <- "https://usafactsstatic.blob.core.windows.net/public/data/covid-19/"
urlMapper <- c("cdcDaily"="https://data.cdc.gov/api/views/9mfq-cb36/rows.csv?accessType=DOWNLOAD", 
               "cdcHosp"="https://beta.healthdata.gov/api/views/g62h-syeh/rows.csv?accessType=DOWNLOAD", 
               "usafCase"=paste0(usafMainURL, "covid_confirmed_usafacts.csv"), 
               "usafDeath"=paste0(usafMainURL, "covid_deaths_usafacts.csv"),
               "usafPop"=paste0(usafMainURL, "covid_county_population_usafacts.csv")
               )

# Mapping for urlType to colRenamer(vecRename=...)
renMapper <- list("cdcDaily"=c('submission_date'='date', 'new_case'='new_cases', 
                               'tot_death'='tot_deaths', 'new_death'='new_deaths'
                               ), 
                  "cdcHosp"=c("inpatient_beds_used_covid"="inp", 
                              "total_adult_patients_hospitalized_confirmed_and_suspected_covid"="hosp_adult", 
                              "total_pediatric_patients_hospitalized_confirmed_and_suspected_covid"="hosp_ped"
                              ), 
                  "usafCase"=c("County Name"="countyName", "State"="state"), 
                  "usafDeath"=c("County Name"="countyName", "State"="state"),
                  "default"=c()
                  )



# Function for zero-padding a character string
zeroPad <- function(x, width, side="left", pad="0", convChar=TRUE) {
    stringr::str_pad(if(convChar) as.character(x) else x, width=width, side=side, pad=pad)
}
zeroPad5 <- function(x, ...) zeroPad(x, width=5, ...)
zeroPad2 <- function(x, ...) zeroPad(x, width=2, ...)



# Mapping for urlType to colMutater(selfList=...)
selfListMapper <- list("cdcDaily"=list('date'=lubridate::mdy), 
                       "cdcHosp"=list(), 
                       "usafCase"=list('countyFIPS'=zeroPad5, 'stateFIPS'=zeroPad2), 
                       "usafDeath"=list('countyFIPS'=zeroPad5, 'stateFIPS'=zeroPad2),
                       "default"=list()
                       )

# Mapping for urlType to colMutater(fullList=...)
fullListMapper <- list("cdcDaily"=list(), 
                       "cdcHosp"=list(), 
                       "usafCase"=list(),
                       "usafDeath"=list(),
                       "default"=list()
                       )

# Mapping for urlType to pivotData(pivotBy=...)
pivotMapper <- list("usafCase"=c("countyFIPS", "countyName", "state", "stateFIPS"), 
                    "usafDeath"=c("countyFIPS", "countyName", "state", "stateFIPS")
                    )

# Mapping for urlType to pivotted variable
rawMakeVarMapper <- list("usafCase"=c("cases"), 
                         "usafDeath"=c("deaths")
                         )

# Mapping for urlType to checkUniqueRows(uniqueBy=...)
uqMapper <- list("cdcDaily"=c("state", "date"), 
                 "cdcHosp"=c("state", "date"), 
                 "usafCase"=c("countyFIPS", "stateFIPS", "date"), 
                 "usafDeath"=c("countyFIPS", "stateFIPS", "date")
                 )

# Mapping list for rows to be filtered (typically, states to be kept)
# Formatted as named list per urlType, with name being the field and element being the allowed values
lstFilterMapper <- list("cdcDaily"=list("state"=c(state.abb, "DC")), 
                        "cdcHosp"=list("state"=c(state.abb, "DC")), 
                        "usafCase"=list(), 
                        "usafDeath"=list()
                        )

# Mapping list for rows to be filtered out (typically, unallocated counties to be deleted)
# Formatted as named list per urlType, with name being the field and element being the disallowed values
lstExcludeMapper <- list("cdcDaily"=list(), 
                        "cdcHosp"=list(), 
                        "usafCase"=list("countyFIPS"=c("00000", "00001")), 
                        "usafDeath"=list("countyFIPS"=c("00000", "00001"))
                        )

# Mapping list for vector selection in processed data
# Formatted as a named list where the names are urlType and the values are fields to be kept
vecSelectMapper <- list("cdcDaily"=c("date", "state", "tot_cases", "tot_deaths", "new_cases", "new_deaths"), 
                        "cdcHosp"=c("date", "state", "inp", "hosp_adult", "hosp_ped"), 
                        "usafCase"=c("countyFIPS", "state", "date", "cases", "new_cases"), 
                        "usafDeath"=c("countyFIPS", "state", "date", "deaths", "new_deaths")
                        )

# Mapping file for group_by variable per urlType
checkControlGroupMapper <- list("cdcDaily"="date",
                                "cdcHosp"="date",
                                "usafDeath"="date",
                                "usafCase"="date",
                                "default"=c()
                                )

# Mapping file for numerics to summarize by group_by variable per urlType
checkControlVarsMapper <- list("cdcDaily"=c("new_cases", "new_deaths"),
                               "cdcHosp"=c("inp", "hosp_adult", "hosp_ped"), 
                               "usafDeath"=c("deaths", "new_deaths"), 
                               "usafCase"=c("cases", "new_cases")
                               )

# Mapping for urlType to checkSimilarity(..., keyVars=); universe similarity checks to perform and report
checkSimilarityMapper <- list("cdcDaily"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                              state=list(label='state', countOnly=FALSE)
                                              ), 
                              "cdcHosp"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                             state=list(label='state', countOnly=FALSE)
                                             ), 
                              "usafCase"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                              countyFIPS=list(label='county', countOnly=FALSE)
                                             ), 
                              "usafDeath"=list(date=list(label='date', countOnly=TRUE, convChar=TRUE), 
                                              countyFIPS=list(label='county', countOnly=FALSE)
                                             ),                               
                              "default"=list()
                              )

# Mapping for urlType to plotSimilarity(..., ); fields where change in universe should be reported
plotSimilarityMapper <- list("cdcDaily"=c("date"), 
                             "cdcHosp"=c("date"), 
                             "usafCase"=c("date"),
                             "usafDeath"=c("date"),
                             "default"=c()
                             )

# Mapping file for aggregated control total checks to perform
# Formatted as one list per urlType
# Within each urlType list, sublists drive the grouping variable, numerical aggregates, and reporting
keyAggMapper <- list("cdcDaily"=list("l1"=list("grpVar"="date",
                                               "numVars"=c("new_cases", "new_deaths",
                                                           "tot_cases", "tot_deaths"
                                               ),
                                               "sameUniverse"=NA,
                                               "plotData"=TRUE,
                                               "isLine"=TRUE,
                                               "returnDelta"=TRUE,
                                               "flagLargeDelta"=TRUE,
                                               "pctTol"=0.05,
                                               "absTol"=5,
                                               "sortBy"=c("name", "pctDelta", "absDelta"),
                                               "dropNA"=TRUE,
                                               "printAll"=TRUE
                                               ),
                                     "l2"=list("grpVar"="state",
                                               "numVars"=c("new_cases", "new_deaths"),
                                               "sameUniverse"=NA,
                                               "plotData"=TRUE,
                                               "isLine"=FALSE,
                                               "returnDelta"=FALSE,
                                               "flagLargeDelta"=FALSE
                                               ),
                                     "l3"=list("grpVar"="state",
                                               "numVars"=c("new_cases", "new_deaths",
                                                           "tot_cases", "tot_deaths"
                                                           ),
                                               "sameUniverse"="date",
                                               "plotData"=TRUE,
                                               "isLine"=FALSE,
                                               "returnDelta"=TRUE,
                                               "flagLargeDelta"=TRUE,
                                               "pctTol"=0.001,
                                               "absTol"=0,
                                               "sortBy"=c("name", "pctDelta", "absDelta"),
                                               "dropNA"=TRUE,
                                               "printAll"=TRUE
                                               )
                                     ),
                     "cdcHosp"=list("l1"=list("grpVar"="date",
                                              "numVars"=c("inp", "hosp_adult", "hosp_ped"),
                                              "sameUniverse"=NA,
                                              "plotData"=TRUE,
                                              "isLine"=TRUE,
                                              "returnDelta"=TRUE,
                                              "flagLargeDelta"=TRUE,
                                              "pctTol"=0.05,
                                              "absTol"=5,
                                              "sortBy"=c("name", "pctDelta", "absDelta"),
                                              "dropNA"=TRUE,
                                              "printAll"=TRUE
                                              ),
                                    "l2"=list("grpVar"="state",
                                              "numVars"=c("inp", "hosp_adult", "hosp_ped"),
                                              "sameUniverse"=NA,
                                              "plotData"=TRUE,
                                              "isLine"=FALSE,
                                              "returnDelta"=FALSE,
                                              "flagLargeDelta"=FALSE
                                              ),
                                    "l3"=list("grpVar"="state",
                                              "numVars"=c("inp", "hosp_adult", "hosp_ped"),
                                              "sameUniverse"="date",
                                              "plotData"=TRUE,
                                              "isLine"=FALSE,
                                              "returnDelta"=TRUE,
                                              "flagLargeDelta"=TRUE,
                                              "pctTol"=0.001,
                                              "absTol"=0,
                                              "sortBy"=c("name", "pctDelta", "absDelta"),
                                              "dropNA"=TRUE,
                                              "printAll"=TRUE
                                              )
                                    ), 
                     "usafDeath"=list("l1"=list("grpVar"="date",
                                                "numVars"=c("deaths", "new_deaths"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=TRUE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.05,
                                                "absTol"=5,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                ),
                                      "l2"=list("grpVar"="state",
                                                "numVars"=c("deaths", "new_deaths"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=FALSE,
                                                "returnDelta"=FALSE,
                                                "flagLargeDelta"=FALSE
                                                ),
                                      "l3"=list("grpVar"=c("countyFIPS", "countyName", "state"),
                                                "numVars"=c("deaths", "new_deaths"),
                                                "sameUniverse"="date",
                                                "plotData"=FALSE,
                                                "isLine"=FALSE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.001,
                                                "absTol"=0,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                )
                                      ), 
                     "usafCase"=list("l1"=list("grpVar"="date",
                                                "numVars"=c("cases", "new_cases"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=TRUE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.05,
                                                "absTol"=5,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                ),
                                      "l2"=list("grpVar"="state",
                                                "numVars"=c("cases", "new_cases"),
                                                "sameUniverse"=NA,
                                                "plotData"=TRUE,
                                                "isLine"=FALSE,
                                                "returnDelta"=FALSE,
                                                "flagLargeDelta"=FALSE
                                                ),
                                      "l3"=list("grpVar"=c("countyFIPS", "countyName", "state"),
                                                "numVars"=c("cases", "new_cases"),
                                                "sameUniverse"="date",
                                                "plotData"=FALSE,
                                                "isLine"=FALSE,
                                                "returnDelta"=TRUE,
                                                "flagLargeDelta"=TRUE,
                                                "pctTol"=0.001,
                                                "absTol"=0,
                                                "sortBy"=c("name", "pctDelta", "absDelta"),
                                                "dropNA"=TRUE,
                                                "printAll"=TRUE
                                                )
                                      )
                     )

# Formatted as one list per urlType, with that list having one list for each combination of data
lstComboMapper <- list("cdcDaily"=list("nyc"=list("comboVar"="state", 
                                                  "uqVars"="date", 
                                                  "vecCombo"=c("NY"="NY", "NYC"="NY"),
                                                  "fn"=specNA(sum)
                                                  )
                                       ), 
                       "cdcHosp"=list()
                       )

# Mapping file for creating per-capita metrics
# Formatted as c('raw variable name'='associated per capita variable name')
perCapMapper <- c("tot_cases"="tcpm", 
                  "tot_deaths"="tdpm",
                  "cases"="tcpm", 
                  "deaths"="tdpm",
                  "new_cases"="cpm", 
                  "new_deaths"="dpm", 
                  "inp"="hpm", 
                  "hosp_adult"="ahpm", 
                  "hosp_ped"="phpm"
                  )



# Function to pivot the data file longer
pivotData <- function(df, 
                      pivotKeys, 
                      nameVar="name", 
                      valVar="value",
                      toLonger=TRUE, 
                      ...
                      ) {
    
    # FUNCTION ARGUMENTS:
    # df: the data frame
    # pivotKeys: the keys (everything but cols for pivot_longer, id_cols for pivot_wider)
    # nameVar: variable name for names_to or names_from
    # valVar: variable name for values_to or values_from
    # toLonger: boolean, should pivot_longer() be used rather than pivot_wider()?
    # ...: other arguments to be passed to pivot_*()

    if (isTRUE(toLonger)) pivot_longer(df, -all_of(pivotKeys), names_to=nameVar, values_to=valVar, ...)
    else pivot_wider(df, all_of(pivotKeys), names_from=all_of(nameVar), values_from=all_of(valVar), ...)
    
}


# Function to read and QC raw USA Facts data
readQCRawUSAF <- function(fileName, 
                          writeLog=NULL,
                          ovrwriteLog=TRUE,
                          dfRef=NULL,
                          urlType=NULL, 
                          url=NULL, 
                          getData=TRUE, 
                          ovrWriteDownload=FALSE, 
                          vecRename=NULL, 
                          selfList=NULL,
                          fullList=NULL,
                          uniqueBy=NULL, 
                          pivotBy=NULL,
                          rawMakeVar=NULL,
                          step3Group=NULL,
                          step3Vals=NULL, 
                          step4KeyVars=NULL, 
                          step5PlotItems=NULL,
                          step6AggregateList=NULL,
                          inferVars=list("url"=urlMapper, 
                                         "vecRename"=renMapper, 
                                         "selfList"=selfListMapper, 
                                         "fullList"=fullListMapper, 
                                         "uniqueBy"=uqMapper, 
                                         "pivotBy"=pivotMapper,
                                         "rawMakeVar"=rawMakeVarMapper,
                                         "step3Group"=checkControlGroupMapper,
                                         "step3Vals"=checkControlVarsMapper,
                                         "step4KeyVars"=checkSimilarityMapper, 
                                         "step5PlotItems"=plotSimilarityMapper,
                                         "step6AggregateList"=keyAggMapper
                                         )
                          ) {
    
    # FUNCtiON ARGUMENTS:
    # fileName: the location where downloaded data either is, or will be, stored
    # writeLog: the external file location for printing (NULL means use the main log stdout)
    # ovrwriteLog: boolean, if using an external log, should it be started from scratch (overwritten)?
    # dfRef: a reference data frame for comparison (either NULL or NA means do not run comparisons)
    # urlType: character vector that can be mapped using urlMapper and keyVarMapper
    # url: direct URL passed as character string
    #      NOTE that if both url and urlType are NULL, no file will be downloaded
    # getData: boolean, should an attempt be made to get new data using urlType or url?
    # ovrWriteDownload: boolean, if fileName already exists, should it be overwritten?
    # vecRename: vector for renaming c('existing name'='new name'), can be any length from 0 to ncol(df)
    #            NULL means infer from urlType, if not available there use c()
    # selfList: list for functions to apply to self, list('variable'=fn) will apply variable=fn(variable)
    #           processed in order, so more than one function can be applied to self
    #           NULL means infer from urlType, if not available in mapping file use list()
    # fullList: list for general functions to be applied, list('new variable'=expression(code))
    #           will create 'new variable' as eval(expression(code))
    #           for now, requires passing an expression
    #           NULL means infer from urlType, use list() if not in mapping file
    # pivotBy: combination of variables that should NOT be pivoted
    # uniqueBy: combination of variables for checking uniqueness of pivoted file
    #           NULL means infer from data, keep as NULL (meaning use-all) if cannot be inferred
    # rawMakeVar: variable name to be used for the numeric data pivoted down from columns
    #           NULL means infer from data, keep as NULL (meaning use-all) if cannot be inferred
    # step3Group: variable to be used as the x-axis (grouping) for step 3 plots
    #             NULL means infer from data
    # step3Vals: values to be plotted on the y-axis for step 3 plots
    #            NULL means infer from data
    # step4KeyVars: list of parameters to be passed as keyVars= in step 4
    #               NULL means infer from urlType
    # step5PlotItems: items to be plotted in step 5
    #                 NULL means infer from urlType
    # step6AggregateList: drives the elements to be passed to compareAggregate() and flagLargeDelta()
    #                     NULL means infer from urlType
    # inferVars: vector of c('variable'='mapper') for inferring parameter values when passed as NULL    
    
    # Step 0a: Use urlType to infer key variables if passed as NULL
    for (vrbl in names(inferVars)) {
        mapper <- inferVars[[vrbl]]
        if (is.null(get(vrbl))) {
            if (urlType %in% names(mapper)) assign(vrbl, mapper[[urlType]])
            else if ("default" %in% names(mapper)) assign(vrbl, mapper[["default"]])
        }
    }

    # Step 1: Download a new file (if requested)
    if (!is.null(url) & isTRUE(getData)) fileDownload(fileName=fileName, url=url, ovrWrite=ovrWriteDownload)
    else cat("\nNo file has been downloaded, will use existing file:", fileName, "\n")

    # Step 2: Read file, rename and mutate variables, confirm uniqueness by expected levels
    dfRaw <- fileRead(fileName) %>% 
        colRenamer(vecRename) %>% 
        colMutater(selfList=selfList, fullList=fullList) %>%
        checkUniqueRows(uniqueBy=pivotBy) %>%
        pivotData(pivotKeys=pivotBy, nameVar="date", valVar=rawMakeVar) %>%
        colMutater(selfList=list("date"=lubridate::mdy)) %>%
        checkUniqueRows(uniqueBy=uniqueBy) %>%
        arrange(across(c(setdiff(uniqueBy, "date"), "date"))) %>%
        group_by(across(setdiff(uniqueBy, "date"))) %>%
        mutate(newBurden=ifelse(row_number()==1, get(rawMakeVar), get(rawMakeVar)-lag(get(rawMakeVar)))) %>%
        ungroup() %>%
        colRenamer(vecRename=c("newBurden"=paste0("new_", rawMakeVar)))
    
    # Step 3: Plot basic control totals for new cases and new deaths by month
    dfRaw %>%
        checkControl(groupBy=step3Group, useVars=step3Vals, printControls=FALSE, na.rm=TRUE) %>%
        helperLinePlot(x=step3Group, y="newValue", facetVar="name", facetScales="free_y", groupColor="name")
    
    # If there is no file for comparison, return the data
    if (is.null(dfRef) | (if(length(dfRef)==1) is.na(dfRef) else FALSE)) return(dfRaw)

    # Step 4b: Check similarity of existing and reference file
    # ovrWriteLog=FALSE since everything should be an append after the opening text line in step 0
    diffRaw <- checkSimilarity(df=dfRaw, 
                               ref=dfRef, 
                               keyVars=step4KeyVars, 
                               writeLog=writeLog, 
                               ovrwriteLog=FALSE
                               )
    
    # Step 5: Plot the similarity checks
    plotSimilarity(diffRaw, plotItems=step5PlotItems)
    
    # Step 6: Plot and report on differences in aggregates
    helperAggMap <- function(x) {
        h1 <- compareAggregate(df=dfRaw, ref=dfRef, grpVar=x$grpVar, numVars=x$numVars, 
                               sameUniverse=x$sameUniverse, plotData=x$plotData, isLine=x$isLine, 
                               returnDelta=x$returnDelta)
        if (isTRUE(x$flagLargeDelta)) {
            h2 <- flagLargeDelta(h1, pctTol=x$pctTol, absTol=x$absTol, sortBy=x$sortBy, 
                                 dropNA=x$dropNA, printAll=x$printAll
            )
            if (is.null(writeLog)) print(h2)
            else {
                cat(nrow(h2), " records", sep="")
                txt <- paste0("\n\n***Differences of at least ", 
                              x$absTol, 
                              " and at least ", 
                              round(100*x$pctTol, 3), "%\n\n"
                )
                printLog(h2, txt=txt, writeLog=writeLog)
            }
        }
    }
    lapply(step6AggregateList, FUN=helperAggMap)
    
    cat("\n\n")

    dfRaw
    
}



# Function to obtain county clusters and return the county clusters vector
getCountyClusters <- function(obj, 
                              hierarchical=FALSE, 
                              kCut=0, 
                              reAssign=list(), 
                              defaultCluster=NULL
                              ) {

    # FUNCTION ARGUMENTS
    # obj: a clustering object returned by clusterCounties()
    # hierarchical: whether the clustering object is based on hierarchical clusters
    #               TRUE means from hierarchical clustering
    #               FALSE means from kmeans clustering
    #               NA means from rules-based clustering
    # kCut; if hierarchical clustering is used, what k (number of clusters in cutree) should be used?
    # reAssign: mapping file to change segments, as list('entity'='other entity cluster to use')
    # defaultCluster: cluster label to be assigned to any county that is not in obj$objCluster
    #                 NULL means do not add these to the clustering vector
    
    # Get the clusters from obj$objCluster
    clust <- getClusters(obj$objCluster, hier=hierarchical, kCut=kCut, reAssign=reAssign)
    
    # Add the defaultCluster label to any county that does not have a cluster label
    if (!is.null(defaultCluster)) {
        ctyAdd <- obj$countyBelow %>% pull(state) %>% unique() %>% sort()
        vecAdd <- rep(defaultCluster, length(ctyAdd)) %>% purrr::set_names(ctyAdd)
        clust <- c(clust, vecAdd)
    }
    
    # Return the cluster vector
    clust
    
}



# Function to take county-level data, prepare for clusterStates, and return resulting outputs
clusterCounties <- function(dfPerCapita, 
                            hierarchical,
                            vecRename=c(),
                            clusterBy=c("state"),
                            arrangeBy=c("date"),
                            burdenMetrics=c("cpm", "dpm"),
                            popVar=c("population"),
                            vecSelect=c(clusterBy, arrangeBy, burdenMetrics, popVar),
                            uniqueBy=c(clusterBy, arrangeBy),
                            minPopCluster=1,
                            returnList=TRUE, 
                            ...
                            ) {
    
    # FUNCTION ARGUMENTS:
    # dfPerCapita: a county-level file with per-capita metrics
    # hierarchical: whether to create hierarchical clusters
    #               TRUE means run hierarchical clustering
    #               FALSE means run kmeans clustering
    #               NA means run rules-based clustering
    # vecRename: renaming of input variables
    # clusterBy: the variable name used for clustering
    # arrangeBy: data will be sorted by this a mix of clusterBy and this variable
    # burdenMetrics: the metrics to be used for burden in clustering
    # popVar: the column containing population data
    # vecSelect: selection of input variables
    # uniqueBy: the input file must be unique by, and will then be sorted by, uniqueBy
    # minPopCluster: minimum population for including county in running cluster-level metrics
    # returnList: boolean, if FALSE just the cluster object is returned
    #                      if TRUE, a list is returned with dfCluster and the cluster object
    # ...: other arguments that will be passed to clusterStates

    # STEP 1: Select and rename variables from the dfPerCapita file
    countyData <- dfPerCapita %>%
        colRenamer(vecRename=vecRename) %>%
        colSelector(vecSelect=vecSelect) %>%
        checkUniqueRows(uniqueBy=uniqueBy, returnDF=TRUE) %>%
        arrange(across(all_of(uniqueBy))) %>%
        mutate(popThresh=(get(popVar)>=minPopCluster)) %>%
        colMutater(selfList=c("state"=as.character))
    
    # STEP 2: Split data based on population threshold
    countyFiltered <- countyData %>% filter(popThresh)
    countyBelow <- countyData %>% filter(!popThresh)
    
    # STEP 2a: Confirm that no county is in both data sets
    count(countyFiltered, a=get(clusterBy), popThresh) %>%
        bind_rows(count(countyBelow, a=get(clusterBy), popThresh)) %>%
        checkUniqueRows(uniqueBy=c("a"), returnDF=FALSE, noteUnique=FALSE)
    
    # STEP 3: Run county-level clusters
    objCluster <- clusterStates(countyFiltered, hierarchical=hierarchical, returnList=returnList, ...)
    
    # Return all of the relevant objects
    list(objCluster=objCluster, 
         countyFiltered=countyFiltered, 
         countyBelow=countyBelow
    )
    
}



# Function to run the USA Facts (US county-level coronavirus data) clustering process
readRunUSAFacts <- function(maxDate, 
                            downloadTo=list("usafCase"=NA, "usafDeath"=NA),
                            readFrom=downloadTo,
                            compareFile=list("usafCase"=NA, "usafDeath"=NA),
                            writeLog=NULL,
                            ovrWriteLog=TRUE,
                            dfPerCapita=NULL,
                            showBurdenMinPop=10000, 
                            minPopCluster=25000,
                            defaultCluster=NULL,
                            existingStateClusters=NULL, 
                            existingCountyClusters=NULL, 
                            createClusters=FALSE, 
                            hierarchical=FALSE,
                            kCut=6,
                            orderCluster=TRUE,
                            reAssignCounty=list(),
                            skipAssessmentPlots=FALSE,
                            brewPalette=NA,
                            ...
                            ) {
    
    # FUNCTION ARGUMENTS:
    # maxDate: the maximum data to use for data from the cases and deaths file
    # downloadTo: named list for locations to download data (usafCase, usafDeath, usafPop)
    #             NA means do not download data for that particular element
    # readFrom: named list for locations to read data from (defaults to donwloadTo)
    # compareFile: named list for the reference file to be used for usafCase, usafDeath, usafPop
    #              NA means do not use a reference file for that element
    # writeLog: name of a separate log file for capturing detailed data on changes between files
    #           NULL means no detailed data captured
    # ovrwriteLog: boolean, should the log file be overwritten and started again from scratch?
    # dfPerCapita: file can be passed directly, which bypasses the loading and processing steps
    #              default NULL means create dfPerCapita using steps 2-4
    # showBurdenMinPop: minimum population for showing in burden by cluster plots (NULL means skip plot)
    # minPopCluster: minimum population for including county in running cluster-level metrics
    # defaultCluster: cluster label to be assigned to any county that falls below minPopCluster
    #                 NULL means do not add these to the clustering vector
    # existingStateClusters: location of an existing named vector with clusters by state (NULL means none)
    # existingCountyClusters: location of an existing named vector with clusters by county (NULL means none)
    #                         if existingStateClusters is not NULL, then existingCountyClusters is ignored
    # createClusters: boolean, whether to create new clusters (only set up for kmeans)
    # hierarchical: whether to create hierarchical clusters
    #               TRUE means run hierarchical clustering
    #               FALSE means run kmeans clustering
    #               NA means run rules-based clustering
    # kCut; if hierarchical clustering is used, what k (number of clusters in cutree) should be used?
    # orderCluster: if FALSE, ignore; if TRUE, order by "dpm"; if anything else, order by orderCluster
    # reAssignCounty: mapping file for assigning a county to another county's cluster
    #                format list("countyToChange"="countyClusterToAssign")
    # skipAssessmentPlots: boolean, should cluster assessment plots be skipped?
    # brewPalette: character vector length-1 referencing a color scheme from brewer_pal to use
    #              NA means use R default color schemes
    # ...: other arguments that will be passed to prepClusterCounties

    # STEP 1: Get a county-level population file, with fips as 5-digit character and non-zero population
    countyData <- getCountyData(selfList=list("countyFIPS"=zeroPad5), lstExclude=list("pop"=c(0)))

    # If a log file is requested, create the log file (allows for append=TRUE for all downstream functions)
    if (!is.null(writeLog)) genNewLog(writeLog=writeLog, ovrwriteLog=ovrwriteLog)
    
    # Get the data types to be used (elements of readFrom) and create a file storage list
    elemUsed <- names(readFrom)
    dfRawList <- vector("list", length=length(elemUsed)) %>% purrr::set_names(elemUsed)
    dfProcessList <- vector("list", length=length(elemUsed)) %>% purrr::set_names(elemUsed)
    
    # Steps 2-4 are required only if dfPerCapita has not been passed
    if (is.null(dfPerCapita)) {
    
        # STEP 2: Download and QC each requested data element
        for (elem in elemUsed) {
            dfRawList[[elem]] <- readQCRawUSAF(fileName=readFrom[[elem]],
                                               writeLog=writeLog,
                                               ovrwriteLog=FALSE,
                                               urlType=elem,
                                               getData=if(is.na(downloadTo[[elem]])) FALSE else TRUE,
                                               dfRef=compareFile[[elem]]
                                               )
            glimpseLog(dfRawList[[elem]], txt=paste0("\nRaw file for ", elem, ":\n"), logFile=writeLog)
        }
    
        # STEP 3: Process all requested data
        for (elem in elemUsed) {
            dfProcessList[[elem]] <- processRawFile(dfRawList[[elem]],
                                                    vecRename=c(), 
                                                    vecSelect=vecSelectMapper[[elem]],
                                                    lstCombo=lstComboMapper[[elem]],
                                                    lstFilter=lstFilterMapper[[elem]], 
                                                    lstExclude=lstExcludeMapper[[elem]]
                                                    )
            glimpseLog(dfProcessList[[elem]], txt=paste0("\nProcessed for ", elem, ":\n"), logFile=writeLog)
        }

        # STEP 4: Integrate to create a per-capita data file
        dfPerCapita <- createPerCapita(dfProcessList,
                                       uqBy=c("countyFIPS", "state", "date"),
                                       popData=countyData,
                                       popJoinBy=c("countyFIPS", "state"),
                                       mapper=perCapMapper
                                       )
        glimpseLog(dfPerCapita, txt="\nIntegrated per capita data file:\n", logFile=writeLog)
    
    } else {
        dfRawList <- NULL
        dfProcessList <- NULL
    }

    # STEP 5: Create clusters (if requested)
    if (isTRUE(createClusters)) {
        clData <- clusterCounties(dfPerCapita=dfPerCapita, 
                                  hierarchical=hierarchical, 
                                  minPopCluster=minPopCluster,
                                  ...
                                  )
        useClusters <- getCountyClusters(clData, 
                                         hier=hierarchical, 
                                         kCut=kCut, 
                                         reAssign=reAssignCounty, 
                                         defaultCluster=defaultCluster
                                         )
    } else {
        clData <- NULL
        useClusters <- NULL # Should fix this to allow passing of clusters
    }
    
    # STEP 6: Assess clusters
    if (skipAssessmentPlots) {
        plotDataList <- NULL
    } else {
        
    }
    
    # Return statement, still need to update Step 6 (cluster assessment)
    return(list(countyData=countyData, 
                dfRaw=dfRawList, 
                dfProcess=dfProcessList, 
                dfPerCapita=dfPerCapita, 
                useClusters=useClusters, 
                maxData=maxDate,
                plotDataList=plotDataList
                )
           )
    
}

```

The function is tested as it evolves:  
```{r, fig.height=9, fig.width=9}

testCluster <- clusterCounties(dfPerCapita=readFromRDS("cty_20201026")$clusterData$countyDailyPerCapita, 
                               minPopCluster=25000, 
                               hierarchical=NA,
                               minShape="2020-04",
                               maxShape="2020-09",
                               ratioDeathvsCase = 0.001,
                               ratioTotalvsShape = 0.25,
                               minDeath=100,
                               minCase=5000, 
                               hmlSegs=3, 
                               eslSegs=3, 
                               seed=2010261358
                               )
table(testCluster$objCluster$objCluster, readFromRDS("cty_20201026")$clustVec)
identical(names(testCluster$objCluster$objCluster), names(readFromRDS("cty_20201026")$clustVec))

vecTestCluster_001 <- getCountyClusters(testCluster, hierarchical=NA, defaultCluster="999")
vecTestCluster_002 <- getCountyClusters(testCluster, hierarchical=NA)
usmap::plot_usmap(regions="counties", 
                  data=vecToTibble(vecTestCluster_001, colNameName="fips"), 
                  values="value"
                  )
usmap::plot_usmap(regions="counties", 
                  data=vecToTibble(vecTestCluster_002, colNameName="fips") %>% mutate(value=factor(value)), 
                  values="value"
                  )

testDFRefDeath <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20200917.csv", 
                                getData=FALSE, 
                                urlType="usafDeath"
                                )
usafDeathTest <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20210104.csv", 
                               getData=FALSE, 
                               urlType="usafDeath", 
                               dfRef=testDFRefDeath
                               )

testDFRefCase <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20200917.csv", 
                                getData=FALSE, 
                                urlType="usafCase"
                                )
usafCaseTest <- readQCRawUSAF("./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20210104.csv", 
                              getData=FALSE, 
                              urlType="usafCase", 
                              dfRef=testDFRefCase
                              )

usafProcessCaseTest <- processRawFile(usafCaseTest, 
                                      vecRename=c(), 
                                      vecSelect=c("countyFIPS", "state", "date", "cases", "new_cases"), 
                                      lstCombo=list(), 
                                      lstFilter=list(), 
                                      lstExclude=list("countyFIPS"=c("00000", "00001"))
                                      )
usafProcessDeathTest <- processRawFile(usafDeathTest, 
                                       vecRename=c(), 
                                       vecSelect=c("countyFIPS", "state", "date", "deaths", "new_deaths"), 
                                       lstCombo=list(), 
                                       lstFilter=list(), 
                                       lstExclude=list("countyFIPS"=c("00000", "00001"))
                                       )

usafPerCapitaTest <- createPerCapita(list(usafProcessCaseTest, usafProcessDeathTest), 
                                     uqBy=c("countyFIPS", "state", "date"), 
                                     popData=getCountyData() %>% 
                                         colMutater(selfList=list("countyFIPS"=zeroPad5)), 
                                     mapper=c("deaths"="tdpm", "new_deaths"="dpm", 
                                              "cases"="tcpm", "new_cases"="cpm"
                                              ),
                                     popJoinBy=c("countyFIPS", "state"), 
                                     popVar="pop"
                                     )

```

* The function completes step 1, reading and formatting the county population data file  
* The clustering function works the same as previous, provided a properly formatted per capita data file  
* The function to create a cluster vector works on data returned by the clustering function  
* The function to read and QC an existing downloaded file, with comparison to previous, is included  
* The function to process read files is included  
* The function to integrate files and create per capita metrics is included  
  
The overall function is then tested, with the cluster assessments to be added later:  
```{r, fig.height=9, fig.width=9}

# Create clusters from existing data frame
testFullUSAF_v001 <- readRunUSAFacts(maxDate=NA, 
                                     dfPerCapita=readFromRDS("cty_20201026")$clusterData$countyDailyPerCapita, 
                                     createClusters=TRUE,
                                     defaultCluster="999",
                                     minPopCluster=25000, 
                                     skipAssessmentPlots=TRUE,
                                     hierarchical=NA,
                                     minShape="2020-04",
                                     maxShape="2020-09",
                                     ratioDeathvsCase = 0.001,
                                     ratioTotalvsShape = 0.25,
                                     minDeath=100,
                                     minCase=5000, 
                                     hmlSegs=3, 
                                     eslSegs=3, 
                                     seed=2010261358
                                     )
identical(testFullUSAF_v001$useClusters, vecTestCluster_001)


# Assemble dfPerCapita from components
readList <- list("usafCase"="./RInputFiles/Coronavirus/covid_confirmed_usafacts_downloaded_20201026.csv", 
                 "usafDeath"="./RInputFiles/Coronavirus/covid_deaths_usafacts_downloaded_20201026.csv"
                 )
compareList <- list("usafCase"=testDFRefCase, 
                    "usafDeath"=testDFRefDeath
                    )

testFullUSAF_v002 <- readRunUSAFacts(maxDate=NA, 
                                     downloadTo=lapply(readList, FUN=function(x) if(file.exists(x)) NA else x),
                                     readFrom=readList, 
                                     compareFile=compareList, 
                                     writeLog=NULL, 
                                     ovrWriteLog=TRUE,
                                     createClusters=FALSE,
                                     skipAssessmentPlots=TRUE,
                                     defaultCluster="999",
                                     minPopCluster=25000, 
                                     hierarchical=NA,
                                     minShape="2020-04",
                                     maxShape="2020-09",
                                     ratioDeathvsCase = 0.001,
                                     ratioTotalvsShape = 0.25,
                                     minDeath=100,
                                     minCase=5000, 
                                     hmlSegs=3, 
                                     eslSegs=3, 
                                     seed=2010261358
                                     )

# Get previous per capita data for comparison
compareDataTest <- readFromRDS("cty_20201026")$clusterStateData %>%
    checkUniqueRows(uniqueBy=c("fipsCounty", "date"))
# Only the counties with spelling mismatches should be in old but not in new
compareDataTest %>% 
    anti_join(testFullUSAF_v002$dfPerCapita, by=c("fipsCounty"="countyFIPS", "date"))
# Primarily the counties with spelling mismatched should be in new but not in old
# Should probably delete the 02270 and 06000 which both have population 0
testFullUSAF_v002$dfPerCapita %>% 
    anti_join(compareDataTest, by=c("countyFIPS"="fipsCounty", "date")) %>%
    count(countyFIPS, state)
# Compare values across files
tmpCheck <- testFullUSAF_v002$dfPerCapita %>%
    select(countyFIPS, date, state, 
           cases_usaf=new_cases, deaths_usaf=new_deaths, cpm7_usaf=cpm7, dpm7_usaf=dpm7
           ) %>%
    inner_join(select(compareDataTest, fipsCounty, date, state, 
                      cases_old=cases, deaths_old=deaths, cpm7_old=cpm7, dpm7_old=dpm7
                      ), 
               by=c("countyFIPS"="fipsCounty", "date", "state")
               ) %>%
    pivot_longer(-c(countyFIPS, date, state)) %>%
    mutate(metric=stringr::str_split(name, pattern="_") %>% sapply("[", 1), 
           src=stringr::str_split(name, pattern="_") %>% sapply("[", 2)
           ) %>%
    select(-name) %>%
    pivot_wider(names_from=src, values_from=value) %>%
    filter((is.na(usaf) & !is.na(old)) | (!is.na(usaf) & is.na(old)) | abs(usaf-old) > 0.000001)
 tmpCheck %>% count(metric)
```

The data produced are broadly the same, with the exception of the misnamed counties (better in more recent) and elimination of zero population fips (better in previous).  The issue of including zero-population counties has been addressed by eliminating them from the universe in step 1 (getCountyData()).

A cluster assessment capability is also added:  
```{r, fig.height=9, fig.width=9}

# Create the integrated and aggregate data from lst
dfFullUSAF <- integrateData(lst=list("stateData"=getCountyData(selfList=list("countyFIPS"=zeroPad5),
                                                               lstExclude=list("pop"=c(0))
                                                               ), 
                                     "dfPerCapita"=testFullUSAF_v002$dfPerCapita, 
                                     "useClusters"=clustersToFrame(testFullUSAF_v001$useClusters,
                                                                   colNameName="countyFIPS"
                                                                   ) %>%
                                         colMutater(selfList=list("countyFIPS"=zeroPad5))
                                     ), 
                            lstExtract=list("stateData"=function(x) 
                                colSelector(x, vecSelect=c("countyFIPS", "pop")),
                                "dfPerCapita"=NULL, 
                                "useClusters"=NULL
                                ), 
                            keyJoin="countyFIPS"
                            )
    
dfAggUSAF <- combineAggData(dfFullUSAF, 
                            aggBy=list("agg1"=list(aggFunc=specNA(specSumProd), 
                                                   aggVars=c("pop"), 
                                                   wtVar=NULL, 
                                                   prefix=NULL
                                                   ), 
                                       "agg2"=list(aggFunc=specNA(weighted.mean), 
                                                   aggVars=c("tcpm7", "tdpm7", "cpm7", "dpm7"), 
                                                   wtVar="pop", 
                                                   prefix="wm_"
                                                   )
                                       )
                            )

# Helper function to make a summary map
helperSummaryMap <- function(df, 
                             mapLevel="states", 
                             keyCol="state",
                             values="cluster",
                             discreteValues=NULL,
                             legend.position="right",
                             labelScale=TRUE,
                             extraArgs=list(),
                             countOnly=FALSE,
                             textLabel=c(),
                             ...
                             ) {
    
    # FUNCTION ARGUMENTS:
    # df: a data frame containing a level of geography and an associated cluster
    # mapLevel: a parameter for whether the map is "states" or "counties"
    # keyCol: the key column for plotting (usmap::plot_usmap is particular, and this must be 'state' or 'fips')
    # values: the character name of the field containing the data to be plotted
    # discreteValues: boolean for whether the values are discrete (if not, use continuous)
    #                 NULL means infer from data
    # legend.position: character for the location of the legend in the plot
    # labelScale: boolean, should an scale_fill_ be created?  Use FALSE if contained in extraArgs
    # extraArgs: list of other arguments that will be appended as '+' to the end of the usmap::plot_usmap call
    # countOnly: should a bar plot of counts only be produced?
    # textLabel: a list of elements that should be labelled as text on the plot (too small to see)
    # ...: other parameters to be passed to usmap::plot_usmap (e.g., labels, include, exclude, etc.)
    
    # Modify the data frame to contain only the relevant data
    df <- df %>%
        select(all_of(c(keyCol, values))) %>%
        distinct()
    
    # Determine the type of data being plotted
    if (is.null(discreteValues)) discreteValues <- !is.numeric(df[[values]])
    
    # Convert data type if needed
    if (isTRUE(discreteValues) & is.numeric(df[[values]])) 
        df[[values]] <- factor(df[[values]])
    
    # If count only is needed, create a count map; otherwise create a map
    if (isTRUE(countOnly)) { 
        gg <- df %>%
            ggplot(aes(x=fct_rev(get(values)))) + 
            geom_bar(aes_string(fill=values)) + 
            stat_count(aes(label=..count.., y=..count../2), 
                       geom="text", 
                       position="identity", 
                       fontface="bold"
                       ) +
            coord_flip() + 
            labs(y="Number of members", x="")
    } else {
        if(keyCol=="countyFIPS") {
            df <- df %>% colRenamer(vecRename=c("countyFIPS"="fips"))
            keyCol <- "fips"
        }
        gg <- usmap::plot_usmap(regions=mapLevel, data=df, values=values, ...)
        if (length(textLabel) > 0) {
            labDF <- df %>% 
                filter(get(keyCol) %in% textLabel) %>%
                mutate(rk=match(get(keyCol), textLabel)) %>%
                arrange(rk) %>%
                mutate(lon=-70.1-seq(0, 0.8*length(textLabel)-0.8, by=0.8), 
                       lat=40.1-seq(0, 1.5*length(textLabel)-1.5, by=1.5)
                       ) %>%
                select(lon, lat, everything()) %>%
                usmap::usmap_transform()
            gg <- gg + geom_text(data=labDF, 
                                 aes(x=lon.1, y=lat.1, label=paste(get(keyCol), get(values))), 
                                 size=3.25
                                 )
        }
    }
    
    # Position the legend as requested
    gg <- gg + theme(legend.position=legend.position)
    
    # Create the scale if appropriate
    if (isTRUE(labelScale)) gg <- gg + 
        if(isTRUE(discreteValues)) scale_fill_discrete(values) else scale_fill_continuous(values)
    
    # Apply extra arguments
    for (ctr in seq_along(extraArgs)) gg <- gg + extraArgs[[ctr]]
    
    # Return the map object
    gg
    
}



# Updated function for handling county-level clusters
createSummary <- function(df, 
                          stateClusterDF=NULL,
                          brewPalette=NA, 
                          dataType="state"
                          ) {
    
    # FUNCTION ARGUMENTS:
    # df: an integrated data frame by cluster-date
    # stateClusterDF: a data frame containing state-cluster (NULL means it can be found in df)
    # brewPalette: character string for a palette from RColorBrewer to be used (NA means default colors)
    # dataType: the type of maps being produced ("state" or "county")
    
    # Create plots that can be relevant for a dashboard, including:
    # 1. Map of segments
    # 2. Bar plot of counts by segment
    # 3. Facetted bar plot of segment descriptors (e.g., population, burden per million)
    # 4. Facetted trend-line plot of burden by segments
    
    # Create a map of the clusters
    p1 <- helperSummaryMap(if(is.null(stateClusterDF)) df else stateClusterDF, 
                           mapLevel=if(dataType=="state") "states" else "counties",
                           keyCol=if(dataType=="state") "state" else "countyFIPS",
                           discreteValues=TRUE, 
                           labelScale=is.na(brewPalette), 
                           textLabel=if(dataType=="state") c("RI", "CT", "DE", "MD", "DC") else c(),
                           extraArgs=if(is.na(brewPalette)) list() else 
                               list("arg1"=scale_fill_brewer("Cluster", palette=brewPalette))
                           )
    
    # Create a bar plot of counts by segment
    p2 <- helperSummaryMap(if(is.null(stateClusterDF)) df else stateClusterDF, 
                           mapLevel=if(dataType=="state") "states" else "counties",
                           keyCol=if(dataType=="state") "state" else "countyFIPS",
                           discreteValues=TRUE, 
                           labelScale=is.na(brewPalette), 
                           countOnly=TRUE,
                           extraArgs=if(is.na(brewPalette)) list() else 
                               list("arg1"=scale_fill_brewer("Cluster", palette=brewPalette))
                           )
    
    # Create plot for population and burden by cluster
    p3 <- df %>%
        helperAggTotal(aggVars=c("pop", "wm_tcpm7", "wm_tdpm7"), 
                       mapper=c("pop"="Population (millions)", 
                                "wm_tcpm7"="Cases per thousand", 
                                "wm_tdpm7"="Deaths per million"
                                ), 
                       xLab=NULL, 
                       yLab=NULL, 
                       title=NULL,
                       divideBy=c("pop"=1000000, "wm_tcpm7"=1000), 
                       extraArgs=if(is.na(brewPalette)) list() else 
                           list("arg1"=scale_fill_brewer("Cluster", palette=brewPalette))
                       )
    
    # Create plot for cumulative burden per million over time
    p4xtra <- list(arg1=scale_x_date(date_breaks="2 months", date_labels="%b-%y"), 
                   arg2=theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
                   )
    if(!is.na(brewPalette)) p4xtra$arg3 <- scale_color_brewer("Cluster", palette=brewPalette)
    p4 <- df %>%
        helperAggTrend(aggVars=append(c("wm_tcpm7", "wm_tdpm7"), if(dataType=="state") "wm_hpm7" else NULL), 
                       mapper=c("wm_tcpm7"="Cases per thousand\n(cumulative)", 
                                "wm_tdpm7"="Deaths per million\n(cumulative)", 
                                "wm_hpm7"="Hospitalized per million\n(current)"
                                ),
                       yLab=NULL,
                       title=NULL, 
                       divideBy=c("wm_tcpm7"=1000), 
                       linesize=0.75,
                       extraArgs=p4xtra
                       )
    
    list(p1=p1, p2=p2, p3=p3, p4=p4)
    
}

    
    
# Create the main summary plots
summaryPlotsUSAF <- createSummary(dfAggUSAF, 
                                  stateClusterDF=clustersToFrame(testFullUSAF_v001$useClusters,
                                                                 colNameName="countyFIPS"
                                                                 ) %>%
                                      colMutater(selfList=list("countyFIPS"=zeroPad5)), 
                                  brewPalette="Paired", 
                                  dataType="county"
                                  )
    





# Create the detailed summaries
detPlotsUSAF <- createDetailedSummaries(dfDetail=dfFullUSAF, 
                                        dfAgg=dfAggUSAF, 
                                        detVar=c("countyFIPS"),
                                        p2DetMetrics=c("tcpm7", "tdpm7", "cpm7", "dpm7"),
                                        brewPalette="Paired"
                                        )
    
# Print the summary plots if requested
if (isTRUE(TRUE)) {
    gridExtra::grid.arrange(summaryPlotsUSAF$p1 + theme(legend.position="none"), 
                            summaryPlotsUSAF$p3 + theme(legend.position="left"), 
                            summaryPlotsUSAF$p4, 
                            layout_matrix=rbind(c(1, 2), 
                                                c(3, 3)
                                                )
                            )
}
    
# Print the detailed plots if requested
if (isTRUE(TRUE)) purrr::walk(detPlotsUSAF, .f=print)

```

The plots appear to be created as expected.  Next steps are to update the relevant functions so that plotting is an automatic component of data acquisition and clustering.
