---
title: "Data Camp Python Notes"
author: "davegoblue"
date: "May 11, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(engine.path=list(python="C:\\Users\\Dave\\AppData\\Local\\Programs\\Python\\Python36-32\\python.exe"))
```

## Background and Overview  
DataCamp offer interactive courses related to Python Programming.  Since R Markdown documents can run simple Python code chunks (though the data is not accessible to future chunks, a large difference from R Markdown for R), this document attempts to summarize notes from the first module.
  
## Python Programming  
###_Intro to Python for Data Science_#
  
Chapter 1 - Python Basics  
  
Hello Python! - focusing on Python specific to data science:  
  
* Designed by Guido Van Rossum (started as a hobby), but has become a general purpose language that can build anything  
* Python is open-source, free, and has packages for data science  
* This course will focus on Python 3.x given that support for Python 2.7 has been (and will continue to) decreasing  
	* Available at https://www.python.org/downloads (have downloaded Python 3.6.1 for Windows)  
    * The DataCamp module uses interactive Python (iPython)  
* Python scripts are simply text files with a .py extension - must use print() inside scripts in order to force printing  
  
Variables and Types - variables names are case-sensitive in Python:  
  
* The single equals sign is the assignment operator  
* The type(myVar) call will return the type of the variable - float, integer ("int"), string ("str"), boolean ("bool"), etc.  
	* The booleans are represented as proper-noun capitalization - True and False  
* String summation is concatenation without spacing (roughly the same as paste0() in R) -- "ab" + "cd" = "abcd" ; note also that "ab" * 2 = "abab"  
	* In general, different types of data will respond differently to the same function  
  
Example code includes:  
```{r engine='python'}

# Example, do not modify!
print(5 / 8)

# Put code below here
print(7 + 10)

# Recall that commented lines are marked by the hash-sign, same as R
# Exponentiation is ** and modulo division is %

# Addition and subtraction
print(5 + 5)
print(5 - 5)

# Multiplication and division
print(3 * 5)
print(10 / 2)

# Exponentiation
print(4 ** 2)

# Modulo
print(18 % 7)

# How much is your $100 worth after 7 years?
print(100 * 1.1**7)


# Create a variable savings
savings = 100

# Print out savings
print(savings)


# Create a variable savings
savings = 100

# Create a variable factor
factor = 1.10

# Calculate result
result = savings * factor ** 7

# Print out result
print(result)


# Create a variable desc
desc = "compound interest"

# Create a variable profitable
profitable = True


# Several variables to experiment with
savings = 100
factor = 1.1
desc = "compound interest"

# Assign product of factor and savings to year1
year1 = savings * factor

# Print the type of year1
print(type(year1))

# Assign sum of desc and desc to doubledesc
doubledesc = desc + desc

# Print out doubledesc
print(doubledesc)


# Definition of savings and result
savings = 100
result = 100 * 1.10 ** 7

# Fix the printout
print("I started with $" + str(savings) + " and now have $" + str(result) + ". Awesome!")

# Definition of pi_string
pi_string = "3.1415926"

# Convert pi_string into float: pi_float
pi_float = float(pi_string)


```
  
The output all comes at once, another difference from R Markdown for R.  In combination with being unable to access any of the variables later in the same document, there are tangible limitations to this approach.

Using Python within R Markdown may be more useful if I install "feather" for both Python and R.  Feather allows for running code in Python, then quick-saving pandas in a way that is quick-readable as frames for the next R chunk.  See https://blog.rstudio.org/2016/03/29/feather/.  

Getting feather for R took just a few seconds using install.packages().  Getting feather for Python 3.6 using Windows seems to require a C++ 14.0 compiler from MS Visual Studio.  So far, that is easier said than done.
  
***

Chapter 2 - Lists  
  
What are lists?  Multiple vales in one variable, formed using square brackets such as myList = [a, b, c]:  
  
* The elements of a list may be of any type, including lists  
  
Subsetting lists - the first element in the list is defined as element 0:  
  
* Subsetting can be done as myList[myIndex]  
* Alternately, subsetting can be done using negative numbers, with -1 being the last element of the list  
* List slicing can be run using the colon operator  
	* myList[a:b] will start with index a and end with index b-1  
    * myList[:b] means go from start to index b-1, while myList[a:] means go from a to the end of the list  
  
List manipulation - changing, adding, or removing elements:  
  
* Changing elements is based on using the indices and the equal sign - myList[myIndex] = myNewValue  
* The addition operator will concatenate the various lists  
    * myList + [a, b] will produce a new list [myList, a, b]  
* Deleting elements from a list uses the del() operator - for example, del(myList[2]) will delete the third item of myList which occupies index 2  
* Behind the scense, Python is storing the data and the references to the data  
	* Importantly, this means that copying a list and then editing the copy will edit the original list also; the pointers are to the same underlying data  
    * Basically, myNewList = myList is copying the references to the data that are contained in myList, rather than copying all the data and the references  
    * On the other hand, myNewList = myList[:] or myNewList = list(myList) will make the full, independent copy of the data with new references  
  
Example code includes:  
```{r engine='python'}

# area variables (in square meters)
hall = 11.25
kit = 18.0
liv = 20.0
bed = 10.75
bath = 9.50

# Create list areas
areas = [hall, kit, liv, bed, bath]

# Print areas
print(areas)


# area variables (in square meters)
hall = 11.25
kit = 18.0
liv = 20.0
bed = 10.75
bath = 9.50

# Adapt list areas
areas = ["hallway", hall, "kitchen", kit, "living room", liv, "bedroom", bed, "bathroom", bath]

# Print areas
print(areas)


# area variables (in square meters)
hall = 11.25
kit = 18.0
liv = 20.0
bed = 10.75
bath = 9.50

# house information as list of lists
house = [["hallway", hall],
         ["kitchen", kit],
         ["living room", liv],
         ["bedroom", bed], 
         ["bathroom", bath]
         ]

# Print out house
print(house)

# Print out the type of house
print(type(house))


# Create the areas list
areas = ["hallway", 11.25, "kitchen", 18.0, "living room", 20.0, "bedroom", 10.75, "bathroom", 9.50]

# Print out second element from areas
print(areas[1])

# Print out last element from areas
print(areas[-1])

# Print out the area of the living room
print(areas[5])


# Create the areas list
areas = ["hallway", 11.25, "kitchen", 18.0, "living room", 20.0, "bedroom", 10.75, "bathroom", 9.50]

# Sum of kitchen and bedroom area: eat_sleep_area
eat_sleep_area = areas[3] + areas[7]

# Print the variable eat_sleep_area
print(eat_sleep_area)


# Create the areas list
areas = ["hallway", 11.25, "kitchen", 18.0, "living room", 20.0, "bedroom", 10.75, "bathroom", 9.50]

# Use slicing to create downstairs
downstairs = areas[:6]

# Use slicing to create upstairs
upstairs = areas[6:]

# Print out downstairs and upstairs
print(downstairs)
print(upstairs)


# Create the areas list
areas = ["hallway", 11.25, "kitchen", 18.0, "living room", 20.0, "bedroom", 10.75, "bathroom", 9.50]

# Correct the bathroom area
areas[-1] = 10.5

# Change "living room" to "chill zone"
areas[4] = "chill zone"


# Create the areas list and make some changes
areas = ["hallway", 11.25, "kitchen", 18.0, "chill zone", 20.0,
         "bedroom", 10.75, "bathroom", 10.50]

# Add poolhouse data to areas, new list is areas_1
areas_1 = areas + ["poolhouse", 24.5]

# Add garage data to areas_1, new list is areas_2
areas_2 = areas_1 + ["garage", 15.45]


# Create list areas
areas = [11.25, 18.0, 20.0, 10.75, 9.50]

# Create areas_copy
areas_copy = list(areas)

# Change areas_copy
areas_copy[0] = 5.0

# Print areas
print(areas)


```
  
  
***

Chapter 3 - Functions and Packages  
  
Introduction to functions - pieces of reusable code for solving a particular task:  
  
* Built-in functions are things like max() or type() or round(myNum, myDecimals)  
* Can use help(builtInFunction) to get the help page for builtInFunction  
  
Methods - all objects of a specific type have default access to the methods for that object:  
  
* Methods are functions that belong to an object  
* For example, myList.index("mySearch") will return the index that matches to "mySearch" (if a number, should not be quoted)  
	* Alternately, myList.count("mySearch") will return the number of matches to "mySearch"  
* The methods will behave differently (perhaps even not existing) for different object types  
* Further, some methods modify the object that they are associated with; for example .append()  
  
Packages are directoried of pyhton scripts, each a module specifying functions, methods, and types:  
  
* Thousands of Python packages are available, including Numpy, Matplotlib, and Scikit-learn  
* Installing packages is based on the "pip" system - download get-pip.py from http://pip.readthedocs.org/en/stable/installing  
	* Then, uses "pip3 install myPackage" (unquoted) at the command line  
    * On my machine, needs to be at command line, then [PythonPath]\python.exe -m pip install myPackage  
* Packages can then be imported using "import myPackage" (unquoted) at the command line  
* The package always needs to be attached to its command, for example numpy.array() rather than just array()  
	* As a result, it is often helpful to use import numpy as np, so that np.array() can serve as a shortcut for numpy.array()  
* Alternately, can ask for "from numpy import array" if only wanting to import the function array()  
	* Now, array() can also be called without any prefix; for example, as array(myNumbers) rather than numpy.array(myNumbers)  
  
Example code includes:  
```{r engine='python'}

# Create variables var1 and var2
var1 = [1, 2, 3, 4]
var2 = True

# Print out type of var1
print(type(var1))

# Print out length of var1
print(len(var1))

# Convert var2 to an integer: out2
out2 = int(var2)


# Create lists first and second
first = [11.25, 18.0, 20.0]
second = [10.75, 9.50]

# Paste together first and second: full
full = first + second

# Sort full in descending order: full_sorted
full_sorted = sorted(full, reverse=True)

# Print out full_sorted
print(full_sorted)


# string to experiment with: room
room = "poolhouse"

# Use upper() on room: room_up
room_up = room.upper()

# Print out room and room_up
print(room)
print(room_up)

# Print out the number of o's in room
print(room.count("o"))


# Create list areas
areas = [11.25, 18.0, 20.0, 10.75, 9.50]

# Print out the index of the element 20.0
print(areas.index(20.0))

# Print out how often 14.5 appears in areas
print(areas.count(14.5))


# Create list areas
areas = [11.25, 18.0, 20.0, 10.75, 9.50]

# Use append twice to add poolhouse and garage size
areas.append(24.5)
areas.append(15.45)

# Print out areas
print(areas)

# Reverse the orders of the elements in areas
areas.reverse()

# Print out areas
print(areas)


# Definition of radius
r = 0.43

# Import the math package
import math

# Calculate C
C = 2 * math.pi * r

# Calculate A
A = math.pi * (r ** 2)

# Build printout
print("Circumference: " + str(C))
print("Area: " + str(A))


# Definition of radius
r = 192500

# Import radians function of math package
from math import radians

# Travel distance of Moon over 12 degrees. Store in dist.
dist = r * radians(12)

# Print out dist
print(dist)

```
  
  
***

Chapter 4 - Numpy  
  
Numpy extends list operations using "Numerical Python" (collections of values, optimized for speed):  
  
* The Numpy array is like a list, but you can run mathematical calculations with it  
	* For example, [1, 2, 3] * 2 is [1, 2, 3, 1, 2, 3] while [1, 2, 3] **2 throws an error  
    * However, numpy.array([1, 2, 3]) * 2 is array([2, 4, 6]) while numpy.array([1, 2, 3]) ** 2 is array([1, 4, 9]), both as expected  
* The basic structure of numpy.array() is a vector, which will operate element-wise  
	* Numpy arrays must be of a single-type, converted to the "most flexible" (e.g., string is more flexible than float is more flexible than boolean)  
* The plus sign with a numpy.array() will add element-wise rather than pasting (as it would with lists)  
* Can also use logical subsetting; for example, bmi[bmi > 23] will return all bmi that are greater than 23  
  
2D Numpy Arrays - extending the vector to be multi-dimensional:  
  
* For a numpy vector/array, the type will be numpy.ndarray (stands for n-dimensional array)  
* Can create a two-dimensional array much like an array of lists; numpy.array( [ [1, 2, 3], [4, 5, 6] ] )  
    * The .shape() method will give the dimensions of the array as rows, columns  
* Selecting a row is just based on myArray[rowIndex], so a specific cell can be extracted with myArray[rowIndex][colIndex]  
	* Alternately, myArray[rowIndex, colIndex] will also return the specified row and column  
    * Can also use myArray[:, colIndex] to get just the specified column(s)  
* The 2D Numpy arrays can also be used for element-wise operations
* The 2D Numpy arrays can also be used for element-wise operations  
  
Numpy Basic Statistics - basic data exploration:  
  
* numpy.mean() will take the mean of the relevant data  
* numpy.median() will take the median of the relevant data  
* numpy.corrcoef() will create the correlation coefficients  
* numpy.std() will take the standard deviation  
* numpy.sum() and numpy.sort() are faster than the base versions since numpy has enforced common data types within the array  
* Note that Filip manufactured the MLB data as follows  
    * height = numpy.round(numpy.random.normal(1.75, 0.20, 5000), 2)  
    * weight = numpy.round(numpy.random.normal(60.32, 15, 5000), 2)  
    * np_baseball = np.column_stack((height, weight))  
  
Example code includes:  
```{r engine='python'}

# Create list baseball
baseball = [180, 215, 210, 210, 188, 176, 209, 200]

# Import the numpy package as np
import numpy as np

# Create a Numpy array from baseball: np_baseball
np_baseball = np.array(baseball)

# Print out type of np_baseball
print(type(np_baseball))


# DO NOT HAVE THE HEIGHT OR WEIGHT DATA - it is MLB data on 1000 players
# Create dummy data
height = np.round(np.random.normal(1.75, 0.20, 5000), 2)  
weight = np.round(np.random.normal(60.32, 15, 5000), 2)  


# Create a Numpy array from height: np_height
np_height = np.array(height)

# Print out np_height
print(np_height)

# Convert np_height to m: np_height_m
np_height_m = np_height * 0.0254

# Print np_height_m
print(np_height_m)


# Create array from height with correct units: np_height_m
np_height_m = np.array(height) * 0.0254

# Create array from weight with correct units: np_weight_kg
np_weight_kg = np.array(weight) * 0.453592

# Calculate the BMI: bmi
bmi = np_weight_kg / (np_height_m ** 2)

# Print out bmi
print(bmi)


# Calculate the BMI: bmi
np_height_m = np.array(height) * 0.0254
np_weight_kg = np.array(weight) * 0.453592
bmi = np_weight_kg / np_height_m ** 2

# Create the light array
light = bmi < 21

# Print out light
print(light)

# Print out BMIs of all baseball players whose BMI is below 21
print(bmi[light])


# Store weight and height lists as numpy arrays
np_weight = np.array(weight)
np_height = np.array(height)

# Print out the weight at index 50
print(np_weight[50])

# Print out sub-array of np_height: index 100 up to and including index 110
print(np_height[100:111])


# Create baseball, a list of lists
baseball = [[180, 78.4],
            [215, 102.7],
            [210, 98.5],
            [188, 75.2]]

# Import numpy
import numpy as np

# Create a 2D Numpy array from baseball: np_baseball
np_baseball = np.array(baseball)

# Print out the type of np_baseball
print(type(np_baseball))

# Print out the shape of np_baseball
print(np_baseball.shape)


# DO NOT HAVE baseball, which is a list of lists of the 1015 MLB players with their height/weight
# Create a 2D Numpy array from baseball: np_baseball
# np_baseball = np.array(baseball)
# Dummy up the data instead
np_baseball = np.column_stack((height, weight))  

# Print out the shape of np_baseball
print(np_baseball.shape)  # 1015 x 2


# Create np_baseball (2 cols)
# np_baseball = np.array(baseball)

# Print out the 50th row of np_baseball
print(np_baseball[49])

# Select the entire second column of np_baseball: np_weight
np_weight = np_baseball[:, 1]

# Print out height of 124th player
print(np_baseball[123, 0])


# DO NOT HAVE baseball OR updated ; each should be 1,015 x 3 (height, weight, bmi)
# Create np_baseball (3 cols)
# np_baseball = np.array(baseball)

# Print out addition of np_baseball and updated
# print(np_baseball + updated)

# Create Numpy array: conversion
# conversion = np.array([0.0254, 0.453592, 1])

# Print out product of np_baseball and conversion
# print(np_baseball * conversion)


# Create np_height from np_baseball
np_height = np_baseball[:, 0]

# Print out the mean of np_height
print(np.mean(np_height))

# Print out the median of np_height
print(np.median(np_height))


# Print mean height (first column)
avg = np.mean(np_baseball[:,0])
print("Average: " + str(avg))

# Print median height. Replace 'None'
med = np.median(np_baseball[:,0])
print("Median: " + str(med))

# Print out the standard deviation on height. Replace 'None'
stddev = np.std(np_baseball[:,0])
print("Standard Deviation: " + str(stddev))

# Print out correlation between first and second column. Replace 'None'
corr = np.corrcoef(np_baseball[:, 0], np_baseball[:, 1])
print("Correlation: " + str(corr))


# DO NOT HAVE DATA for positions or heights (soccer data . . . )
# Convert positions and heights to numpy arrays: np_positions, np_heights
# np_positions = np.array(positions)
# np_heights = np.array(heights)

# Heights of the goalkeepers: gk_heights
# gk_heights = np_heights[np_positions == "GK"]

# Heights of the other players: other_heights
# other_heights = np_heights[np_positions != "GK"]

# Print out the median height of goalkeepers. Replace 'None'
# print("Median height of goalkeepers: " + str(np.median(gk_heights)))

# Print out the median height of other players. Replace 'None'
# print("Median height of other players: " + str(np.median(other_heights)))


```
  

###_Intermediate Python for Data Science_#  
  
Chapter 1 - Matplotlib for Data Visualization  
  
Basic plots with matplotlib - generally, the heart of visualization within Python:  
  
* Need to import the key functions; for example import matplotlib.pyplot as plt  
* Then, plt.plot(list1, list2) will create a line plot with list1 being x and list2 being y  
	* If you want to actually see the plot, use plt.show(), somewhat like plt.plot() just being a saved ggplot2 object  
* Alternately, plt.scatter() to create a scatter plot  
  
Histograms are useful for exploring a dataset (getting an idea about the distribution):  
  
* import matplotlib.pyplot as plt  # help(plt.hist) will show all the options for a histogram  
* plt.hist(x, bins=myBins)  # default for myBins is 10  
	* Needs plt.show() as per the above  
  
Customization for changing the base plot types in Python:  
  
* Can label x-axis with plt.xlabel('X Label')  
* Can label y-axis with plt.xlabel('Y Label')  
* Can add title with plt.title('My Title')  
* Can add plt.yticks([myList], [myNames]) # myList can be 2+ elements which will define the y-range; optional list myNames must be the same length as myList and will label the y-axis  
	* All of these must be run PRIOR to the plt.show() command  
  
Example code includes:  
```{r engine="python"}

# Define the reading data path
readPath = "C:/Users/Dave/Documents/Personal/Learning/Coursera/RDirectory/RHomework/DataCamp/"

# This is world population 1950-2100 (DO NOT HAVE FILE)
# Import some wikipedia data from CSV as panda
import pandas as pd

globalPop = pd.read_csv(readPath + "GlobalPopYear_1950_2100_v001.csv")

year = globalPop["year"]
pop = globalPop["pop"]

# Print the last item from year and pop
print(year.iloc[-1])
print(pop.iloc[-1])

# Import matplotlib.pyplot as plt
import matplotlib.pyplot as plt

# Make a line plot: year on the x-axis, pop on the y-axis
plt.plot(year, pop)

# Display the plot with plt.show()
# Need to use a proper Python IDE for plt.show() - otherwise just pops up the images "live"
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy001.png", bbox_inches="tight")

```
  
**The population plot saved from Python is**:  
![](_dummyPy001.png)
  
Next, the Hans Rosling Data is explored:  
```{r engine = "python"}

# Using the Hans Rosling Data (2007 life expectancy and GDP for 142 countries)
# Create from Wikipedia, World Bank, and the like
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# readPath = "C:\\Users\\Dave\\Documents\\Personal\\Learning\\Coursera\\RDirectory\\RHomework\\DataCamp\\"
readPath = "C:/Users/Dave/Documents/Personal/Learning/Coursera/RDirectory/RHomework/DataCamp/"


globalData = pd.read_csv(readPath + "GlobalGDPLifeExpectancy_v001.csv")

gdp_cap = 1000000 * np.array(globalData["gdp"]) / np.array(globalData["pop"])
life_exp = globalData["le_2015"]
pop = globalData["pop"]
life_exp1950 = globalData["le_1960"]  # Much easier to get 1960 than 1950 online - KLUGE
regn = globalData["region"]

# Print the last item of gdp_cap and life_exp
print(gdp_cap[-1])  # Since it is a numpy
print(life_exp.iloc[-1])  # Since it is a panda

# Make a line plot, gdp_cap on the x-axis, life_exp on the y-axis
plt.plot(gdp_cap, life_exp)

# Display the plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy002.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Change the line plot below to a scatter plot
plt.scatter(gdp_cap, life_exp)

# Put the x-axis on a logarithmic scale
plt.xscale('log')

# Show plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy003.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Brings in yet another variable, population

# Build Scatter plot
plt.scatter(pop, life_exp)
plt.xscale("log")

# Show plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy004.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Create histogram of life_exp data
plt.hist(life_exp)

# Display histogram
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy005.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Build histogram with 5 bins
plt.hist(life_exp, bins=5)

# Show and clean up plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# plt.clf()
# Save as dummy PNG instead
plt.savefig("_dummyPy006.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Build histogram with 20 bins
plt.hist(life_exp, bins=20)

# Show and clean up again
# Need to use a proper Python IDE for plt.show()
# plt.show()
# plt.clf()
# Save as dummy PNG instead
plt.savefig("_dummyPy007.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Histogram of life_exp, 15 bins
plt.hist(life_exp, bins=15)

# Show and clear plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# plt.clf()
# Save as dummy PNG instead
plt.savefig("_dummyPy008.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Histogram of life_exp1950, 15 bins
plt.hist(life_exp1950, bins=15)

# Show and clear plot again
# Need to use a proper Python IDE for plt.show()
# plt.show()
# plt.clf()
# Save as dummy PNG instead
plt.savefig("_dummyPy009.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Basic scatter plot, log scale
plt.scatter(gdp_cap, life_exp)
plt.xscale('log') 

# Strings
xlab = 'GDP per Capita [in USD]'
ylab = 'Life Expectancy [in years]'
title = 'World Development in 2007'

# Add axis labels
plt.xlabel(xlab)
plt.ylabel(ylab)

# Add title
plt.title(title)

# After customizing, display the plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy010.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Scatter plot
plt.scatter(gdp_cap, life_exp)

# Previous customizations
plt.xscale('log') 
plt.xlabel('GDP per Capita [in USD]')
plt.ylabel('Life Expectancy [in years]')
plt.title('World Development in 2007')

# Definition of tick_val and tick_lab
tick_val = [1000,10000,100000]
tick_lab = ['1k','10k','100k']

# Adapt the ticks on the x-axis
plt.xticks(tick_val, tick_lab)

# After customizing, display the plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy011.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Import numpy as np
import numpy as np

# Store pop as a numpy array: np_pop
np_pop = np.array(pop) / 1000000  # Population in millions

# Double np_pop
np_pop = np_pop * 2 # Doubled for larger bubbles

# Update: set s argument to np_pop
plt.scatter(gdp_cap, life_exp, s = np_pop)

# Previous customizations
plt.xscale('log') 
plt.xlabel('GDP per Capita [in USD]')
plt.ylabel('Life Expectancy [in years]')
plt.title('World Development in 2007')
plt.xticks([1000, 10000, 100000],['1k', '10k', '100k'])

# Display the plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy012.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Color is based on continent, using the below dictionary
colDict = {
    'Asia':'red',
    'Europe':'green',
    'Africa':'blue',
    'Americas':'yellow',
    'Oceania':'black'
}

col=[]

for eachRegion in regn :
    col.append(colDict[eachRegion])

# Specify c and alpha inside plt.scatter()
plt.scatter(x = gdp_cap, y = life_exp, s = np_pop , c=col, alpha=0.8)

# Previous customizations
plt.xscale('log') 
plt.xlabel('GDP per Capita [in USD]')
plt.ylabel('Life Expectancy [in years]')
plt.title('World Development in 2007')
plt.xticks([1000,10000,100000], ['1k','10k','100k'])

# Show the plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# plt.clf()
# Save as dummy PNG instead
plt.savefig("_dummyPy013.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

# Scatter plot
plt.scatter(x = gdp_cap, y = life_exp, s = np_pop, c = col, alpha = 0.4)

# Previous customizations
plt.xscale('log') 
plt.xlabel('GDP per Capita [in USD]')
plt.ylabel('Life Expectancy [in years]')
plt.title('World Development in 2007')
plt.xticks([1000,10000,100000], ['1k','10k','100k'])

# Additional customizations
plt.text(1550, 71, 'India')
plt.text(5700, 80, 'China')

# Add grid() call
plt.grid(True)

# Show the plot
# Need to use a proper Python IDE for plt.show()
# plt.show()
# Save as dummy PNG instead
plt.savefig("_dummyPy014.png", bbox_inches="tight")
plt.clf()  # Required to prevent continued over-plotting

```
  
**GDP vs Life Expectancy by Country as Line Graph (not good . . . )**:  
![](_dummyPy002.png)
  
**GDP vs Life Expectancy by Country as Scatter Plot**:  
![](_dummyPy003.png)

**GDP vs Life Expectancy by Country as Scatter Plot with Log Scale**:  
![](_dummyPy004.png)

**Life Expectancy Histogram (default 10 bins)**:  
![](_dummyPy005.png)

**Life Expectancy Histogram (5 bins)**:  
![](_dummyPy006.png)

**Life Expectancy Histogram (20 bins)**:  
![](_dummyPy007.png)

**Life Expectancy Histogram for 2015 (15 bins)**:  
![](_dummyPy008.png)

**Life Expectancy Histogram for 1960 (15 bins)**:  
![](_dummyPy009.png)

**Base Rosling-like graph (GDP vs Life Expectancy by Country Scatter)**:  
![](_dummyPy010.png)

**Rosling-like graph (enhanced tick labels)**:  
![](_dummyPy011.png)

**Rosling-like graph (bubble size ~ population)**:  
![](_dummyPy012.png)

**Rosling-like graph (bubble color based on region)**:  
![](_dummyPy013.png)
  
**Rosling-like graph (semit-transparent bubbles)**:  
![](_dummyPy014.png)
  
  
***
  
Chapter 2 - Dictionaries and Pandas  
  
Dictionaries, Part I - key-value pairs:  
  
* The dictionary is created with curly brackets, with key-value pairs denoted by a colon and separated by a comma  
	* world = { "afghanistan":31, "albania":2.8, "algeria":39 }  # sets up three key-value pairs as the dictionary called world  
    * Now, world["albania"] will return 2.8, the value that is associated with key "albania"  
* Dictionary look-ups are extremely fast even for enormous dictionaries  
  
Dictionaries, Part II:  
  
* Dictionaries need to have unique keys; if duplicate keys are included, the value associated with the LAST key is retained  
* The keys also need to be immutable objects, which is to say strings or booleans or integers or floats (but not lists, since you can change their contents dynamically)  
* Assigning (or changing) key-value pairs in a dictionary is myDict[myKey] = myValue  
* To test whether a key is in the dictionary, use myKey in myDict # returns boolean True or False  
* To delete an item from the dictionary, use del(myDict[myKey]) # the full key-value pair is removed  
* Lists and dictionaries have many similarities, but also some key differences  
	* Lists are indexed by a range of numbers, making them ideal for collections of values where the order matters  
    * Dictionaries are indexed by unique keys, making them ideal for fast look-ups (they are also inherently completely unordered/unsorted based on how they are hashed)  
  
Pandas, Part I - tabular dataset storage and manipulation:  
  
* Same general philosophy where rows are observations and columns are attributes/variables  
* Basically, need a form of numpy.array() that allows for different variable types in different columns  
* The pandas package provides a high-level data-manipulation tool (built on numpy by Wes McKinney)  
	* The pandas package conveniently stores data as a DataFrame  
    * Generally, the rows and columns will all have unique names  
    * Further, the columns can all be of different types  
* Suppose that you create a dictionary where the keys are the desired column labels while the values are a list of the desired values for the column  
	* import pandas as pd  
    * myFrame = pd.DataFrame(myDict)  
    * myFrame.index = labelList # optional, if wanting to provide row-names  
* Alternately, the data can be imported such as from a CSV  
	* pd.read_csv(myCSVPath, index_col=myIndex)  # index_col is optional and needed only if an index column has been provided  
  
Pandas, Part II - indexing and selecting data from a DataFrame using square brackets, loc, and iloc:  
  
* myFrame[colNameQuoted] will return a subset of the panda with type pandas.core.series.Series  
* myFrame[[colNameQuoted]] will return a single-column panda with type pandas.core.frame.DataFrame  
* myFrame[[colName1Quoted, colName2Quoted]] will return a two-column panda  
* myFrame[a:b] will return rows rather than columns, starting with index a and ending at index b-1  
* The loc and iloc tools are designed to extend Pandas data extraction to be more similar to numpy extractions such as [ rows, columns ]  
	* myFrame.loc[rowNameQuoted] will return a panda series matching the ROW  
    * myFrame.loc[[rowNameQuoted]] will return a panda frame containing just that ROW  
    * myFrame.loc[[rowName1Quoted, rowName2Quoted, rowName3Quoted]] will return a panda frame containing the requested ROWS  
    * myFrame.loc[[rowListQuoted], [colListQuoted]] will return just the specified rows and columns  
    * myFrame.loc[:, [colListQuoted]] will return all rows and just the specified columns  
* The iloc function is the index-based version of loc for data access and extraction  
	* myFrame.iloc[[rowIndices]] will return a panda frame containing just these ROWS  
    * myFrame.iloc[[rowIndices], [colIndices]] will return a panda frame containing just these COLUMNS  
  
Example code includes:  
```{r engine="python"}

# Definition of countries and capital
countries = ['spain', 'france', 'germany', 'norway']
capitals = ['madrid', 'paris', 'berlin', 'oslo']

# Get index of 'germany': ind_ger
ind_ger = countries.index("germany")

# Use ind_ger to print out capital of Germany
print(capitals[ind_ger])


# Definition of countries and capital
countries = ['spain', 'france', 'germany', 'norway']
capitals = ['madrid', 'paris', 'berlin', 'oslo']

# From string in countries and capitals, create dictionary europe
europe = {
   'spain':'madrid', 
   'france':'paris', 
   'germany':'berlin', 
   'norway':'oslo'
}

# Print europe
print(europe)


# Definition of dictionary
europe = {'spain':'madrid', 'france':'paris', 'germany':'berlin', 'norway':'oslo' }

# Print out the keys in europe
print(europe.keys())

# Print out value that belongs to key 'norway'
print(europe['norway'])


# Definition of dictionary
europe = {'spain':'madrid', 'france':'paris', 'germany':'berlin', 'norway':'oslo' }

# Add italy to europe
europe['italy'] = 'rome'

# Print out italy in europe
print('italy' in europe)

# Add poland to europe
europe['poland'] = 'warsaw'

# Print europe
print(europe)


# Definition of dictionary
europe = {'spain':'madrid', 'france':'paris', 'germany':'bonn',
          'norway':'oslo', 'italy':'rome', 'poland':'warsaw',
          'australia':'vienna' }

# Update capital of germany
europe['germany'] = 'berlin'

# Remove australia
del(europe['australia'])

# Print europe
print(europe)


# Dictionary of dictionaries
europe = { 'spain': { 'capital':'madrid', 'population':46.77 },
           'france': { 'capital':'paris', 'population':66.03 },
           'germany': { 'capital':'berlin', 'population':80.62 },
           'norway': { 'capital':'oslo', 'population':5.084 } }


# Print out the capital of France
print(europe['france']['capital'])

# Create sub-dictionary data
data = { 'capital':'rome', 'population':59.83 }

# Add data to europe under key 'italy'
europe['italy'] = data

# Print europe
print(europe)


# Pre-defined lists
names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']
dr =  [True, False, False, False, True, True, True]
cpc = [809, 731, 588, 18, 200, 70, 45]

# Import pandas as pd
import pandas as pd

# Create dictionary my_dict with three key:value pairs: my_dict
my_dict = { 'country': names, 'drives_right': dr, 'cars_per_cap': cpc }

# Build a DataFrame cars from my_dict: cars
cars = pd.DataFrame(my_dict)

# Print cars
print(cars)


# Build cars DataFrame
names = ['United States', 'Australia', 'Japan', 'India', 'Russia', 'Morocco', 'Egypt']
dr =  [True, False, False, False, True, True, True]
cpc = [809, 731, 588, 18, 200, 70, 45]
dict = { 'country':names, 'drives_right':dr, 'cars_per_cap':cpc }
cars = pd.DataFrame(dict)
print(cars)

# Definition of row_labels
row_labels = ['US', 'AUS', 'JAP', 'IN', 'RU', 'MOR', 'EG']

# Specify row labels of cars
cars.index = row_labels

# Print cars again
print(cars)


# DO NOT HAVE FILE "cars.csv" - cars_per_cap , country , drives_right
# Created as cars.to_csv("cars.csv")
# Import the cars.csv data: cars
cars = pd.read_csv("cars.csv")

# Print out cars
print(cars)


# SLIGHTLY DIFFERENT VERSION WITH ROW NAMES AS THE FIRST COLUMN
# Import pandas as pd
import pandas as pd

# Fix import by including index_col
cars = pd.read_csv('cars.csv', index_col=0)

# Print out cars
print(cars)


# Import cars data
import pandas as pd
cars = pd.read_csv('cars.csv', index_col = 0)

# Print out country column as Pandas Series
print(cars["country"])

# Print out country column as Pandas DataFrame
print(cars[["country"]])

# Print out DataFrame with country and drives_right columns
print(cars[["country", "drives_right"]])


# Import cars data
import pandas as pd
cars = pd.read_csv('cars.csv', index_col = 0)

# Print out first 3 observations
print(cars[0:3])

# Print out fourth, fifth and sixth observation
print(cars[3:6])


# Print out observation for Japan
print(cars.loc["JAP"])

# Print out observations for Australia and Egypt
print(cars.loc[["AUS", "EG"]])


# Print out drives_right value of Morocco
print(cars.loc[["MOR"], ["drives_right"]])

# Print sub-DataFrame
print(cars.loc[["RU", "MOR"], ["country", "drives_right"]])


# Print out drives_right column as Series
print(cars.loc[:, "drives_right"])

# Print out drives_right column as DataFrame
print(cars.loc[:, ["drives_right"]])

# Print out cars_per_cap and drives_right as DataFrame
print(cars.loc[:, ["cars_per_cap", "drives_right"]])


```
  
  
***

Chapter 3 - Logic, Control Flow, and Filtering  
  
Comparison Operators - how two values relate (tests for equality, greater, lesser, etc.):  
  
* Less than (<), greater than (>), equals (==), less than or equal (<=), greater than or equal (>=), and not equals (!=) are as per R  
* Need to have comparisons between objects of the same type (specifically, not comparing strings and floats)  
  
Boolean operators - most commonly used are and, or, and not:  
  
* In Python, the word "and" is used rather than & or &&  
* In Python, the word "or" is used rather than | or ||  
* In Python, the word "not" is used rather than - or !  
* If comparisons will be run on an array, then use np.logical_and(), np.logical_or(), and np.logical_not()  
    * np.logical_and(bmi > 27, bmi < 30)  
  
If, elif, else:  
  
* General syntax is "if condition : action" followed optionally by "elif condition : action" or "else condition : action"
	* If written on multiple lines, the action should be indented by 4 spaces and may include block instructions  
    * Any code without the indentation will be known to no longer be part of the if block  
  
Filtering Pandas DataFrame - generally a three-step process of 1) select key column as panda.series, 2) run test, and 3) use to grab relevant rows:  
  
* If you pass myFrame[myBool] where myBool is the same size (number of rows) as myFrame, then it will automatically pull back the rows where myBool == True  
* Because pandas are built on the numpy infrastructure, np.logical_and() and the related terms will work on the pandas also  
  
Example code includes:  
```{r engine='python'}

# Comparison of booleans
print(True == False)

# Comparison of integers
print((-5 * 15) != 75)

# Comparison of strings
print("pyscript" == "PyScript")

# Compare a boolean with an integer
print(True == 1)


# Comparison of integers
x = -3 * 6
print(x >= -10)

# Comparison of strings
y = "test"
print("test" <= y)

# Comparison of booleans
print(True > False)


# Create arrays
import numpy as np
my_house = np.array([18.0, 20.0, 10.75, 9.50])
your_house = np.array([14.0, 24.0, 14.25, 9.0])

# my_house greater than or equal to 18
print(my_house >= 18)

# my_house less than your_house
print(my_house < your_house)


# Define variables
my_kitchen = 18.0
your_kitchen = 14.0

# my_kitchen bigger than 10 and smaller than 18?
print(my_kitchen > 10 and my_kitchen < 18)

# my_kitchen smaller than 14 or bigger than 17?
print(my_kitchen < 14 or my_kitchen > 17)

# Double my_kitchen smaller than triple your_kitchen?
print(2 * my_kitchen < 3 * your_kitchen)


# Create arrays
import numpy as np
my_house = np.array([18.0, 20.0, 10.75, 9.50])
your_house = np.array([14.0, 24.0, 14.25, 9.0])

# my_house greater than 18.5 or smaller than 10
print(np.logical_or(my_house > 18.5, my_house < 10))

# Both my_house and your_house smaller than 11
print(np.logical_and(my_house <11, your_house < 11))


# Define variables
room = "kit"
area = 14.0

# if statement for room
if room == "kit" :
    print("looking around in the kitchen.")

# if statement for area
if area > 15 :
    print("big place!")


# Define variables
room = "kit"
area = 14.0

# if-else construct for room
if room == "kit" :
    print("looking around in the kitchen.")
else :
    print("looking around elsewhere.")

# if-else construct for area
if area > 15 :
    print("big place!")
else :
    print("pretty small.")


# Define variables
room = "bed"
area = 14.0

# if-elif-else construct for room
if room == "kit" :
    print("looking around in the kitchen.")
elif room == "bed":
    print("looking around in the bedroom.")
else :
    print("looking around elsewhere.")

# if-elif-else construct for area
if area > 15 :
    print("big place!")
elif area > 10 :
    print("medium size, nice!")
else :
    print("pretty small.")


# AS PER ABOVE, DO NOT HAVE THIS DATASET
# That has since been worked around . . . 
# Import cars data
import pandas as pd
cars = pd.read_csv('cars.csv', index_col = 0)

# Extract drives_right column as Series: dr
dr = cars["drives_right"]

# Use dr to subset cars: sel
sel = cars[dr]

# Print sel
print(sel)


# Convert code to a one-liner
sel = cars[cars['drives_right']]

# Print sel
print(sel)


# Import cars data
import pandas as pd
cars = pd.read_csv('cars.csv', index_col = 0)

# Create car_maniac: observations that have a cars_per_cap over 500
cpc = cars["cars_per_cap"]
many_cars = cpc > 500
car_maniac = cars[many_cars]

# Print car_maniac
print(car_maniac)


# Create medium: observations with cars_per_cap between 100 and 500
cpc = cars['cars_per_cap']
between = np.logical_and(cpc > 100, cpc < 500)
medium = cars[between]

# Print medium
print(medium)


```
  
  
***

Chapter 4 - Loops  
  




