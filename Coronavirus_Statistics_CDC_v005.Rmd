---
title: "Coronavirus US - CDC All-Cause Death"
author: "davegoblue"
date: "7/7/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Background  
This module extends code contained in Coronavirus_Statistics_v004.Rmd to include sourcing of all key functions and parameters.  This file includes the latest code for analyzing all-cause death data from [CDC Weekly Deaths by Jurisdiction](https://catalog.data.gov/dataset/weekly-counts-of-deaths-by-jurisdiction-and-age-group).  CDC maintains data on deaths by week, age cohort, and state in the US.  Downloaded data are unique by state, epidemiological week, year, age, and type (actual vs. predicted/projected).

These data are known to have a lag between death and reporting, and the CDC back-correct to report deaths at the time the death occurred even if the death is reported in following weeks.  This means totals for recent weeks tend to run low (lag), and the CDC run a projection of the expected total number of deaths given the historical lag times.  Per other analysts on the internet, there is currently significant supra-lag, with lag times much longer than historical averages causing CDC projected deaths for recent weeks to be low.

The code leverages tidyverse and sourced functions throughout:  
```{r}

# All functions assume that tidyverse and its components are loaded and available
library(tidyverse)

# If the same function is in both files, use the version from the more specific source
source("./Generic_Added_Utility_Functions_202105_v001.R")
source("./Coronavirus_CDC_Excess_Functions_v001.R")

```
  
## Running Code  
The main function is readRunCDCAllCause(), which performs multiple tasks:  
  
STEP 0: Optionally, downloads the latest data file from CDC
STEP 1: Reads and processes a data file has been downloaded from CDC to local  
STEP 2: Extract relevant data from a processed state-level COVID Tracking Project list  
STEP 3: Basic plots of the CDC data  
STEP 4: Basic excess-deaths analysis  
STEP 5: Create cluster-level aggregate plots  
STEP 6: Create state-level aggregate plots  
STEP 7: Create age-cohort aggregate plots  
STEP 8: Returns a list of key data frames, modeling objects, named cluster vectors, etc.  
  
The functions are tested on previously downloaded data:  
```{r, fig.height=9, fig.width=9}

cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20210623.csv"
cdcList_20210703 <- readRunCDCAllCause(loc=cdcLoc, 
                                       weekThru=17, 
                                       lst=readFromRDS("cdc_daily_210528"), 
                                       dlData=FALSE, 
                                       stateNoCheck=c("NC"), 
                                       pdfCluster=TRUE, 
                                       pdfAge=TRUE
                                       )

```
  
The latest data are downloaded and processed:  
```{r, fig.height=9, fig.width=9, cache=TRUE}

cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20210708.csv"
cdcList_20210708 <- readRunCDCAllCause(loc=cdcLoc, 
                                       weekThru=22, 
                                       lst=readFromRDS("cdc_daily_210708"), 
                                       stateNoCheck=c("NC", "AK", "WV"), 
                                       pdfCluster=TRUE, 
                                       pdfAge=TRUE
                                       )
saveToRDS(cdcList_20210708)

```
  
The function readProcessCDC() is updated to allow for more control in zeroing out (rather than erroring) where there is a small number of data suppression:  
```{r}

# Function to check for CDC excess suppression
checkCDCSuppression <- function(df, stateNoCheck, errTotAllowed=20, errMaxAllowed=round(errTotAllowed/2)) {
    
    # Categorize the potential issues in the file (note to suppress or NA deaths)
    checkProblems <- df %>% 
        mutate(problem=(!is.na(Suppress) | is.na(deaths)), 
               noCheck=state %in% all_of(stateNoCheck)
               )
    
    # Print a list of the problems, excluding those in stateNoCheck
    cat("\nRows in states to be checked that have NA deaths or a note for suppression:\n")
    checkProblems %>%
        filter(problem, !noCheck) %>%
        arrange(desc(year), desc(week)) %>%
        select(state, weekEnding, year, week, age, Suppress, deaths) %>%
        as.data.frame() %>%
        print()
    
    # Summarize the problems
    cat("\n\nProblems by state:\n")
    checkProblems %>%
        group_by(noCheck, state, problem) %>%
        summarize(n=n(), deaths=specNA(sum)(deaths), .groups="drop") %>%
        filter(problem) %>%
        print()
    
    # Assess the amount of error
    errorState <- checkProblems %>%
        filter(problem, !noCheck) %>%
        count(state)
    
    # Error out if threshold for error by state OR total errors exceeded
    errMax <- errorState %>% pull(n) %>% max()
    errTot <- errorState %>% pull(n) %>% sum()
    cat("\n\nThere are", errTot, "rows with errors; maximum for any given state is", errMax, "errors\n")
    
    if ((errTot > errTotAllowed) | (errMax > errMaxAllowed)) {
        stop("\nToo many errors; thresholds are ", errTotAllowed, " total and ", errMaxAllowed, " maximum\n")
    }
    
}



plotQCReadProcessCDC <- function(df, 
                                 ckCombos=list(c("age"), c("period", "year", "Type"), 
                                               c("period", "Suppress"), c("period", "Note")
                                               )
                                 ) {
    
    # Create dataset for analysis
    df <- df %>% 
        mutate(n=1, n_deaths_na=ifelse(is.na(deaths), 1, 0))
    
    # Check control totals by specified combinaions
    purrr::walk(ckCombos, .f=function(x) {
        cat("\n\nChecking variable combination:", x, "\n")
        checkControl(df, groupBy=x, useVars=c("n", "n_deaths_na", "deaths"), fn=specNA(sum))
        }
        )
    
    # Plot deaths by state
    p1 <- checkControl(df, 
                       groupBy=c("state"), 
                       useVars=c("deaths"), 
                       fn=specNA(sum), 
                       printControls=FALSE, 
                       pivotData=FALSE
                       ) %>%
        ggplot(aes(x=fct_reorder(state, deaths), y=deaths)) + 
        geom_col(fill="lightblue") + 
        geom_text(aes(y=deaths, label=paste0(round(deaths/1000), "k")), hjust=0, size=3) + 
        coord_flip() +
        labs(y="Total deaths", x=NULL, title="Total deaths by state in all years in processed file")
    print(p1)
    
    # Plot deaths by week/year
    p2 <- checkControl(df, 
                       groupBy=c("year", "week"), 
                       useVars=c("deaths"), 
                       fn=specNA(sum), 
                       printControls=FALSE, 
                       pivotData=FALSE
                       ) %>%
        ggplot(aes(x=week, y=deaths)) + 
        geom_line(aes(group=year, color=year)) + 
        labs(title="Deaths by year and epidemiological week", x="Epi week", y="US deaths") + 
        scale_color_discrete("Year") + 
        lims(y=c(0, NA))
    print(p2)
    
}



# Function to read and process raw CDC all-cause deaths data
readProcessCDC <- function(fName, 
                           weekThru,
                           periodKeep=cdcExcessParams$periodKeep,
                           fDir="./RInputFiles/Coronavirus/",
                           col_types=cdcExcessParams$colTypes, 
                           renameVars=cdcExcessParams$remapVars,
                           maxSuppressAllowed=20, 
                           stateNoCheck=c()
                           ) {
    
    # FUNCTION ARGUMENTS:
    # fName: name of the downloaded CDC data file
    # weekThru: any record where week is less than or equal to weekThru will be kept
    # periodKeep: any record where period is in periodKeep will be kept
    # fDir: directory name for the downloaded CDC data file
    # col_types: variable type by column in the CDC data (passed to readr::read_csv())
    # renameVars: named vector for variable renaming of type c("Existing Name"="New Name")
    # maxSuppressAllowed: maximum number of data suppressions (must be in current week/year) to avoid error
    # stateNoCheck: vector of states that do NOT have suppression errors thrown
    
    # STEP 1: Read the CSV data
    cdcRaw <- fileRead(paste0(fDir, fName), col_types=col_types)
    # glimpse(cdcRaw)
    
    # STEP 2: Rename the variables for easier interpretation
    cdcRenamed <- cdcRaw %>%
        colRenamer(vecRename=renameVars) %>%
        colMutater(selfList=list("weekEnding"=lubridate::mdy))
    # glimpse(cdcRenamed)
    
    # STEP 3: Convert to factored data
    cdcFactored <- cdcRenamed %>%
        colMutater(selfList=list("age"=factor), levels=cdcExcessParams$ageLevels) %>%
        colMutater(selfList=list("period"=factor), levels=cdcExcessParams$periodLevels) %>%
        colMutater(selfList=list("year"=factor), levels=cdcExcessParams$yearLevels)
    # glimpse(cdcFactored)
    
    # STEP 4: Filter the data to include only weighted deaths and only through the desired time period
    cdcFiltered <- cdcFactored %>%
        rowFilter(lstFilter=list("Type"="Predicted (weighted)")) %>%
        filter(period %in% all_of(periodKeep) | week <= weekThru)
    # glimpse(cdcFiltered)
    
    # STEP 4a: Check that all suppressed data and NA deaths have been eliminated
    cat("\n\n *** Data suppression checks *** \n")
    checkCDCSuppression(cdcFiltered, stateNoCheck=stateNoCheck, errTotAllowed=maxSuppressAllowed)
    cat("\n\nData suppression checks passed\n\n")
    
    # STEP 5: Remove any NA death fields, delete the US record, convert YC to be part of NY
    cdcProcessed <- cdcFiltered %>%
        rowFilter(lstExclude=list("state"=c("US", "PR"), "deaths"=c(NA))) %>%
        mutate(state=ifelse(state=="YC", "NY", state), 
               fullState=ifelse(state %in% c("NY", "YC"), "New York State (NY plus YC)", fullState)
               ) %>%
        group_by(fullState, weekEnding, state, year, week, age, period, Type, Suppress) %>%
        arrange(!is.na(Note)) %>%
        summarize(n=n(), deaths=sum(deaths), Note=first(Note), .groups="drop") %>%
        ungroup() %>%
        checkUniqueRows(uniqueBy=c("state", "year", "week", "age"))
    glimpse(cdcProcessed)
    
    # STEP 5a: Check control levels for key variables in processed file
    cat("\nCheck Control Levels and Record Counts for Processed Data:\n")
    plotQCReadProcessCDC(cdcProcessed)

    # STEP 6: Return the processed data file
    cdcProcessed
    
}

```

The data are processed using the updated function:  
```{r, fig.height=9, fig.width=9, cache=TRUE}

cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20210708.csv"
cdcList_20210708_v2 <- readRunCDCAllCause(loc=cdcLoc, 
                                          weekThru=23, 
                                          lst=readFromRDS("cdc_daily_210708"), 
                                          stateNoCheck=c("NC"), 
                                          pdfCluster=TRUE, 
                                          pdfAge=TRUE
                                          )

```
  
The latest data are downloaded and processed:  
```{r, fig.height=9, fig.width=9, cache=TRUE}

cdcLoc <- "Weekly_counts_of_deaths_by_jurisdiction_and_age_group_downloaded_20210823.csv"
cdcList_20210823 <- readRunCDCAllCause(loc=cdcLoc, 
                                       weekThru=29, 
                                       lst=readFromRDS("cdc_daily_210815"), 
                                       stateNoCheck=c("NC", "AK", "CT"), 
                                       pdfCluster=TRUE, 
                                       pdfAge=TRUE
                                       )

```
  
CDC data for deaths by age and location available at [CDC website](https://data.cdc.gov/api/views/4va6-ph5s/rows.csv?accessType=DOWNLOAD) are downloaded, cached to avoid multiple hits to the server:  
```{r, fig.height=9, fig.width=9, cache=TRUE}

deathAgeLoc <- "./RInputFiles/Coronavirus/COvID_deaths_age_place_20210824.csv"
if (!file.exists(deathAgeLoc)) {
    fileDownload(fileName="./RInputFiles/Coronavirus/COvID_deaths_age_place_20210824.csv", 
                 url="https://data.cdc.gov/api/views/4va6-ph5s/rows.csv?accessType=DOWNLOAD"
                 )
} else {
    cat("\nFile already exists, not downloading\n")
}

```
  
The file is then read for a basic exploration:  
```{r, fig.height=9, fig.width=9}

deathAge_20210824_raw <- fileRead(deathAgeLoc, col_types="cccciiccccddddddc")
glimpse(deathAge_20210824_raw)

deathAge_20210824_conv <- deathAge_20210824_raw %>%
    colRenamer(vecRename=c("Data as of"="asofDate", 
                           "Start Date"="startDate", 
                           "End Date"="endDate", 
                           "HHS Region"="HHSRegion", 
                           "Place of Death"="deathPlace", 
                           "Age group"="Age", 
                           "COVID-19 Deaths"="covidDeaths", 
                           "Total Deaths"="totalDeaths", 
                           "Pneumonia Deaths"="pneumoDeaths", 
                           "Pneumonia and COVID-19 Deaths"="pneumoCovidDeaths", 
                           "Influenza Deaths"="fluDeaths", 
                           "Pneumonia, Influenza, or COVID-19 Deaths"="pnemoFluCovidDeaths"
                           )
               ) %>%
    colMutater(selfList=list("asofDate"=lubridate::mdy, "startDate"=lubridate::mdy, "endDate"=lubridate::mdy))
glimpse(deathAge_20210824_conv)

# Combinations of startDate and endDate
deathAge_20210824_conv %>%
    count(asofDate, startDate, endDate) %>%
    ggplot(aes(y=startDate, x=endDate)) + 
    geom_point(aes(size=n)) + 
    facet_wrap(~asofDate) + 
    labs(x="Ending Date", y="Starting Date", title="Combinations of Start and End Date")

deathAge_20210824_conv %>%
    count(Group, deathPlace, Age) %>%
    ggplot(aes(x=Group, y=deathPlace)) + 
    geom_tile(aes(fill=n)) + 
    facet_wrap(~Age) + 
    labs(x="Group", y="Place of Death", title="Combinations of Age, Place of Death, and Group")

deathState <- deathAge_20210824_conv %>%
    filter(Group=="By Total", deathPlace=="Total - All Places of Death", Age=="All Ages") %>%
    group_by(State) %>%
    summarize(across(where(is.numeric), sum, na.rm=TRUE)) %>%
    mutate(abb=state.abb[match(State, state.name)])
deathState %>% filter(is.na(abb))

deathBase <- deathState %>%
    select(State, covidDeaths, totalDeaths) %>%
    mutate(noncovid=covidDeaths/totalDeaths) %>%
    filter(!(State %in% c("United States", "Puerto Rico"))) %>%
    pivot_longer(-c(State)) %>%
    ggplot(aes(x=fct_reorder(State, value, max), y=value/1000)) + 
    coord_flip() + 
    theme(legend.position="bottom")
deathBase + 
    geom_col(data=~filter(., name=="totalDeaths"), aes(fill="All")) +
    geom_col(data=~filter(., name=="covidDeaths"), aes(fill="COVID")) + 
    scale_fill_manual("Type", breaks=c("COVID", "All"), labels=c("COVID", "All"), values=c("red", "black")) + 
    labs(title="Deaths 2020-present by state", x=NULL, y="Deaths (000s)")
deathBase + 
    geom_col(data=~filter(., name=="noncovid"), aes(y=value), position="identity") + 
    labs(x=NULL, y=NULL, title="Proportion of deaths from COVID")

```

The data appear to contain monthly totals, with the addition of full-year 2020, YTD 2021, and total 2020-YTD 2021. Totals are provided by age sub-group and overall, place of death category and overall, and monthly, annually, and total.

Total deaths and proportions from COVID appear sensible. Next steps are to continue processing and exploring the data:  
```{r, fig.height=9, fig.width=9}

# Add the state abbreviation
deathAge_20210824_conv <- deathAge_20210824_conv %>%
    mutate(abb=c(state.abb, "DC")[match(State, c(state.name, "District of Columbia"))])

# Function to check that totals match sum of sub-totals
checkSubTotals <- function(df, checkByVars, subVar, subVarTotal, sumVars=NULL, sumFunc=specNA(sum), ...) {
    
    # FUNCTION ARGUMENTS:
    # df: data.frame or tibble
    # checkByVars: variables that the frame will be checked by
    # subVar: variable that is being checked
    # subVarTotal: label for the value that is the total of subVar
    # sumVars: variables to be summed (NULL means all numeric)
    # sumFunc: function to be applied when summing all variables
    # ...: any other arguments to pass to summarize(across(all_of(checkByVars), .fns=sumFunc, ...))
    
    # If sumVars is NULL, find the sum variables
    if (is.null(sumVars)) sumVars <- df %>% head(1) %>% select_if(is.numeric) %>% names()
    
    # Keep only te desired variables in df
    df <- df %>%
        select(all_of(c(checkByVars, subVar, sumVars))) %>%
        arrange(across(all_of(checkByVars)))
    
    # Split the data frame by subtotal and total
    dfTot <- df %>%
        filter(get(subVar) == subVarTotal)
    dfSub <- df %>%
        filter(get(subVar) != subVarTotal) %>%
        group_by(across(all_of(checkByVars))) %>%
        summarize(across(all_of(sumVars), .fns=sumFunc, ...), .groups="drop") %>%
        mutate(fakeCol=subVarTotal) %>%
        colRenamer(vecRename=c("fakeCol"=subVar)) %>%
        select(names(dfTot))
    
    # Comparison of totals
    list(dfSub=dfSub, dfTot=dfTot)
    
}

checkNumbers <- function(lst, byVars, lstNames=NULL, absTol=100, pctTol=0.05, keyVar="key variable") {
    
    # FUNCTION ARGUMENTS:
    # lst: a list with two items that will be checked for similarity
    # byVars: by variables that should be identical across the list items
    # lstNames: names to use for the list (NULL means use names provided in lst)
    # absTol: absolute value of differences to flag
    # pctTol: percent tolerance for differences to flag
    # keyVar: name for the key variable in plot title
    
    # Check that lst is a list of length 2
    if (!("list" %in% class(lst)) | !(length(lst)==2)) stop("\nMust pass a list with two items\n")
    
    # Add names if passed in lstNames, otherwise use names(lst)
    if (!is.null(lstNames)) names(lst) <- lstNames 
    else lstNames <- names(lst)
    
    # Check for identical files using only byVars
    if (!isTRUE(identical(lst[[1]][, byVars], lst[[2]][, byVars]))) 
        stop("\nSub-lists differ by byVars, not comparing\n") 
    else cat("\nSub-lists are identical by:", paste0(byVars, collapse=", "), "\n")
    
    # Check the numeric values
    dfDelta <- lapply(lst, FUN=function(x) pivot_longer(x, cols=-all_of(byVars)) %>% 
               mutate(value=ifelse(is.na(value), 0, value)) %>%
               select(all_of(byVars), name, value)
           ) %>%
        purrr::reduce(.f=inner_join, by=c(all_of(byVars), "name")) %>%
        mutate(delta=value.x-value.y, pct=ifelse(delta==0, 0, delta/(value.x+value.y))) %>%
        purrr::set_names(c(all_of(byVars), "name", all_of(lstNames), "delta", "pct"))
    
    # Plot the differences using name as facet
    p1 <- dfDelta %>%
        ggplot(aes(x=delta, y=pct)) + 
        geom_point() + 
        facet_wrap(~name, scales="free") + 
        labs(title=paste0("Differences between totals and subtotals on variable: ", keyVar), 
             x="Difference between total and subtotal", 
             y="Percentage difference"
             )
    print(p1)
    
    # Flag significant outliers
    dfDelta %>%
        filter(abs(delta) >= absTol, abs(pct) >= pctTol) %>%
        arrange(-abs(delta)) %>%
        print()
    
}

# Get a list of the possible variables
allCheckVars <- names(deathAge_20210824_conv) %>% 
    setdiff(deathAge_20210824_conv %>% head(1) %>% select_if(is.numeric) %>% names()) %>%
    setdiff(c("Footnote", "abb", "HHSRegion"))

# Test for each variable in allCheckVars
subMap <- c("State"="United States", "Age"="All Ages", "deathPlace"="Total - All Places of Death")
lapply(c("State", "deathPlace", "Age"), 
       FUN=function(x) deathAge_20210824_conv %>% 
           select(-Year, -Month) %>%
           checkSubTotals(checkByVars=allCheckVars %>% setdiff(x), subVar=x, subVarTotal=unname(subMap[x])) %>%
           checkNumbers(byVars=allCheckVars, keyVar=x)
       )

```

Variables Age and deathPlace appear to be well-aligned between sub-totals and totals, while variable State shows some more significant differences. Next steps are to further research what is contained in State, including alignment to other data sources.
